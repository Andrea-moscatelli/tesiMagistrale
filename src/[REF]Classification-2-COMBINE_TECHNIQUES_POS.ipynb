{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/students_home/amoscatelli/.local/bin:/data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/bin:/data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/cuda/bin:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# PROJECT_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis\"\n",
    "# os.environ['PATH'] = \"/sbin:/bin:/usr/bin:/usr/local/bin:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin\"\n",
    "# os.environ['PATH'] = PROJECT_FOLDER+\"/miniconda3/bin:\" + os.environ['PATH'] \n",
    "os.environ['PATH'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# with tf.device(\"/GPU:0\"):\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Almost) Reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=32, inter_op_parallelism_threads=32)\n",
    "# session_conf = tf.ConfigProto()\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# import tensorflow as tf\n",
    "# # import os\n",
    "# # with tf.device(\"/GPU:0\"):\n",
    "# # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.python.client import device_lib\n",
    "# # gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# # tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# # config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "#                                     # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and count zero's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "def getData(datasetName):\n",
    "    with open(datasetName,'rb') as file_in:\n",
    "#         features, labels, setups, cameras, performers, replications = pickle.load(file_in)\n",
    "        train_set, val_set, test_set = pickle.load(file_in)\n",
    "    \n",
    "    #### stats ################################\n",
    "    labels = [\"train_set\", \"val_set\", \"test_set\"]\n",
    "    for i,dataset in enumerate([train_set, val_set, test_set]):\n",
    "        totalsize, zero_elements =  getZeroStatsForDataset(dataset[0])\n",
    "        print(\"{} shape: {}\".format(labels[i], dataset[0].shape))\n",
    "        print(\"{} zero elements: {}/{} ({:.2}%)\".format(labels[i],zero_elements,totalsize,zero_elements*100/totalsize))\n",
    "        \n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def getZeroStatsForDataset(X):\n",
    "    totalsize = sum([len(x)*len(x[0])*2 for x in X])\n",
    "    non_zero_elements = sum([np.count_nonzero(x) for x in X])\n",
    "    zero_elements = totalsize - non_zero_elements\n",
    "    return totalsize, zero_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it removes the zeros from the dataset features taking for each video the closest non-zero value \n",
    "def removeZerosFromDataset(X):\n",
    "    print(\"removing zeros from dataset\")\n",
    "    for i,video in enumerate(X):\n",
    "        if sum([np.count_nonzero(frame==0) for frame in video])>0:\n",
    "#             print(\"removing zeros from video\", i)\n",
    "            removeZerosFromVideo(video)\n",
    "    return X\n",
    "    \n",
    "# return the closest non zero point for the passed point\n",
    "def getClosestNonZeroCoordinate(frameIdx, point, features):\n",
    "    for hop in range(1,len(features)):\n",
    "        previousIdx = max(0, frameIdx-hop)\n",
    "        nextIdx = min(len(features)-1, frameIdx+hop)\n",
    "        if all(features[previousIdx][point] != 0):\n",
    "            return features[previousIdx][point]\n",
    "        if all(features[nextIdx][point] != 0):\n",
    "            return features[nextIdx][point]\n",
    "    return [0.0,0.0] #in case that point is never found in the video\n",
    "        \n",
    "# it removes the zeros from the video features taking the closest non-zero values for each point\n",
    "def removeZerosFromVideo(videoFeatures):\n",
    "    # retrieving the index of the points which contain 0 values for each frame \n",
    "    zeroPoints = [list(set(np.where(frame == 0.)[0])) for frame in videoFeatures] \n",
    "    \n",
    "    # concatenating the previous result with the frame index (discarding correct frames)\n",
    "    zeroPointsCoordinates = [(i,p) for i,p in enumerate(zeroPoints) if len(p)>0]\n",
    "    \n",
    "    oldVideo = np.copy(videoFeatures)\n",
    "    notFoundPoints = set()\n",
    "    for frameIdx, pointCoordinates in zeroPointsCoordinates:\n",
    "        for pointIdx in pointCoordinates:\n",
    "            if pointIdx in notFoundPoints:\n",
    "                videoFeatures[frameIdx][pointIdx] = [0.0,0.0]\n",
    "            else:\n",
    "                videoFeatures[frameIdx][pointIdx] = getClosestNonZeroCoordinate(frameIdx, pointIdx,oldVideo)\n",
    "            \n",
    "            if np.count_nonzero(videoFeatures[frameIdx][pointIdx]) == 0:\n",
    "                notFoundPoints.add(pointIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def one_hot_encoding(labels):\n",
    "    encoder = LabelBinarizer()\n",
    "    label_strings = [str(i) for i in labels]\n",
    "    oneHotLabels = encoder.fit_transform(label_strings)\n",
    "    print('classes order:', encoder.classes_) \n",
    "    return oneHotLabels, encoder.classes_\n",
    "    \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def paddingTrainValTest(X_train, X_val, X_test, maxLength=None):\n",
    "    if maxLength is None:\n",
    "         maxLength = max([len(s) for s in np.concatenate((X_train, X_val, X_test), axis=0)])\n",
    "    \n",
    "    # 17 if there is always only 1 person, 34 if there are videos with 2 people\n",
    "    maxVideoHeigth = max([len(s[0]) for s in np.concatenate((X_train, X_val, X_test), axis=0)])\n",
    "    \n",
    "    for dataset in [X_train, X_val, X_test]:\n",
    "        for i in range(len(dataset)):\n",
    "            if dataset[i].shape[1] < maxVideoHeigth:\n",
    "                videoShape = dataset[i].shape\n",
    "                missingPart = (videoShape[0], maxVideoHeigth-videoShape[1], videoShape[2])\n",
    "#                 dataset[i] = np.concatenate((dataset[i],np.zeros(dataset[i].shape)),axis=1)\n",
    "                dataset[i] = np.concatenate((dataset[i], np.zeros(missingPart)), axis=1)\n",
    "    \n",
    "    \n",
    "    X_train = pad_sequences(X_train, maxlen=maxLength, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "    X_val = pad_sequences(X_val, maxlen=maxLength, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "    X_test = pad_sequences(X_test, maxlen=maxLength, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "    \n",
    "    ### stats ######################################\n",
    "    labels = [\"train set\", \"val set\", \"test set\"]\n",
    "    for i, dataset in enumerate([X_train, X_val, X_test]):\n",
    "        totalsize, zero_elements =  getZeroStatsForDataset(dataset)\n",
    "        print(\"{} shape: {}\".format(labels[i], dataset.shape))\n",
    "        print(\"{} zero elements (after padding): {} ({:.2f}%)\".format(labels[i],zero_elements,zero_elements*100/totalsize))\n",
    "    \n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseWholeDataset(X_train, X_val, X_test):\n",
    "    trainAndVal = np.concatenate((X_train, X_val), axis=0)\n",
    "    print(\"normalising together train, val and test values BEFORE padding\")\n",
    "    trainMean = np.vstack([p.reshape((-1,2)) for p in trainAndVal]).mean() # the mean and std must be calculated only on the training data\n",
    "    trainStd = np.vstack([p.reshape((-1,2)) for p in trainAndVal]).std()\n",
    "    normalized_X_train = np.array([(x - trainMean)/trainStd for x in X_train])\n",
    "    normalized_X_val = np.array([(x - trainMean)/trainStd for x in X_val])\n",
    "    normalized_X_test = np.array([(x - trainMean)/trainStd for x in X_test])\n",
    "\n",
    "    return normalized_X_train, normalized_X_val, normalized_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeVideosXYInpid(dataset):\n",
    "    print(\"normalising EACH VIDEO, considering x and y INDIPENDENTLY\")\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        xAndYVideoMean = np.mean(np.vstack(dataset[i]),axis=0)\n",
    "        xAndYVideoStd = np.std(np.vstack(dataset[i]),axis=0)\n",
    "        dataset[i] = (dataset[i]-xAndYVideoMean)/xAndYVideoStd\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeVideos(dataset):\n",
    "    print(\"normalising EACH VIDEO, considering x and y TOGETHER\")\n",
    "    for i in range(len(dataset)):\n",
    "        videoMean = np.mean(np.vstack(dataset[i]))\n",
    "        videoStd = np.std(np.vstack(dataset[i]))\n",
    "        dataset[i] = (dataset[i]-videoMean)/videoStd\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posenet predicts:\n",
    "# 1 - nose             18\n",
    "# 2 - leftEye          19\n",
    "# 3 - rightEye         20\n",
    "# 4 - leftEar          21\n",
    "# 5 - rightEar         22\n",
    "\n",
    "# 6 - leftShoulder     23\n",
    "# 7 - rightShoulder    24\n",
    "# 8 - leftElbow        25\n",
    "# 9 - rightElbow       26\n",
    "# 10 - leftWrist       27\n",
    "# 11 - rightWrist      28\n",
    "\n",
    "# 12 - leftHip         29\n",
    "# 13 - rightHip        30\n",
    "# 14 - leftKnee        31\n",
    "# 15 - rightKnee       32\n",
    "# 16 - leftAnkle       33\n",
    "# 17 - rightAnkle      34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeToVideoCenter(X):\n",
    "    print(\"Adapting the data to the CENTER of each VIDEO\")\n",
    "    for i,frames in enumerate(X):\n",
    "        # calculating the center of the whole video\n",
    "        videoMean = np.mean([np.mean(features,axis=0) for features in frames], axis = 0) \n",
    "        X[i] = [frame-videoMean for frame in frames]\n",
    "\n",
    "    return X\n",
    "\n",
    "def relativeToPersonVideoCenter(X):\n",
    "    print(\"Adapting the data to the video PERSON CENTER of each VIDEO\")\n",
    "    for i,frames in enumerate(X):\n",
    "        # calculating the center of the frames points relative to the whole video\n",
    "        videoMean = np.mean([np.mean(features[:17],axis=0) for features in frames], axis = 0) \n",
    "\n",
    "        if len(frames[0]) == 34:\n",
    "            videoMean2 = np.mean([np.mean(features[17:],axis=0) for features in frames], axis = 0) \n",
    "            videoMean = np.vstack((videoMean, videoMean2)) \n",
    "            videoMean = np.repeat(videoMean, [17, 17], axis=0)\n",
    "        \n",
    "        X[i] = [frame-videoMean for frame in frames]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeToFrameCenter(X):\n",
    "    print(\"Adapting the data to the CENTER of each FRAME\")\n",
    "    for i_video, video in enumerate(X):\n",
    "        for i_frame, frame in enumerate(video):\n",
    "            frame_mean = np.mean(frame,axis=0)\n",
    "            X[i_video][i_frame] = frame - frame_mean\n",
    "\n",
    "    return X\n",
    "\n",
    "def relativeToPersonFrameCenter(X):\n",
    "    print(\"Adapting the data to the PERSON CENTER of each FRAME\")\n",
    "    for i_video, video in enumerate(X):\n",
    "        for i_frame, frame in enumerate(video):\n",
    "            frame_mean = np.mean(frame[:17],axis=0)\n",
    "            if len(frame) == 34:\n",
    "                frame_mean2 = np.mean(frame[17:],axis=0)\n",
    "                frame_mean = np.vstack((frame_mean, frame_mean2)) \n",
    "                frame_mean = np.repeat(frame_mean, [17, 17], axis=0)\n",
    "            X[i_video][i_frame] = frame - frame_mean\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[p[0]+i, p[1]+i]for i,p in enumerate(f)] for f in X_to_test1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER PERSON BARICENTERS\n",
    "def relativeTo5PersonalBaricentersNTURGBofVideo(X):\n",
    "    print(\"Adapting the data to the 5 body PERSONAL BARICENTERS of each video as in NTU-RGB+D\")\n",
    "    for i_video,frames in enumerate(X): \n",
    "        troncoPoints = [0,1,2,3,4,5,6,11,12]\n",
    "        rightArmPoints = [8,10]\n",
    "        leftArmPoints = [7,9]\n",
    "        rightLegPoints = [14,16]\n",
    "        leftLegPoints = [13,15] \n",
    "        videoCenterFrame = np.zeros(frames[0].shape)\n",
    "        for person_offset in range(0,len(frames[0]),17):\n",
    "            troncoPoints = [i+person_offset for i in troncoPoints]\n",
    "            rightArmPoints = [i+person_offset for i in rightArmPoints]\n",
    "            leftArmPoints = [i+person_offset for i in leftArmPoints]\n",
    "            rightLegPoints = [i+person_offset for i in rightLegPoints]\n",
    "            leftLegPoints = [i+person_offset for i in leftLegPoints]\n",
    "            troncoCenter = np.mean(np.mean(np.array(frames)[:,troncoPoints], axis=1),axis=0)\n",
    "            rightArmCenter = np.mean(np.mean(np.array(frames)[:,rightArmPoints], axis=1),axis=0)\n",
    "            leftArmCenter = np.mean(np.mean(np.array(frames)[:,leftArmPoints], axis=1),axis=0)\n",
    "            rightLegCenter = np.mean(np.mean(np.array(frames)[:,rightLegPoints], axis=1),axis=0)\n",
    "            leftLegCenter = np.mean(np.mean(np.array(frames)[:,leftLegPoints], axis=1),axis=0)\n",
    "\n",
    "            videoCenterFrame[troncoPoints] = troncoCenter \n",
    "            videoCenterFrame[rightArmPoints] = rightArmCenter \n",
    "            videoCenterFrame[leftArmPoints] = leftArmCenter \n",
    "            videoCenterFrame[rightLegPoints] = rightLegCenter \n",
    "            videoCenterFrame[leftLegPoints] = leftLegCenter \n",
    "\n",
    "        X[i_video] = frames - videoCenterFrame\n",
    "    return X\n",
    "\n",
    "\n",
    "# GLOBAL BARICENTERS\n",
    "def relativeTo5GlobalBaricentersNTURGBofVideo(X):\n",
    "    print(\"Adapting the data to the 5 body GLOBAL BARICENTERS of each video as in NTU-RGB+D\")\n",
    "    for i_video,frames in enumerate(X): \n",
    "        troncoPoints = [0,1,2,3,4,5,6,11,12]\n",
    "        rightArmPoints = [8,10]\n",
    "        leftArmPoints = [7,9]\n",
    "        rightLegPoints = [14,16]\n",
    "        leftLegPoints = [13,15] \n",
    "        videoCenterFrame = np.zeros(frames[0].shape)\n",
    "        if len(frames[0]) == 34:\n",
    "            person_offset = 17\n",
    "            troncoPoints += [i+person_offset for i in troncoPoints]\n",
    "            rightArmPoints += [i+person_offset for i in rightArmPoints]\n",
    "            leftArmPoints += [i+person_offset for i in leftArmPoints]\n",
    "            rightLegPoints += [i+person_offset for i in rightLegPoints]\n",
    "            leftLegPoints += [i+person_offset for i in leftLegPoints]\n",
    "        troncoCenter = np.mean(np.mean(np.array(frames)[:,troncoPoints], axis=1),axis=0)\n",
    "        rightArmCenter = np.mean(np.mean(np.array(frames)[:,rightArmPoints], axis=1),axis=0)\n",
    "        leftArmCenter = np.mean(np.mean(np.array(frames)[:,leftArmPoints], axis=1),axis=0)\n",
    "        rightLegCenter = np.mean(np.mean(np.array(frames)[:,rightLegPoints], axis=1),axis=0)\n",
    "        leftLegCenter = np.mean(np.mean(np.array(frames)[:,leftLegPoints], axis=1),axis=0)\n",
    "\n",
    "        videoCenterFrame[troncoPoints] = troncoCenter \n",
    "        videoCenterFrame[rightArmPoints] = rightArmCenter \n",
    "        videoCenterFrame[leftArmPoints] = leftArmCenter \n",
    "        videoCenterFrame[rightLegPoints] = rightLegCenter \n",
    "        videoCenterFrame[leftLegPoints] = leftLegCenter \n",
    "\n",
    "        X[i_video] = frames - videoCenterFrame\n",
    "    return X\n",
    "\n",
    "def relativeTo5GlobalBaricentersNTURGBofVideoAbs(X):\n",
    "    print(\"ABSOLUTE VALUES of 5 GLOBAL BARICENTERS\")\n",
    "    return abs(relativeTo5GlobalBaricentersNTURGBofVideo(X))\n",
    "\n",
    "def relativeTo5PersonalBaricentersNTURGBofVideoAbs(X):\n",
    "    print(\"ABSOLUTE VALUES of 5 PERSONAL BARICENTERS\")\n",
    "    return abs(relativeTo5PersonalBaricentersNTURGBofVideo(X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_name = \"keypoint_rcnn_X_101_32x8d_FPN_3x\"\n",
    "# model_name = \"PoseNet-101\"\n",
    "# datasetName = DATASET_FOLDER+model_name+\"-CROSS_SUBJECT_TEST-dataset.pickle\"\n",
    "\n",
    "# train_set, val_set, test_set = getData(datasetName)\n",
    "\n",
    "# train_set[0] = removeZerosFromDataset(train_set[0])\n",
    "# val_set[0] = removeZerosFromDataset(val_set[0])\n",
    "# test_set[0] = removeZerosFromDataset(test_set[0])\n",
    "\n",
    "# labels = [\"train_set\", \"val_set\", \"test_set\"]\n",
    "# for i,dataset in enumerate([train_set, val_set, test_set]):\n",
    "#     totalsize, zero_elements =  getZeroStatsForDataset(dataset[0])\n",
    "#     print(\"{} shape: {}\".format(labels[i], dataset[0].shape))\n",
    "#     print(\"{} zero elements: {}/{} ({:.2}%)\".format(labels[i],zero_elements,totalsize,zero_elements*100/totalsize))\n",
    "\n",
    "    \n",
    "# X_to_test = train_set[0][0]\n",
    "# X_to_test = X_to_test[:2]\n",
    "# X_to_test = np.expand_dims(X_to_test, axis=0)\n",
    "# print(\"X_to_test shape\", X_to_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relativeTo3BaricentersOfFrame(X):\n",
    "#     assert False, \"Va testato\"\n",
    "#     print(\"Adapting the data to the TOP-MIDDLE-BOTTOM center of each frame\")\n",
    "#     for i_video, video in enumerate(X):\n",
    "#         for i_frame, frame in enumerate(video):\n",
    "#             X[i_video][i_frame][:5] = frame[:5] - np.mean(frame[:5], axis=0)\n",
    "#             X[i_video][i_frame][5:11] = frame[5:11] - np.mean(frame[5:11], axis=0)\n",
    "#             X[i_video][i_frame][11:17] = frame[11:17] - np.mean(frame[11:17], axis=0)\n",
    "#             if len(frame) == 34:\n",
    "#                 X[i_video][i_frame][17:22] = frame[17:22] - np.mean(frame[17:22], axis=0)\n",
    "#                 X[i_video][i_frame][22:28] = frame[22:28] - np.mean(frame[22:28], axis=0)\n",
    "#                 X[i_video][i_frame][28:34] = frame[28:34] - np.mean(frame[28:34], axis=0)\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ARTIFICIAL \n",
    "# X_to_test1 = np.ones(2*17*2).reshape((2,17,2)) # 1 person\n",
    "# X_to_test1 = np.asarray([np.asarray([np.asarray([p[0]+i, p[1]+i]) for i,p in enumerate(f)]) for f in X_to_test1])\n",
    "\n",
    "# X_to_test2 = np.ones(3*34*2).reshape((3,34,2)) # 2 people\n",
    "# X_to_test2 = np.asarray([np.asarray([np.asarray([p[0]+i+100, p[1]+i+100]) for i,p in enumerate(f)]) for f in X_to_test2])\n",
    "\n",
    "# # X_to_test3 = np.ones(3*17*2).reshape((3,17,2)) # 1 person\n",
    "# # X_to_test3 = np.asarray([np.asarray([np.asarray([p[0]+i+200, p[1]+i+200]) for i,p in enumerate(f)]) for f in X_to_test3])\n",
    "\n",
    "# # X_to_test = np.asarray([X_to_test1, X_to_test2, X_to_test3])\n",
    "# X_to_test = np.asarray([X_to_test1, X_to_test2])\n",
    "\n",
    "# print(X_to_test)\n",
    "# print(relativeTo3GlobalBaricentersOfVideo(X_to_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeTo3PersonalBaricentersOfVideo(X):\n",
    "    print(\"Adapting the data wrt to the 3 PERSONAL BARICENTERS of each VIDEO\")\n",
    "    \n",
    "    for i_video,frames in enumerate(X):        \n",
    "        videoUpperMeanP1 = np.mean([np.mean(features[:5], axis=0) for features in frames], axis = 0) \n",
    "        videoMiddleMeanP1 = np.mean([np.mean(features[5:11], axis=0) for features in frames], axis = 0) \n",
    "        videoBottomMeanP1 = np.mean([np.mean(features[11:17], axis=0) for features in frames], axis = 0) \n",
    "        if len(frames[0]) == 34:\n",
    "            videoUpperMeanP2 = np.mean([np.mean(features[17:22], axis=0) for features in frames], axis = 0) \n",
    "            videoMiddleMeanP2 = np.mean([np.mean(features[22:28], axis=0) for features in frames], axis = 0) \n",
    "            videoBottomMeanP2 = np.mean([np.mean(features[28:34], axis=0) for features in frames], axis = 0) \n",
    "        \n",
    "        for i_frame, frame in enumerate(frames):\n",
    "            X[i_video][i_frame][:5] = frame[:5] - videoUpperMeanP1\n",
    "            X[i_video][i_frame][5:11] = frame[5:11] - videoMiddleMeanP1\n",
    "            X[i_video][i_frame][11:17] = frame[11:17] - videoBottomMeanP1\n",
    "            if len(frame) == 34:\n",
    "                X[i_video][i_frame][17:22] = frame[17:22] - videoUpperMeanP2\n",
    "                X[i_video][i_frame][22:28] = frame[22:28] - videoMiddleMeanP2\n",
    "                X[i_video][i_frame][28:34] = frame[28:34] - videoBottomMeanP2\n",
    "                \n",
    "    return X\n",
    "\n",
    "def relativeTo3GlobalBaricentersOfVideo(X):\n",
    "    print(\"Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\")\n",
    "    \n",
    "    for i_video,frames in enumerate(X):        \n",
    "        upperMean = np.mean([np.mean(features[:5], axis=0) for features in frames], axis = 0) \n",
    "        middleMean = np.mean([np.mean(features[5:11], axis=0) for features in frames], axis = 0) \n",
    "        bottomMean = np.mean([np.mean(features[11:17], axis=0) for features in frames], axis = 0) \n",
    "        if len(frames[0]) == 34:\n",
    "            upperMeanP2 = np.mean([np.mean(features[17:22], axis=0) for features in frames], axis = 0) \n",
    "            middleMeanP2 = np.mean([np.mean(features[22:28], axis=0) for features in frames], axis = 0) \n",
    "            bottomMeanP2 = np.mean([np.mean(features[28:34], axis=0) for features in frames], axis = 0) \n",
    "            upperMean = (upperMean + upperMeanP2)/2.\n",
    "            middleMean = (middleMean+middleMeanP2)/2.\n",
    "            bottomMean = (bottomMean+bottomMeanP2)/2.\n",
    "        \n",
    "        for i_frame, frame in enumerate(frames):\n",
    "            X[i_video][i_frame][:5] = frame[:5] - upperMean\n",
    "            X[i_video][i_frame][5:11] = frame[5:11] - middleMean\n",
    "            X[i_video][i_frame][11:17] = frame[11:17] - bottomMean\n",
    "            if len(frame) == 34:\n",
    "                X[i_video][i_frame][17:22] = frame[17:22] - upperMean\n",
    "                X[i_video][i_frame][22:28] = frame[22:28] - middleMean\n",
    "                X[i_video][i_frame][28:34] = frame[28:34] - bottomMean\n",
    "                \n",
    "    return X\n",
    "\n",
    "def relativeTo3PersonalBaricentersOfVideoAbs(X):\n",
    "    print(\"Adapting the data as the ABSOLUTE values wrt the 3 PERSONAL BARICENTERS of each VIDEO \")\n",
    "    return abs(relativeTo3PersonalBaricentersOfVideo(X))\n",
    "\n",
    "def relativeTo3GlobalBaricentersOfVideoAbs(X):\n",
    "    print(\"Adapting the data as the ABSOLUTE values wrt the 3 GLOBAL BARICENTERS of each VIDEO \")\n",
    "    return abs(relativeTo3GlobalBaricentersOfVideo(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeTo17BaricentersOfVideo(X):\n",
    "    print(\"Adapting the data as the difference to the center of EACH KEYPOINT in the VIDEO\")   \n",
    "    for i_video,frames in enumerate(X): \n",
    "        video_mean_by_points = np.mean(X[i_video],axis=0)\n",
    "        X[i_video] = X[i_video] - video_mean_by_points\n",
    "    return X\n",
    "\n",
    "def relativeTo17BaricentersOfVideoAbs(X):\n",
    "    return abs(relativeTo17BaricentersOfVideo(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relativeToNextFrameOLD(X):\n",
    "#     print(\"Adapting the data to the next frame\")\n",
    "#     newX = []\n",
    "#     for frames in X:\n",
    "#         motions = []\n",
    "#         for i in range(len(frames)-1):\n",
    "#             motions.append(np.array(frames[i+1])-np.array(frames[i]))\n",
    "#         newX.append(motions)\n",
    "#     return np.array(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builder function which return a function to calculate the difference each N frames\n",
    "def relativeToNextFrameBuilder(step):\n",
    "    step = step\n",
    "    \n",
    "    # it smooths the dataset following the Savitzky-Golay algorithm\n",
    "    def relativeToNextFrame(X):\n",
    "        print(\"Adapting the data to the next\",step,\"frame\")\n",
    "        newX = []\n",
    "        for frames in X:\n",
    "            # repeat the last frame of the video as much as the number of steps\n",
    "            frames = np.concatenate((frames,np.repeat(np.expand_dims(frames[-1],axis=0),step,axis=0)))\n",
    "            motions = np.array([frames[i+step]-frames[i] for i in range(len(frames)-step-1)])\n",
    "            newX.append(motions)\n",
    "        return np.array(newX)\n",
    "    \n",
    "    if step>1:\n",
    "        relativeToNextFrame.__name__ = \"relativeToNextFrame_\"+str(step)\n",
    "    return relativeToNextFrame\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulativeDifferences(X):\n",
    "        print(\"Adapting the data as the CUMULATIVE DIFFERENCES of consecutive frames\")\n",
    "        newX = []\n",
    "        for frames in X:\n",
    "            motions = frames - frames[0]\n",
    "            newX.append(motions)\n",
    "        return np.array(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euclDistance(point1,point2):\n",
    "    return math.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)\n",
    "\n",
    "def relativeToPointDistances(X):\n",
    "    print(\"Adapting the data to the DISTANCES between points of each person in each FRAME\")\n",
    "    newX = []\n",
    "    for videoIdx,video in enumerate(X):\n",
    "        if videoIdx % 100 == 0:\n",
    "            print(\"{}/{} video done\".format(videoIdx,len(X)))\n",
    "        \n",
    "        videoDistances = np.zeros((len(video),len(video[0]),17))\n",
    "        \n",
    "        for fIdx, frame in enumerate(video):\n",
    "            distances = [[euclDistance(frame[i],frame[j]) for j in range(17)] for i in range(17)]\n",
    "            if len(frame) == 34:\n",
    "                distancesP2 = [[euclDistance(frame[i],frame[j]) for j in range(17,34)] for i in range(17,34)]\n",
    "                distances = np.concatenate((distances,distancesP2),axis = 0)\n",
    "            videoDistances[fIdx] = distances\n",
    "        \n",
    "        newX.append(videoDistances)\n",
    "    return np.array(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(train_set, val_set, test_set, preprocess_functions = None, normaliseDatasetGlobally = False):\n",
    "    X_train, X_val, X_test = train_set[0], val_set[0], test_set[0]\n",
    "    # one hot encoding\n",
    "    y_train, encoding_train = one_hot_encoding(train_set[1])\n",
    "    y_val, encoding_val = one_hot_encoding(val_set[1])\n",
    "    y_test, encoding_test = one_hot_encoding(test_set[1])\n",
    "    \n",
    "    assert all(encoding_train == encoding_val)\n",
    "    assert all(encoding_val == encoding_test)\n",
    "\n",
    "    # preprocess\n",
    "    if preprocess_functions is not None:\n",
    "        for preprocess_function in preprocess_functions:\n",
    "            X_train = preprocess_function(X_train)\n",
    "            X_val = preprocess_function(X_val)\n",
    "            X_test = preprocess_function(X_test)\n",
    "            \n",
    "    # global normalization of dataset\n",
    "    # avoid this normalization if already normalized the videos individually\n",
    "    if normaliseDatasetGlobally:\n",
    "        X_train, X_val, X_test = normaliseWholeDataset(X_train,X_val,X_test)\n",
    "\n",
    "    #padding\n",
    "    X_train, X_val, X_test = paddingTrainValTest(X_train, X_val, X_test)\n",
    "\n",
    "    \n",
    "    ## reshaping after padding ###\n",
    "    X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2] * X_train.shape[3])\n",
    "    X_val = X_val.reshape(X_val.shape[0],X_val.shape[1],X_val.shape[2] * X_val.shape[3])\n",
    "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2] * X_test.shape[3])\n",
    "    \n",
    "#     ## reshaping without padding ###\n",
    "#     for dataset in [X_train, X_val, X_test]:\n",
    "#         for i in range(len(dataset)):\n",
    "#             dataset[i] = dataset[i].reshape(dataset[i].shape[0], \n",
    "#                                             dataset[i].shape[1] * dataset[i].shape[2])\n",
    "\n",
    "    encoding_train = [int(i) for i in encoding_train]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, encoding_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "# builder function which returs a Savitzky-Golay smoother function with the passed arguments\n",
    "def smoothingPoints(window, order):\n",
    "    movingWindow = window\n",
    "    polynomialOrder = order\n",
    "    \n",
    "    # it smooths the dataset following the Savitzky-Golay algorithm\n",
    "    def smooth(X):\n",
    "        for vidIdx, video in enumerate(X):\n",
    "            if vidIdx % 500 == 0:\n",
    "                print(\"smooting video {}/{}\".format(vidIdx,len(X)))\n",
    "            for p in range(len(X[0][0])): # X[0][0] == 17 or 34 -> the number of points\n",
    "                x, y = zip(*[(f[p][0], f[p][1]) for f in video])\n",
    "                \n",
    "                #     Savitzky-Golay\n",
    "                smooth_x = signal.savgol_filter(x, movingWindow, polynomialOrder)\n",
    "                smooth_y = signal.savgol_filter(y, movingWindow, polynomialOrder)\n",
    "                \n",
    "                # placing the smoothed series\n",
    "                for i,frame in enumerate(video):\n",
    "                    frame[p] = [smooth_x[i], smooth_y[i]]\n",
    "        return X\n",
    "    \n",
    "    smooth.__name__ = \"smooth_\"+str(window)+\"_\"+str(order)\n",
    "        \n",
    "    return smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print(\"#### Loading dataset: \", datasetName)\n",
    "# train_set, val_set, test_set = getData(datasetName)\n",
    "# print(\"Preproccesing dataset...\")\n",
    "\n",
    "# ##### DATA AUGMENTATION #####\n",
    "# X_AXIS = 1 if modelName == \"PoseNet-101\" else 0\n",
    "# train_set = augmentData(train_set, xAxis = X_AXIS, mirroring = mirroring, std_jittering = std_jittering)\n",
    "# # val_set = augmentData(val_set, xAxis = X_AXIS, mirroring = mirroring, std_jittering = std_jittering)\n",
    "\n",
    "# # X_train, y_train, X_val, y_val, X_test, y_test, encodingLabels = preprocessData(train_set, \n",
    "# #                                                                                val_set, \n",
    "# #                                                                                test_set,  \n",
    "# #                                                                                preprocess_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from random import gauss\n",
    "\n",
    "def augmentData(dataset, xAxis = None, mirroring = False, std_jittering = 0):\n",
    "    X = dataset[0]\n",
    "    y = dataset[1]\n",
    "    setups = dataset[2] \n",
    "    cameras = dataset[3]\n",
    "    performers = dataset[4]\n",
    "    replications = dataset[5]\n",
    "\n",
    "    coordinates = [y, setups, cameras, performers, replications]\n",
    "    \n",
    "    print(\"## OLD LENGHT OF DATSET:\",len(X))\n",
    "    \n",
    "    # check that the X and labels have the same length\n",
    "    assert len(X) == len(y)\n",
    "    \n",
    "    # MIRRORING\n",
    "    if mirroring:\n",
    "        print(\"## Applying MIRRORING to dataset...\")\n",
    "        if xAxis == 0:\n",
    "            mirrX = np.asarray([ np.asarray([ np.asarray([ np.asarray([-p[0],p[1]],dtype=np.float32) for p in f]) for f in v]) for v in X])\n",
    "        elif xAxis == 1:\n",
    "            mirrX = np.asarray([ np.asarray([ np.asarray([ np.asarray([p[0],-p[1]],dtype=np.float32) for p in f]) for f in v]) for v in X])\n",
    "        else:\n",
    "            raise Exception(\"xAxis can be only 0 or 1\")\n",
    "\n",
    "        X = np.concatenate((X,mirrX))\n",
    "        coordinates = np.concatenate((coordinates,coordinates),axis=1)\n",
    "    \n",
    "    \n",
    "    # JITTERING\n",
    "    if std_jittering > 0:\n",
    "        print(\"## Applying JITTERING to dataset...\")\n",
    "        jitterX = np.asarray([np.asarray([ np.asarray([ \n",
    "                                np.asarray([p[0]+gauss(0,std_jittering), p[1]+gauss(0,std_jittering)], dtype=np.float32) for p in f]) \n",
    "                              for f in v]) for v in X])\n",
    "        \n",
    "        X = np.concatenate((X,jitterX))\n",
    "#         y = np.concatenate((y,y))\n",
    "        coordinates = np.concatenate((coordinates,coordinates),axis=1)\n",
    "    \n",
    "    print(\"## NEW LENGHT OF DATSET:\",len(X))\n",
    "    \n",
    "    return [X,*coordinates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 MIRRORING_VALUES: [False, True]\n",
      "1 STD_JITTERING_VALUES: [0]\n",
      "CuDNNLSTM\n",
      "2 MODEL_NAME_VALUES: ['PoseNet-101', 'keypoint_rcnn_X_101_32x8d_FPN_3x']\n",
      "1 LSTM_LAYERS_VALUES LAYERS: [3]\n",
      "1 HIDDEN UNITS [64]\n",
      "1 REGULARIZER_VALUES [1e-05]\n",
      "1 DROPOUT_VALUES [0.15]\n",
      "4 PREPROCESS_FUNCTION_TO_TEST\n",
      "\n",
      "!! MERGING TECNIQUES !!\n",
      "\n",
      "!!!! MERGING TRAIN+VAL !!!!\n",
      "\n",
      "EPOCHS: 2000\n",
      "REFERENCE_EPOCHS: 250\n",
      "PATIENCE: 100\n",
      "\n",
      "1 LEARNING_RATE_VALUES [0.01]\n",
      "polynomialScheduler\n",
      "LR_OFFSET: 0.001\n",
      "LR_POWER: 2\n",
      "BATCH_SIZE: 600\n",
      "CONTINUE_TRAINING: None\n",
      "\n",
      "Number of tests: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/',\n",
       " 'Cross_subject/',\n",
       " 'Cross_view/')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVED_MODEL_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/\"\n",
    "DATASET_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/\"\n",
    "\n",
    "# DATASET_FOLDER = \"/content/gdrive/My Drive/actionAnalysis/datasets/\"\n",
    "# SAVED_MODEL_FOLDER = \"/content/gdrive/My Drive/actionAnalysis/savedModels/\"\n",
    "      \n",
    "folder_where_save1 = \"Cross_subject/\"\n",
    "folder_where_save2 = \"Cross_view/\"        \n",
    "\n",
    "# folder_where_save1 = \"Cross_view_lrScan/\"        \n",
    "# folder_where_save1 = \"Cross_subject_lrScan/\"     \n",
    "# folder_where_save2 = \"Cross_subject_lrScan/\"\n",
    "# SCAN_EPOCHS = 10\n",
    "\n",
    "# folder_where_save1 = \"Cross_view_tough/\" \n",
    "# folder_where_save2 = \"Cross_view_tough/\" \n",
    "\n",
    "# folder_where_save1 = \"Cross_subject_tough/\"\n",
    "# folder_where_save2 = \"Cross_view_tough/\"\n",
    "\n",
    "# folder_where_save1 = \"Cross_view_test/\" \n",
    "# folder_where_save2 = \"Cross_subject_test/\"\n",
    "\n",
    "# folder_where_save1 = \"Cross_view_mini/\"     \n",
    "# folder_where_save2 = \"Cross_subject_mini/\"  \n",
    "\n",
    "# folder_where_save1 = \"Senesi/\"\n",
    "# folder_where_save2 = \"Cross_subject/\"\n",
    "\n",
    "# folder_where_save1 = \"Cross_view/\"\n",
    "# folder_where_save2 = \"top-models/\"\n",
    "\n",
    "\n",
    "MODEL_NAME_VALUES = [\n",
    "    \"PoseNet-101\",\n",
    "    \"keypoint_rcnn_X_101_32x8d_FPN_3x\"\n",
    "    \n",
    "    ]\n",
    "\n",
    "CONTINUE_TRAINING = None\n",
    "# CONTINUE_TRAINING = \"keypoint_rcnn_X_101_32x8d_FPN_3x-3L-HU_64-LR_0.01-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-THEN_drop_0.05\"\n",
    "\n",
    "MERGING_TRAIN_VAL = True\n",
    "\n",
    "MERGE_TECHNIQUES = True\n",
    "PREPROCESS_FUNCTION_TO_TEST = [\n",
    "      (folder_where_save1,[\n",
    "          ([removeZerosFromDataset,normalizeVideosXYInpid,relativeToNextFrameBuilder(3)],True),\n",
    "          ([removeZerosFromDataset,relativeTo3GlobalBaricentersOfVideo],True)\n",
    "      ]),\n",
    "    \n",
    "      (folder_where_save2,[\n",
    "          ([removeZerosFromDataset,normalizeVideosXYInpid,relativeToNextFrameBuilder(3)],True),\n",
    "          ([removeZerosFromDataset,relativeTo3GlobalBaricentersOfVideo],True)\n",
    "      ]),\n",
    "    \n",
    "      (folder_where_save1,[\n",
    "          ([removeZerosFromDataset,normalizeVideosXYInpid,relativeToNextFrameBuilder(3)],True),\n",
    "          ([removeZerosFromDataset,normalizeVideosXYInpid,relativeTo3GlobalBaricentersOfVideo],True)\n",
    "      ]),\n",
    "    \n",
    "      (folder_where_save2,[\n",
    "          ([removeZerosFromDataset,normalizeVideosXYInpid,relativeToNextFrameBuilder(3)],True),\n",
    "          ([removeZerosFromDataset,normalizeVideosXYInpid,relativeTo3GlobalBaricentersOfVideo],True)\n",
    "      ])\n",
    "    \n",
    "]\n",
    "\n",
    "PATIENCE = 100\n",
    "HIDDEN_UNITS_VALUES = [64]\n",
    "\n",
    "#                         [0.04,0.039,0.038,0.037,0.036,0.035,0.034,0.033,0.032,0.031,\n",
    "#                         0.03,0.029,0.028,0.027,0.026,0.025,0.024,0.023,0.022,0.021,\n",
    "#                         0.02,0.019,0.018,0.017,0.016,0.015,0.014,0.013,0.012,0.011,\n",
    "#                         0.01,0.009,0.008,0.007,0.006,0.005,0.004,0.003,0.002,0.001]\n",
    "BATCH_SIZE = 600\n",
    "REFERENCE_EPOCHS = 250 #the earlystop will eventually stop the training\n",
    "EPOCHS = 2000\n",
    "\n",
    "MIRRORING_VALUES = [False,True]\n",
    "STD_JITTERING_VALUES = [0]\n",
    "\n",
    "\n",
    "USE_SCHEDULER = True\n",
    "LEARNING_RATE_VALUES = [0.01]\n",
    "\n",
    "###### POLYNOMIAL SCHEDULER #############\n",
    "LR_OFFSET = 0.001\n",
    "LR_POWER = 2\n",
    "def polynomialScheduler(epoch, lr):\n",
    "    if epoch < REFERENCE_EPOCHS:\n",
    "        decay = (1 - (epoch / float(REFERENCE_EPOCHS)))  ** LR_POWER\n",
    "        alpha = LEARNING_RATE * decay\n",
    "        return float(alpha)+LR_OFFSET\n",
    "    else:\n",
    "        return LR_OFFSET\n",
    "scheduler = polynomialScheduler\n",
    "##########################################\n",
    "\n",
    "USE_LSTM = False\n",
    "USE_CuDNNLSTM = not USE_LSTM\n",
    "\n",
    "REGULARIZER_VALUES = [0.00001]  \n",
    "\n",
    "DROPOUT_VALUES = [0.15] # [] == don't load\n",
    "\n",
    "LOAD_FROM_PREVIOUS_DROPOUT = [] # [] == don't load\n",
    "\n",
    "LSTM_LAYERS_VALUES = [3]\n",
    "# PREPROCESS_FUNCTION_TO_TEST = [\n",
    "    \n",
    "# #      (folder_where_save1,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideo,normalizeVideos])\n",
    "# #      ,(folder_where_save2,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideo,normalizeVideos])\n",
    "    \n",
    "#      (folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(1),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(1),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(3),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(3),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(7),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(7),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(15),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(15),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToFrameCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToFrameCenter,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToPersonFrameCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToPersonFrameCenter,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToVideoCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToVideoCenter,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToPersonVideoCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToPersonVideoCenter,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,cumulativeDifferences,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,cumulativeDifferences,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideoAbs,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideoAbs,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideoAbs,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideoAbs,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo17BaricentersOfVideo,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo17BaricentersOfVideo,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo17BaricentersOfVideoAbs,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo17BaricentersOfVideoAbs,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToPointDistances,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToPointDistances,normalizeVideos])\n",
    "    \n",
    "    \n",
    "    \n",
    "# #      ,(folder_where_save1,[])\n",
    "# #      ,(folder_where_save2,[])\n",
    "# #      ,(folder_where_save1,[normalizeVideos])\n",
    "# #      ,(folder_where_save2,[normalizeVideos])\n",
    "#      ,(folder_where_save1,[normalizeVideosXYInpid])\n",
    "#      ,(folder_where_save2,[normalizeVideosXYInpid])\n",
    "# #      ,(folder_where_save1,[removeZerosFromDataset,normalizeVideos])\n",
    "# #      ,(folder_where_save2,[removeZerosFromDataset,normalizeVideos])\n",
    "# #      ,(folder_where_save1,[removeZerosFromDataset,normalizeVideosXYInpid])\n",
    "# #      ,(folder_where_save2,[removeZerosFromDataset,normalizeVideosXYInpid])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo3GlobalBaricentersOfVideo,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo3GlobalBaricentersOfVideo,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo5GlobalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo5GlobalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "    \n",
    "     \n",
    "#     # TECNIQUES\n",
    "\n",
    "# # relativeToVideoCenter\n",
    "# # relativeToPersonVideoCenter\n",
    "# # relativeToFrameCenter\n",
    "# # relativeToPersonFrameCenter\n",
    "# # relativeTo5BaricentersNTURGBofVideo\n",
    "# # relativeTo5BaricentersNTURGBofVideoAbs\n",
    "# # relativeTo3BaricentersOfVideo\n",
    "# # relativeTo3BaricentersOfVideoAbs\n",
    "# # relativeTo17BaricentersOfVideo\n",
    "# # relativeTo17BaricentersOfVideoAbs\n",
    "# # relativeToNextFrameBuilder(1)\n",
    "# # relativeToNextFrameBuilder(3)\n",
    "# # relativeToNextFrameBuilder(7)\n",
    "# # relativeToNextFrameBuilder(15)\n",
    "# # cumulativeDifferences\n",
    "# # relativeToPointDistances\n",
    "# ]\n",
    "\n",
    "if USE_LSTM:\n",
    "    REGULARIZER_VALUES = [0]\n",
    "if not USE_SCHEDULER:\n",
    "    LR_OFFSET = 0\n",
    "    LR_POWER = 0\n",
    " \n",
    "    \n",
    "print(len(MIRRORING_VALUES),\"MIRRORING_VALUES:\", MIRRORING_VALUES)\n",
    "print(len(STD_JITTERING_VALUES),\"STD_JITTERING_VALUES:\", STD_JITTERING_VALUES)\n",
    "print(\"NORMAL LSTM\" if USE_LSTM else \"CuDNNLSTM\")\n",
    "print(len(MODEL_NAME_VALUES),\"MODEL_NAME_VALUES:\", MODEL_NAME_VALUES)\n",
    "print(len(LSTM_LAYERS_VALUES),\"LSTM_LAYERS_VALUES LAYERS:\", LSTM_LAYERS_VALUES)\n",
    "print(len(HIDDEN_UNITS_VALUES), \"HIDDEN UNITS\",HIDDEN_UNITS_VALUES)\n",
    "print(len(REGULARIZER_VALUES),\"REGULARIZER_VALUES\",REGULARIZER_VALUES)\n",
    "print(len(DROPOUT_VALUES),\"DROPOUT_VALUES\",DROPOUT_VALUES)\n",
    "print(len(PREPROCESS_FUNCTION_TO_TEST),\"PREPROCESS_FUNCTION_TO_TEST\")\n",
    "\n",
    "\n",
    "numberOfTests = len(MIRRORING_VALUES) * len(STD_JITTERING_VALUES) * len(MODEL_NAME_VALUES)* len(LEARNING_RATE_VALUES)*len(HIDDEN_UNITS_VALUES) * len(PREPROCESS_FUNCTION_TO_TEST)*len(DROPOUT_VALUES)*len(REGULARIZER_VALUES)*len(LSTM_LAYERS_VALUES)\n",
    "print()\n",
    "if MERGE_TECHNIQUES:\n",
    "    print(\"!! MERGING TECNIQUES !!\\n\")\n",
    "    \n",
    "if MERGING_TRAIN_VAL:\n",
    "    print(\"!!!! MERGING TRAIN+VAL !!!!\\n\")\n",
    "    \n",
    "    \n",
    "print(\"EPOCHS:\", EPOCHS)\n",
    "print(\"REFERENCE_EPOCHS:\", REFERENCE_EPOCHS)\n",
    "print(\"PATIENCE:\", PATIENCE)\n",
    "print()\n",
    "    \n",
    "print(len(LEARNING_RATE_VALUES),\"LEARNING_RATE_VALUES\",LEARNING_RATE_VALUES)\n",
    "if USE_SCHEDULER:\n",
    "#     print(\"\\nUSE_SCHEDULER\\n\\tDECAY_RATE:\", DECAY_RATE, \"\\n\\tDECAY_STEP:\", DECAY_STEP)\n",
    "    print(scheduler.__name__)\n",
    "    print(\"LR_OFFSET:\",LR_OFFSET)\n",
    "    print(\"LR_POWER:\",LR_POWER)\n",
    "print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "print(\"CONTINUE_TRAINING:\",CONTINUE_TRAINING)\n",
    "print(\"\\nNumber of tests:\", numberOfTests)\n",
    "SAVED_MODEL_FOLDER, folder_where_save1, folder_where_save2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequential trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanForExcel(text):\n",
    "    replacements = (\n",
    "        (\"relativeToVideoCenter\",\"VIDEO\"),\n",
    "        (\"relativeToPersonVideoCenter\",\"VIDEO_PERS\"),        \n",
    "        (\"relativeToFrameCenter\",\"FRAME\"),        \n",
    "        (\"relativeToPersonFrameCenter\",\"FRAME_PERS\"),  \n",
    "        (\"relativeTo3BaricentersOfVideo\",\"3BAR_PERS\"), \n",
    "        (\"relativeTo3GlobalBaricentersOfVideo\",\"3BAR_GLOB\"),\n",
    "        (\"relativeTo3PersonalBaricentersOfVideo\",\"3BAR_PERS\"),\n",
    "        \n",
    "        (\"relativeToUpperMiddleBottomCentersOfVideo\",\"3BAR\"),        \n",
    "        (\"relativeTo5BaricentersNTURGBofVideo\",\"5BAR_OLD\"),      \n",
    "        (\"relativeTo5PersonalBaricentersNTURGBofVideo\",\"5BAR_PERS\"),\n",
    "        (\"relativeTo5GlobalBaricentersNTURGBofVideo\",\"5BAR_GLOB\"),\n",
    "        \n",
    "        (\"relativeTo17BaricentersOfVideo\",\"17BAR\"),\n",
    "        (\"relativeToPointDistances\",\"DIST_REL\"),\n",
    "        (\"relativeToNextFrame\",\"NEXT\"),\n",
    "        (\"cumulativeDifferences\",\"DIST_CUM\"),\n",
    "        (\"removeZerosFromDataset\",\"rimoz_0\"), \n",
    "        (\"normalizeVideosXYInpid\",\"normXY\"),\n",
    "        (\"normalizeVideos\",\"norm\"),     \n",
    "        (\"Abs\",\"_ASS\"),    \n",
    "        (\"CuDNNLSTM\",\"cuda\"),\n",
    "        (\".pickle\",\"\"),\n",
    "        (\".h5\",\"\"),\n",
    "        (\".\",\",\"),\n",
    "        (\"PoseNet-101\",\"pos\"),\n",
    "        (\"keypoint_rcnn_X_101_32x8d_FPN_3x\",\"det\"),\n",
    "        (\"-drop-0-\",\"-\"),\n",
    "        (\"-rec_drop-0-\",\"-\"),\n",
    "        (\"-reg-0#\",\"\"),\n",
    "        (\"-reg-0-\",\"-\"),\n",
    "        (\"#\",\"\")\n",
    "    )\n",
    "    text = text+\"#\"\n",
    "    for r in replacements:\n",
    "        text = text.replace(*r)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSaveFileName(modelName,preprocess_functions,learning_rate, offset, power, numberOfLSTMLayers, useCudaLSTM, hiddenUnits, regularizerValue, dropOut, recurrentDropOut, std_jittering, mirroring, preprocess_functions_2 = None, normalizeGlobally1 = False, normalizeGlobally2 = False):\n",
    "                                                                   \n",
    "    saveFileName = modelName+\"-{}L\".format(numberOfLSTMLayers+1)\n",
    "    saveFileName += \"-CuDNNLSTM\" if useCudaLSTM else \"\"\n",
    "    saveFileName += \"-HU_\"+str(hiddenUnits)\n",
    "    saveFileName += \"-LR_\"+str(learning_rate)\n",
    "    saveFileName += \"-OFF_\"+str(offset)\n",
    "    saveFileName += \"-POW_\"+str(power)\n",
    "    saveFileName += \"-MIRR\" if mirroring else \"\"\n",
    "    saveFileName += \"-STD_JIT_\"+str(std_jittering) if std_jittering>0 else \"\" \n",
    "               \n",
    "    if preprocess_functions is not None:\n",
    "        for function in preprocess_functions:\n",
    "            saveFileName += \"-{}\".format(function.__name__)\n",
    "    if normalizeGlobally1:\n",
    "        saveFileName += \"-glob_norm1\"    \n",
    "        \n",
    "    \n",
    "    if preprocess_functions_2 is not None:\n",
    "        saveFileName += \"-MERGED\"\n",
    "        for function in preprocess_functions_2:\n",
    "            saveFileName += \"-{}\".format(function.__name__)                              \n",
    "        if normalizeGlobally2:\n",
    "            saveFileName += \"-glob_norm2\"\n",
    "    \n",
    "   \n",
    "    saveFileName += \"-drop-\"+str(dropOut)\n",
    "    \n",
    "    if useCudaLSTM:\n",
    "        saveFileName += \"-reg-\"+str(regularizerValue)\n",
    "    else:\n",
    "        saveFileName += \"-rec_drop-\"+str(recurrentDropOut)\n",
    "    \n",
    "    return cleanForExcel(saveFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type(model) \n",
    "# isinstance(model, keras.engine.training.Model)\n",
    "\n",
    "# # y_val_pred = [label_order[i] for i in model.predict(X_val)]\n",
    "# result = model.predict(X_val)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmax(result), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def getValTestAccuracy(model, x_val,y_val,x_test,y_test, label_order = None):\n",
    "    if label_order is None:\n",
    "        raise Exception(\"define label order for val test accuracy evaluation\")\n",
    "    if isinstance(model, keras.engine.training.Model):\n",
    "        y_val_pred = [label_order[np.argmax(i)] for i in model.predict(x_val)]\n",
    "    else:\n",
    "        y_val_pred = [label_order[i] for i in model.predict_classes(x_val)]\n",
    "\n",
    "    y_val_true = [label_order[np.argmax(i)] for i in y_val]\n",
    "    \n",
    "    if isinstance(model, keras.engine.training.Model):\n",
    "        y_test_pred = [label_order[np.argmax(i)] for i in model.predict(x_test)]\n",
    "    else:\n",
    "        y_test_pred = [label_order[i] for i in model.predict_classes(x_test)]\n",
    "        \n",
    "    y_test_true = [label_order[np.argmax(i)] for i in y_test]\n",
    "    val_acc = accuracy_score(y_pred=y_val_pred,y_true=y_val_true)\n",
    "    test_acc = accuracy_score(y_pred=y_test_pred,y_true=y_test_true)\n",
    "    return val_acc, test_acc, y_val_true, y_val_pred, y_test_true, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetName(folderPathWhereToSave, modelName, datasetFolder = DATASET_FOLDER):\n",
    "\n",
    "    if folderPathWhereToSave.endswith(\"Senesi/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-SPLIT-SENESI-dataset.pickle\"\n",
    "    elif folderPathWhereToSave.endswith(\"top-models/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-SPLIT-dataset.pickle\"      \n",
    "\n",
    "    elif folderPathWhereToSave.endswith(\"Cross_subject_test/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_SUBJECT_TEST-dataset.pickle\"            \n",
    "    elif folderPathWhereToSave.endswith(\"Cross_view_test/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_VIEW_TEST-dataset.pickle\"     \n",
    "\n",
    "    elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_subject/\",\"Cross_subject_lrScan/\"]]):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_SUBJECT-dataset.pickle\"       \n",
    "    elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_view/\",\"Cross_view_lrScan/\"]]):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_VIEW-dataset.pickle\"  \n",
    "\n",
    "    elif folderPathWhereToSave.endswith(\"Cross_view_tough/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_VIEW_TOUGH-dataset.pickle\"            \n",
    "    elif folderPathWhereToSave.endswith(\"Cross_subject_tough/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_SUBJECT_TOUGH-dataset.pickle\" \n",
    "\n",
    "    elif folderPathWhereToSave.endswith(\"Cross_view_mini/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_VIEW_MINI-dataset.pickle\"            \n",
    "    elif folderPathWhereToSave.endswith(\"Cross_subject_mini/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_SUBJECT_MINI-dataset.pickle\"    \n",
    "\n",
    "    elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_view/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_VIEW_TOP+SENESI-dataset.pickle\"            \n",
    "    elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_subject/\"):\n",
    "        datasetName = datasetFolder+modelName+\"-CROSS_SUBJECT_TOP+SENESI-dataset.pickle\" \n",
    "\n",
    "    elif folderPathWhereToSave.endswith(\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset)/\") and MODEL_NAME == \"PoseNet-101\":\n",
    "        datasetName = datasetFolder+modelName+\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset.pickle\"\n",
    "    else:\n",
    "        raise Exception(\"result folder not correct\")\n",
    "    \n",
    "    return datasetName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreprocessedDataset(datasetName, modelName, mirroring, std_jittering, preprocess_functions, normaliseDatasetGlobally=False, datasetFolder = DATASET_FOLDER):\n",
    "    ### CHECK IF ALREADY PREPROCESSED DATASET EXISTS\n",
    "    preprocessed_datasetName = basename(datasetName).replace(\"-dataset.pickle\",\"\")\n",
    "    for f in preprocess_functions:\n",
    "        preprocessed_datasetName += \"-\"+f.__name__\n",
    "    preprocessed_datasetName += \"-dataset.pickle\"\n",
    "\n",
    "    preprocessed_datasetPath = datasetFolder+preprocessed_datasetName\n",
    "\n",
    "    # print(\"###### NOT CHECKING IF THERE IS A PREPROCCED DATASET ######\")\n",
    "    # if False:\n",
    "    if exists(preprocessed_datasetPath):\n",
    "        print(\"#### Loading preprocessed dataset: \", preprocessed_datasetPath)\n",
    "        with open(preprocessed_datasetPath,'rb') as file_in:\n",
    "            prepDict = pickle.load(file_in)\n",
    "            X_train = prepDict[\"X_train\"]\n",
    "            y_train = prepDict[\"y_train\"]\n",
    "            X_val = prepDict[\"X_val\"]\n",
    "            y_val = prepDict[\"y_val\"]\n",
    "            X_test = prepDict[\"X_test\"]\n",
    "            y_test = prepDict[\"y_test\"]\n",
    "            encodingLabels = prepDict[\"encodingLabels\"]\n",
    "    else:\n",
    "        print(\"#### Loading dataset: \", datasetName)\n",
    "        train_set, val_set, test_set = getData(datasetName)\n",
    "        print(\"Preproccesing dataset...\")\n",
    "\n",
    "        ##### DATA AUGMENTATION #####\n",
    "        X_AXIS = 1 if modelName == \"PoseNet-101\" else 0\n",
    "        train_set = augmentData(train_set, xAxis = X_AXIS, mirroring = mirroring, std_jittering = std_jittering)\n",
    "        val_set = augmentData(val_set, xAxis = X_AXIS, mirroring = mirroring, std_jittering = std_jittering)\n",
    "\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test, encodingLabels = preprocessData(train_set, \n",
    "                                                                                       val_set, \n",
    "                                                                                       test_set,  \n",
    "                                                                                       preprocess_functions,\n",
    "                                                                                       normaliseDatasetGlobally)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, encodingLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sampleGenerator(X_1, y_1, X_2, y_2, batch_size, isTraining = None):\n",
    "    # check that the 2 passed datasets are combinable\n",
    "    assert len(X_1) == len(X_2)\n",
    "    assert len(y_1) == len(y_2)\n",
    "    assert all([all(y1==y2) for (y1,y2) in zip(y_1, y_2)])\n",
    "    name = \"TRAINING\" if isTraining else \"VALIDATION\"\n",
    "    \n",
    "    # TO SOLVE THE DROPOUT LAYER SHAPE PROBLEM\n",
    "    missing_train = (batch_size - (len(X_1) % batch_size)) % batch_size\n",
    "    print (\"## {} len of data {} - batch size {}\".format(name, len(X_1), batch_size))\n",
    "    print (\"## {} missing_train = {}\".format(name, missing_train))\n",
    "#     X_1 = np.concatenate((X_train1, X_train1[:missing_train]), axis=0)\n",
    "#     X_2 = np.concatenate((X_train2, X_train2[:missing_train]), axis=0)\n",
    "#     y_1 = np.concatenate((y_train1, y_train1[:missing_train]), axis=0)\n",
    "#     y_2 = np.concatenate((y_train2, y_train2[:missing_train]), axis=0)\n",
    "    \n",
    "    #chose the order of samples to pick\n",
    "    randomIdx = list(range(len(X_1)))\n",
    "    random.shuffle(randomIdx)\n",
    "    \n",
    "    counter = 1\n",
    "    while True:\n",
    "        if (counter-1)*batch_size >= len(X_1): # end of epoch\n",
    "            random.shuffle(randomIdx)\n",
    "            counter = 1\n",
    "\n",
    "        features_1 = X_1[randomIdx[(counter-1)*batch_size : counter*batch_size]]\n",
    "        features_2 = X_2[randomIdx[(counter-1)*batch_size : counter*batch_size]]\n",
    "        \n",
    "        batchTargets = y_1[randomIdx[(counter-1)*batch_size : counter*batch_size]]\n",
    "        \n",
    "        # TO SOLVE THE DROPOUT LAYER SHAPE PROBLEM\n",
    "        if (counter)*batch_size >= len(X_1) and isTraining: # the last epoch\n",
    "            features_1 = np.concatenate((features_1, X_1[randomIdx[:missing_train]]), axis=0)\n",
    "            features_2 = np.concatenate((features_2, X_2[randomIdx[:missing_train]]), axis=0)\n",
    "            batchTargets = np.concatenate((batchTargets, y_1[randomIdx[:missing_train]]), axis=0)\n",
    "        \n",
    "        counter += 1\n",
    "        batchFeatures = [features_1,features_2]\n",
    "        \n",
    "        yield batchFeatures, batchTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## 1/16 - pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05 - Cross_subject/ ########\n",
      "touching /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.h5\n",
      "## To be saved in [...]/savedModels/Cross_subject/ ###\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_SUBJECT-dataset.pickle\n",
      "train_set shape: (32256,)\n",
      "train_set zero elements: 4070412/104805544 (3.9%)\n",
      "val_set shape: (8064,)\n",
      "val_set zero elements: 1067838/26143382 (4.1%)\n",
      "test_set shape: (16560,)\n",
      "test_set zero elements: 2234310/57232200 (3.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 32256\n",
      "## NEW LENGHT OF DATSET: 32256\n",
      "## OLD LENGHT OF DATSET: 8064\n",
      "## NEW LENGHT OF DATSET: 8064\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (32256, 299, 34, 2)\n",
      "train set zero elements (after padding): 552321296 (84.22%)\n",
      "val set shape: (8064, 299, 34, 2)\n",
      "val set zero elements (after padding): 138138226 (84.25%)\n",
      "test set shape: (16560, 299, 34, 2)\n",
      "test set zero elements (after padding): 280131984 (83.20%)\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_SUBJECT-dataset.pickle\n",
      "train_set shape: (32256,)\n",
      "train_set zero elements: 4070412/104805544 (3.9%)\n",
      "val_set shape: (8064,)\n",
      "val_set zero elements: 1067838/26143382 (4.1%)\n",
      "test_set shape: (16560,)\n",
      "test_set zero elements: 2234310/57232200 (3.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 32256\n",
      "## NEW LENGHT OF DATSET: 32256\n",
      "## OLD LENGHT OF DATSET: 8064\n",
      "## NEW LENGHT OF DATSET: 8064\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (32256, 300, 34, 2)\n",
      "train set zero elements (after padding): 553216856 (84.07%)\n",
      "val set shape: (8064, 300, 34, 2)\n",
      "val set zero elements (after padding): 138362218 (84.11%)\n",
      "test set shape: (16560, 300, 34, 2)\n",
      "test set zero elements (after padding): 280591800 (83.06%)\n",
      "## MERGING TRAIN+VAL ##\n",
      "#### CREATINGS COMBINATION OF BEST STRUCTURES #######\n",
      "WARNING:tensorflow:From /data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/envs/gpuEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "### FITTING WITH GENERATORS  ####\n",
      "WARNING:tensorflow:From /data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/envs/gpuEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /data/students_home/amoscatelli/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/2000\n",
      "## VALIDATION len of data 16560 - batch size 600\n",
      "## VALIDATION missing_train = 240\n",
      "## TRAINING len of data 40320 - batch size 600\n",
      "## TRAINING missing_train = 480\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.011.\n",
      "68/68 [==============================] - 63s 923ms/step - loss: 4.1034 - accuracy: 0.0172 - val_loss: 4.0951 - val_accuracy: 0.0171\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.09513, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.01709, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.010920160000000002.\n",
      "68/68 [==============================] - 50s 733ms/step - loss: 4.1023 - accuracy: 0.0165 - val_loss: 4.0699 - val_accuracy: 0.0219\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.09513 to 4.06993, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.01709 to 0.02186, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.010840639999999999.\n",
      "68/68 [==============================] - 46s 677ms/step - loss: 4.1109 - accuracy: 0.0158 - val_loss: 4.0956 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.06993\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.02186\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.01076144.\n",
      "68/68 [==============================] - 35s 519ms/step - loss: 4.0948 - accuracy: 0.0162 - val_loss: 4.0857 - val_accuracy: 0.0181\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.06993\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.02186\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.01068256.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 35s 519ms/step - loss: 4.1112 - accuracy: 0.0169 - val_loss: 4.0970 - val_accuracy: 0.0166\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.06993\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.02186\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.010603999999999999.\n",
      "68/68 [==============================] - 40s 590ms/step - loss: 4.0950 - accuracy: 0.0175 - val_loss: 4.0936 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.06993\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.02186\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.010525759999999999.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 3.7853 - accuracy: 0.0391 - val_loss: 3.5439 - val_accuracy: 0.0568\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.06993 to 3.54390, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.02186 to 0.05676, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.01044784.\n",
      "68/68 [==============================] - 50s 733ms/step - loss: 3.5864 - accuracy: 0.0543 - val_loss: 3.5009 - val_accuracy: 0.0577\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.54390 to 3.50093, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.05676 to 0.05773, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.01037024.\n",
      "68/68 [==============================] - 49s 723ms/step - loss: 3.5034 - accuracy: 0.0660 - val_loss: 3.4593 - val_accuracy: 0.0793\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.50093 to 3.45931, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.05773 to 0.07935, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.01029296.\n",
      "68/68 [==============================] - 50s 734ms/step - loss: 3.3638 - accuracy: 0.0960 - val_loss: 3.2582 - val_accuracy: 0.0969\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.45931 to 3.25822, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.07935 to 0.09686, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.010216.\n",
      "68/68 [==============================] - 50s 734ms/step - loss: 3.2516 - accuracy: 0.1092 - val_loss: 3.2710 - val_accuracy: 0.1118\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.25822\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.09686 to 0.11178, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.01013936.\n",
      "68/68 [==============================] - 50s 739ms/step - loss: 3.2251 - accuracy: 0.1187 - val_loss: 3.2987 - val_accuracy: 0.1129\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.25822\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.11178 to 0.11292, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.010063039999999999.\n",
      "68/68 [==============================] - 50s 740ms/step - loss: 3.1943 - accuracy: 0.1242 - val_loss: 3.1836 - val_accuracy: 0.1210\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.25822 to 3.18364, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.11292 to 0.12095, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.009987039999999999.\n",
      "68/68 [==============================] - 52s 762ms/step - loss: 3.1758 - accuracy: 0.1278 - val_loss: 3.2923 - val_accuracy: 0.1030\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.18364\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.12095\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.009911360000000001.\n",
      "68/68 [==============================] - 51s 744ms/step - loss: 3.0981 - accuracy: 0.1568 - val_loss: 3.0912 - val_accuracy: 0.1748\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.18364 to 3.09119, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.12095 to 0.17482, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.009836000000000001.\n",
      "68/68 [==============================] - 63s 928ms/step - loss: 2.9446 - accuracy: 0.2079 - val_loss: 2.9634 - val_accuracy: 0.2404\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.09119 to 2.96339, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.17482 to 0.24040, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.009760959999999999.\n",
      "68/68 [==============================] - 56s 828ms/step - loss: 2.8019 - accuracy: 0.2557 - val_loss: 2.6393 - val_accuracy: 0.2827\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.96339 to 2.63926, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.24040 to 0.28267, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.009686239999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 55s 809ms/step - loss: 2.6689 - accuracy: 0.2971 - val_loss: 2.7769 - val_accuracy: 0.3021\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.63926\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.28267 to 0.30205, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.00961184.\n",
      "68/68 [==============================] - 55s 805ms/step - loss: 2.5980 - accuracy: 0.3160 - val_loss: 2.5580 - val_accuracy: 0.3462\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.63926 to 2.55797, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.30205 to 0.34620, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.009537760000000003.\n",
      "68/68 [==============================] - 53s 773ms/step - loss: 2.4912 - accuracy: 0.3528 - val_loss: 2.4948 - val_accuracy: 0.3306\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.55797 to 2.49482, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.34620\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.009464.\n",
      "68/68 [==============================] - 55s 809ms/step - loss: 2.4153 - accuracy: 0.3766 - val_loss: 2.4511 - val_accuracy: 0.3763\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.49482 to 2.45110, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.34620 to 0.37627, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.00939056.\n",
      "68/68 [==============================] - 55s 813ms/step - loss: 2.3493 - accuracy: 0.4016 - val_loss: 2.2919 - val_accuracy: 0.4239\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.45110 to 2.29194, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.37627 to 0.42391, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.00931744.\n",
      "68/68 [==============================] - 56s 819ms/step - loss: 2.2800 - accuracy: 0.4267 - val_loss: 2.2708 - val_accuracy: 0.4589\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.29194 to 2.27082, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.42391 to 0.45888, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.009244640000000002.\n",
      "68/68 [==============================] - 55s 806ms/step - loss: 2.2183 - accuracy: 0.4447 - val_loss: 2.1261 - val_accuracy: 0.4877\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.27082 to 2.12609, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.45888 to 0.48774, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.009172160000000002.\n",
      "68/68 [==============================] - 57s 843ms/step - loss: 2.1645 - accuracy: 0.4629 - val_loss: 2.2123 - val_accuracy: 0.4775\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.12609\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.48774\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0091.\n",
      "68/68 [==============================] - 54s 787ms/step - loss: 2.1068 - accuracy: 0.4822 - val_loss: 2.0365 - val_accuracy: 0.5188\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.12609 to 2.03653, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.48774 to 0.51878, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.00902816.\n",
      "68/68 [==============================] - 53s 781ms/step - loss: 2.0375 - accuracy: 0.5012 - val_loss: 1.9886 - val_accuracy: 0.5309\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.03653 to 1.98858, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.51878 to 0.53086, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.008956640000000002.\n",
      "68/68 [==============================] - 53s 784ms/step - loss: 1.9906 - accuracy: 0.5081 - val_loss: 1.8580 - val_accuracy: 0.5415\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.98858 to 1.85796, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.53086 to 0.54155, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.008885440000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 52s 770ms/step - loss: 1.9354 - accuracy: 0.5303 - val_loss: 1.8386 - val_accuracy: 0.5726\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.85796 to 1.83860, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.54155 to 0.57264, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.008814559999999999.\n",
      "68/68 [==============================] - 53s 784ms/step - loss: 1.8869 - accuracy: 0.5462 - val_loss: 1.7535 - val_accuracy: 0.5825\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.83860 to 1.75352, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.57264 to 0.58249, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.008744.\n",
      "68/68 [==============================] - 54s 793ms/step - loss: 1.8331 - accuracy: 0.5633 - val_loss: 1.7183 - val_accuracy: 0.5960\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.75352 to 1.71835, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.58249 to 0.59595, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.008673759999999999.\n",
      "68/68 [==============================] - 52s 769ms/step - loss: 1.7762 - accuracy: 0.5763 - val_loss: 1.7028 - val_accuracy: 0.6086\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.71835 to 1.70279, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.59595 to 0.60857, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.00860384.\n",
      "68/68 [==============================] - 53s 778ms/step - loss: 1.7338 - accuracy: 0.5828 - val_loss: 1.6354 - val_accuracy: 0.6044\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.70279 to 1.63540, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.60857\n",
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.00853424.\n",
      "68/68 [==============================] - 51s 752ms/step - loss: 1.6940 - accuracy: 0.5980 - val_loss: 1.8232 - val_accuracy: 0.6080\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.63540\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.60857\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.00846496.\n",
      "68/68 [==============================] - 52s 760ms/step - loss: 1.6682 - accuracy: 0.6056 - val_loss: 1.7988 - val_accuracy: 0.4076\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.63540\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.60857\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.008396.\n",
      "68/68 [==============================] - 54s 799ms/step - loss: 1.6433 - accuracy: 0.6127 - val_loss: 1.6614 - val_accuracy: 0.6106\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.63540\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.60857 to 0.61063, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.008327359999999999.\n",
      "68/68 [==============================] - 53s 785ms/step - loss: 1.6842 - accuracy: 0.6266 - val_loss: 1.8258 - val_accuracy: 0.6483\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.63540\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.61063 to 0.64831, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.00825904.\n",
      "68/68 [==============================] - 52s 763ms/step - loss: 1.6823 - accuracy: 0.6371 - val_loss: 1.7314 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.63540\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.64831\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.00819104.\n",
      "68/68 [==============================] - 52s 769ms/step - loss: 1.5940 - accuracy: 0.6413 - val_loss: 1.5693 - val_accuracy: 0.6641\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.63540 to 1.56931, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.64831 to 0.66407, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.00812336.\n",
      "68/68 [==============================] - 50s 736ms/step - loss: 1.5621 - accuracy: 0.6497 - val_loss: 1.6121 - val_accuracy: 0.6426\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.56931\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66407\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.008055999999999999.\n",
      "68/68 [==============================] - 52s 767ms/step - loss: 1.5409 - accuracy: 0.6503 - val_loss: 1.5649 - val_accuracy: 0.6591\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.56931 to 1.56491, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66407\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00798896.\n",
      "68/68 [==============================] - 52s 760ms/step - loss: 1.5267 - accuracy: 0.6559 - val_loss: 1.5720 - val_accuracy: 0.6545\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.56491\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66407\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00792224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 51s 750ms/step - loss: 1.5089 - accuracy: 0.6621 - val_loss: 1.4672 - val_accuracy: 0.6844\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.56491 to 1.46721, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.66407 to 0.68442, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.007855840000000001.\n",
      "68/68 [==============================] - 52s 765ms/step - loss: 1.4897 - accuracy: 0.6714 - val_loss: 1.5266 - val_accuracy: 0.6791\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.46721\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.68442\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0077897600000000015.\n",
      "68/68 [==============================] - 53s 776ms/step - loss: 1.4782 - accuracy: 0.6722 - val_loss: 1.5130 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.46721\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.68442\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.007724000000000001.\n",
      "68/68 [==============================] - 52s 768ms/step - loss: 1.4587 - accuracy: 0.6806 - val_loss: 1.4734 - val_accuracy: 0.6930\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.46721\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.68442 to 0.69300, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.007658560000000001.\n",
      "68/68 [==============================] - 53s 786ms/step - loss: 1.4483 - accuracy: 0.6812 - val_loss: 1.5120 - val_accuracy: 0.6801\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.46721\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.69300\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.007593440000000001.\n",
      "68/68 [==============================] - 52s 759ms/step - loss: 1.4259 - accuracy: 0.6874 - val_loss: 1.5407 - val_accuracy: 0.6665\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.46721\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.69300\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.007528640000000001.\n",
      "68/68 [==============================] - 52s 771ms/step - loss: 1.4161 - accuracy: 0.6906 - val_loss: 1.4663 - val_accuracy: 0.6870\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.46721 to 1.46629, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.69300\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.007464160000000001.\n",
      "68/68 [==============================] - 257s 4s/step - loss: 1.4039 - accuracy: 0.6958 - val_loss: 1.4546 - val_accuracy: 0.6877\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.46629 to 1.45463, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.69300\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.007400000000000001.\n",
      "68/68 [==============================] - 495s 7s/step - loss: 1.3833 - accuracy: 0.7039 - val_loss: 1.3555 - val_accuracy: 0.6996\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.45463 to 1.35549, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.69300 to 0.69958, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00733616.\n",
      "68/68 [==============================] - 76s 1s/step - loss: 1.3771 - accuracy: 0.7022 - val_loss: 1.4296 - val_accuracy: 0.7109\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.35549\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.69958 to 0.71093, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00727264.\n",
      "68/68 [==============================] - 49s 717ms/step - loss: 1.3603 - accuracy: 0.7089 - val_loss: 1.4070 - val_accuracy: 0.7087\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.35549\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.71093\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.007209440000000001.\n",
      "68/68 [==============================] - 39s 567ms/step - loss: 1.3501 - accuracy: 0.7109 - val_loss: 1.3527 - val_accuracy: 0.7144\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.35549 to 1.35270, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.71093 to 0.71443, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0071465600000000015.\n",
      "68/68 [==============================] - 40s 589ms/step - loss: 1.3349 - accuracy: 0.7152 - val_loss: 1.4588 - val_accuracy: 0.6979\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.35270\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.71443\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.007084000000000001.\n",
      "68/68 [==============================] - 39s 570ms/step - loss: 1.3106 - accuracy: 0.7193 - val_loss: 1.2683 - val_accuracy: 0.7116\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.35270 to 1.26831, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.71443\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.007021760000000001.\n",
      "68/68 [==============================] - 39s 572ms/step - loss: 1.2977 - accuracy: 0.7220 - val_loss: 1.4151 - val_accuracy: 0.7030\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.26831\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.71443\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.006959840000000001.\n",
      "68/68 [==============================] - 36s 524ms/step - loss: 1.2775 - accuracy: 0.7222 - val_loss: 1.3040 - val_accuracy: 0.7092\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.26831\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.71443\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00689824.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 37s 544ms/step - loss: 1.2565 - accuracy: 0.7273 - val_loss: 1.3041 - val_accuracy: 0.7093\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.26831\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.71443\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00683696.\n",
      "68/68 [==============================] - 38s 565ms/step - loss: 1.2472 - accuracy: 0.7291 - val_loss: 1.2067 - val_accuracy: 0.7164\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.26831 to 1.20667, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.71443 to 0.71643, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.006776.\n",
      "68/68 [==============================] - 36s 532ms/step - loss: 1.2361 - accuracy: 0.7283 - val_loss: 1.3277 - val_accuracy: 0.7101\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.20667\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.71643\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.006715360000000001.\n",
      "68/68 [==============================] - 37s 545ms/step - loss: 1.2141 - accuracy: 0.7365 - val_loss: 1.3481 - val_accuracy: 0.7130\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.20667\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.71643\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00665504.\n",
      "68/68 [==============================] - 40s 581ms/step - loss: 1.2072 - accuracy: 0.7381 - val_loss: 1.2925 - val_accuracy: 0.7199\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.20667\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.71643 to 0.71987, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.00659504.\n",
      "68/68 [==============================] - 43s 625ms/step - loss: 1.1933 - accuracy: 0.7395 - val_loss: 1.1850 - val_accuracy: 0.7122\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.20667 to 1.18495, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.71987\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0065353600000000005.\n",
      "68/68 [==============================] - 41s 610ms/step - loss: 1.1874 - accuracy: 0.7414 - val_loss: 1.2509 - val_accuracy: 0.7204\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.71987 to 0.72041, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.006476.\n",
      "68/68 [==============================] - 43s 628ms/step - loss: 1.1663 - accuracy: 0.7463 - val_loss: 1.3224 - val_accuracy: 0.7158\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.72041\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.006416959999999999.\n",
      "68/68 [==============================] - 47s 693ms/step - loss: 1.1648 - accuracy: 0.7468 - val_loss: 1.2729 - val_accuracy: 0.7236\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00067: val_accuracy improved from 0.72041 to 0.72361, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.006358239999999999.\n",
      "68/68 [==============================] - 43s 638ms/step - loss: 1.1496 - accuracy: 0.7509 - val_loss: 1.2987 - val_accuracy: 0.7094\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.72361\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.00629984.\n",
      "68/68 [==============================] - 59s 862ms/step - loss: 1.1641 - accuracy: 0.7485 - val_loss: 1.2847 - val_accuracy: 0.7239\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00069: val_accuracy improved from 0.72361 to 0.72391, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.00624176.\n",
      "68/68 [==============================] - 42s 612ms/step - loss: 1.1324 - accuracy: 0.7528 - val_loss: 1.2200 - val_accuracy: 0.7320\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.72391 to 0.73200, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.006184.\n",
      "68/68 [==============================] - 33s 478ms/step - loss: 1.1260 - accuracy: 0.7524 - val_loss: 1.2761 - val_accuracy: 0.7281\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.73200\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0061265600000000005.\n",
      "68/68 [==============================] - 32s 477ms/step - loss: 1.1112 - accuracy: 0.7562 - val_loss: 1.2192 - val_accuracy: 0.7220\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.73200\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.00606944.\n",
      "68/68 [==============================] - 35s 509ms/step - loss: 1.1006 - accuracy: 0.7598 - val_loss: 1.2279 - val_accuracy: 0.7298\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.18495\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.73200\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.00601264.\n",
      "68/68 [==============================] - 34s 500ms/step - loss: 1.0901 - accuracy: 0.7613 - val_loss: 1.1465 - val_accuracy: 0.7322\n",
      "\n",
      "Epoch 00074: val_loss improved from 1.18495 to 1.14646, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.73200 to 0.73219, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.005956159999999999.\n",
      "68/68 [==============================] - 33s 486ms/step - loss: 1.0804 - accuracy: 0.7636 - val_loss: 1.2661 - val_accuracy: 0.7264\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.14646\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.73219\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0059.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 33s 482ms/step - loss: 1.0681 - accuracy: 0.7660 - val_loss: 1.3170 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.14646\n",
      "\n",
      "Epoch 00076: val_accuracy improved from 0.73219 to 0.73303, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.005844159999999999.\n",
      "68/68 [==============================] - 34s 499ms/step - loss: 1.0647 - accuracy: 0.7654 - val_loss: 1.1471 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.14646\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.73303\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.005788639999999999.\n",
      "68/68 [==============================] - 34s 506ms/step - loss: 1.0547 - accuracy: 0.7681 - val_loss: 1.2736 - val_accuracy: 0.7338\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.14646\n",
      "\n",
      "Epoch 00078: val_accuracy improved from 0.73303 to 0.73382, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.005733439999999999.\n",
      "68/68 [==============================] - 34s 494ms/step - loss: 1.0435 - accuracy: 0.7703 - val_loss: 1.2254 - val_accuracy: 0.7284\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.14646\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.73382\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.005678559999999999.\n",
      "68/68 [==============================] - 34s 494ms/step - loss: 1.0296 - accuracy: 0.7735 - val_loss: 1.2583 - val_accuracy: 0.7284\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.14646\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.73382\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.005624.\n",
      "68/68 [==============================] - 37s 548ms/step - loss: 1.0315 - accuracy: 0.7731 - val_loss: 1.1378 - val_accuracy: 0.7268\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.14646 to 1.13782, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.73382\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.005569759999999999.\n",
      "68/68 [==============================] - 34s 494ms/step - loss: 1.0128 - accuracy: 0.7754 - val_loss: 1.1257 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.13782 to 1.12575, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.73382\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.005515839999999999.\n",
      "68/68 [==============================] - 34s 498ms/step - loss: 1.0071 - accuracy: 0.7777 - val_loss: 1.1891 - val_accuracy: 0.7372\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.12575\n",
      "\n",
      "Epoch 00083: val_accuracy improved from 0.73382 to 0.73720, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.005462239999999999.\n",
      "68/68 [==============================] - 34s 505ms/step - loss: 1.0042 - accuracy: 0.7812 - val_loss: 1.0715 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.12575 to 1.07147, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.73720\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.005408959999999999.\n",
      "68/68 [==============================] - 36s 536ms/step - loss: 0.9943 - accuracy: 0.7815 - val_loss: 1.2439 - val_accuracy: 0.7338\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.73720\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.005355999999999999.\n",
      "68/68 [==============================] - 35s 515ms/step - loss: 0.9913 - accuracy: 0.7830 - val_loss: 1.1123 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00086: val_accuracy improved from 0.73720 to 0.74342, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.005303360000000001.\n",
      "68/68 [==============================] - 25s 371ms/step - loss: 0.9741 - accuracy: 0.7890 - val_loss: 1.3011 - val_accuracy: 0.7385\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.74342\n",
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.00525104.\n",
      "68/68 [==============================] - 27s 400ms/step - loss: 0.9678 - accuracy: 0.7879 - val_loss: 1.2143 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.74342\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.00519904.\n",
      "68/68 [==============================] - 26s 375ms/step - loss: 0.9614 - accuracy: 0.7903 - val_loss: 1.2439 - val_accuracy: 0.7341\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.74342\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.005147360000000001.\n",
      "68/68 [==============================] - 27s 398ms/step - loss: 0.9614 - accuracy: 0.7861 - val_loss: 1.2193 - val_accuracy: 0.7367\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.74342\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.005096000000000001.\n",
      "68/68 [==============================] - 30s 437ms/step - loss: 0.9441 - accuracy: 0.7905 - val_loss: 1.1600 - val_accuracy: 0.7386\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.74342\n",
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.00504496.\n",
      "68/68 [==============================] - 35s 513ms/step - loss: 0.9389 - accuracy: 0.7939 - val_loss: 1.2220 - val_accuracy: 0.7413\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.74342\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0049942400000000005.\n",
      "68/68 [==============================] - 47s 693ms/step - loss: 0.9362 - accuracy: 0.7927 - val_loss: 1.1599 - val_accuracy: 0.7445\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00093: val_accuracy improved from 0.74342 to 0.74450, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0049438400000000006.\n",
      "68/68 [==============================] - 34s 496ms/step - loss: 0.9181 - accuracy: 0.7978 - val_loss: 1.2189 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.74450\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0048937600000000005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 34s 497ms/step - loss: 0.9169 - accuracy: 0.7962 - val_loss: 1.2712 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.07147\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.74450\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.004844.\n",
      "68/68 [==============================] - 35s 515ms/step - loss: 0.9020 - accuracy: 0.8017 - val_loss: 1.0050 - val_accuracy: 0.7388\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.07147 to 1.00496, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.74450\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.00479456.\n",
      "68/68 [==============================] - 32s 468ms/step - loss: 0.8957 - accuracy: 0.8040 - val_loss: 1.2125 - val_accuracy: 0.7417\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.74450\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.00474544.\n",
      "68/68 [==============================] - 30s 437ms/step - loss: 0.8881 - accuracy: 0.8015 - val_loss: 1.2083 - val_accuracy: 0.7426\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.74450\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.00469664.\n",
      "68/68 [==============================] - 41s 600ms/step - loss: 0.8789 - accuracy: 0.8063 - val_loss: 1.0908 - val_accuracy: 0.7404\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.74450\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.00464816.\n",
      "68/68 [==============================] - 38s 560ms/step - loss: 0.8792 - accuracy: 0.8063 - val_loss: 1.1333 - val_accuracy: 0.7444\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.74450\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0046.\n",
      "68/68 [==============================] - 55s 809ms/step - loss: 0.8726 - accuracy: 0.8079 - val_loss: 1.1619 - val_accuracy: 0.7384\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.74450\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.0045521599999999995.\n",
      "68/68 [==============================] - 39s 577ms/step - loss: 0.8642 - accuracy: 0.8105 - val_loss: 1.2220 - val_accuracy: 0.7428\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.74450\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.004504640000000001.\n",
      "68/68 [==============================] - 42s 617ms/step - loss: 0.8542 - accuracy: 0.8122 - val_loss: 1.2607 - val_accuracy: 0.7446\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00103: val_accuracy improved from 0.74450 to 0.74463, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.004457440000000002.\n",
      "68/68 [==============================] - 49s 717ms/step - loss: 0.8517 - accuracy: 0.8133 - val_loss: 1.0240 - val_accuracy: 0.7496\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00104: val_accuracy improved from 0.74463 to 0.74958, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.004410560000000001.\n",
      "68/68 [==============================] - 50s 732ms/step - loss: 0.8407 - accuracy: 0.8164 - val_loss: 1.2529 - val_accuracy: 0.7443\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.74958\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.0043640000000000016.\n",
      "68/68 [==============================] - 52s 770ms/step - loss: 0.8418 - accuracy: 0.8160 - val_loss: 1.2399 - val_accuracy: 0.7428\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.74958\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.00431776.\n",
      "68/68 [==============================] - 55s 806ms/step - loss: 0.8289 - accuracy: 0.8187 - val_loss: 1.1928 - val_accuracy: 0.7445\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.00496\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.74958\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.004271840000000001.\n",
      "68/68 [==============================] - 50s 729ms/step - loss: 0.8218 - accuracy: 0.8206 - val_loss: 0.9933 - val_accuracy: 0.7459\n",
      "\n",
      "Epoch 00108: val_loss improved from 1.00496 to 0.99333, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.74958\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.004226240000000001.\n",
      "68/68 [==============================] - 49s 722ms/step - loss: 0.8124 - accuracy: 0.8207 - val_loss: 1.0335 - val_accuracy: 0.7432\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.99333\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.74958\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.004180960000000001.\n",
      "68/68 [==============================] - 51s 745ms/step - loss: 0.8078 - accuracy: 0.8230 - val_loss: 1.1229 - val_accuracy: 0.7493\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.99333\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.74958\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.004136000000000001.\n",
      "68/68 [==============================] - 53s 774ms/step - loss: 0.7949 - accuracy: 0.8243 - val_loss: 1.2262 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.99333\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.74958\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0040913600000000005.\n",
      "68/68 [==============================] - 53s 777ms/step - loss: 0.7918 - accuracy: 0.8254 - val_loss: 1.2137 - val_accuracy: 0.7481\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.99333\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.74958\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.00404704.\n",
      "68/68 [==============================] - 52s 758ms/step - loss: 0.7890 - accuracy: 0.8259 - val_loss: 0.9713 - val_accuracy: 0.7490\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.99333 to 0.97132, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.74958\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.004003040000000001.\n",
      "68/68 [==============================] - 54s 791ms/step - loss: 0.7796 - accuracy: 0.8261 - val_loss: 1.2460 - val_accuracy: 0.7403\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.74958\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.00395936.\n",
      "68/68 [==============================] - 54s 799ms/step - loss: 0.7729 - accuracy: 0.8292 - val_loss: 1.1267 - val_accuracy: 0.7496\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.74958\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.003916.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 53s 785ms/step - loss: 0.7698 - accuracy: 0.8311 - val_loss: 1.0567 - val_accuracy: 0.7545\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00116: val_accuracy improved from 0.74958 to 0.75447, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0038729600000000004.\n",
      "68/68 [==============================] - 52s 765ms/step - loss: 0.7632 - accuracy: 0.8323 - val_loss: 1.1585 - val_accuracy: 0.7524\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.75447\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.003830240000000001.\n",
      "68/68 [==============================] - 52s 766ms/step - loss: 0.7630 - accuracy: 0.8303 - val_loss: 1.0378 - val_accuracy: 0.7478\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.75447\n",
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0037878400000000002.\n",
      "68/68 [==============================] - 53s 782ms/step - loss: 0.7555 - accuracy: 0.8341 - val_loss: 1.0344 - val_accuracy: 0.7482\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.75447\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0037457600000000003.\n",
      "68/68 [==============================] - 52s 760ms/step - loss: 0.7479 - accuracy: 0.8364 - val_loss: 1.1572 - val_accuracy: 0.7537\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.75447\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0037040000000000003.\n",
      "68/68 [==============================] - 51s 750ms/step - loss: 0.7467 - accuracy: 0.8360 - val_loss: 1.2773 - val_accuracy: 0.7550\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.97132\n",
      "\n",
      "Epoch 00121: val_accuracy improved from 0.75447 to 0.75495, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.00366256.\n",
      "68/68 [==============================] - 49s 722ms/step - loss: 0.7437 - accuracy: 0.8351 - val_loss: 0.9679 - val_accuracy: 0.7511\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.97132 to 0.96791, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.75495\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.00362144.\n",
      "68/68 [==============================] - 50s 737ms/step - loss: 0.7389 - accuracy: 0.8369 - val_loss: 1.0492 - val_accuracy: 0.7554\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00123: val_accuracy improved from 0.75495 to 0.75537, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0035806400000000004.\n",
      "68/68 [==============================] - 50s 737ms/step - loss: 0.7276 - accuracy: 0.8411 - val_loss: 0.9957 - val_accuracy: 0.7529\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.75537\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.00354016.\n",
      "68/68 [==============================] - 50s 740ms/step - loss: 0.7222 - accuracy: 0.8423 - val_loss: 1.1228 - val_accuracy: 0.7569\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00125: val_accuracy improved from 0.75537 to 0.75688, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0035.\n",
      "68/68 [==============================] - 51s 748ms/step - loss: 0.7192 - accuracy: 0.8415 - val_loss: 1.1365 - val_accuracy: 0.7530\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.75688\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.00346016.\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 0.7165 - accuracy: 0.8427 - val_loss: 1.0422 - val_accuracy: 0.7534\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.75688\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.00342064.\n",
      "68/68 [==============================] - 53s 774ms/step - loss: 0.7102 - accuracy: 0.8449 - val_loss: 1.1184 - val_accuracy: 0.7583\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00128: val_accuracy improved from 0.75688 to 0.75827, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.00338144.\n",
      "68/68 [==============================] - 51s 750ms/step - loss: 0.7065 - accuracy: 0.8460 - val_loss: 0.9768 - val_accuracy: 0.7496\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.75827\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.00334256.\n",
      "68/68 [==============================] - 51s 753ms/step - loss: 0.6988 - accuracy: 0.8448 - val_loss: 1.1045 - val_accuracy: 0.7546\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.96791\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.75827\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.003304.\n",
      "68/68 [==============================] - 53s 780ms/step - loss: 0.6889 - accuracy: 0.8477 - val_loss: 0.9334 - val_accuracy: 0.7523\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.96791 to 0.93343, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.75827\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.00326576.\n",
      "68/68 [==============================] - 51s 745ms/step - loss: 0.6864 - accuracy: 0.8476 - val_loss: 1.0438 - val_accuracy: 0.7529\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.75827\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.00322784.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 0.6812 - accuracy: 0.8526 - val_loss: 1.1859 - val_accuracy: 0.7518\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.75827\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0031902399999999996.\n",
      "68/68 [==============================] - 50s 732ms/step - loss: 0.6871 - accuracy: 0.8491 - val_loss: 1.0751 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00134: val_accuracy improved from 0.75827 to 0.76021, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 135/2000\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.00315296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 50s 734ms/step - loss: 0.6749 - accuracy: 0.8520 - val_loss: 1.0274 - val_accuracy: 0.7553\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.76021\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0031159999999999994.\n",
      "68/68 [==============================] - 51s 752ms/step - loss: 0.6718 - accuracy: 0.8534 - val_loss: 1.0102 - val_accuracy: 0.7585\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.76021\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0030793599999999997.\n",
      "68/68 [==============================] - 49s 720ms/step - loss: 0.6686 - accuracy: 0.8548 - val_loss: 1.1312 - val_accuracy: 0.7569\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.76021\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0030430399999999995.\n",
      "68/68 [==============================] - 52s 760ms/step - loss: 0.6620 - accuracy: 0.8548 - val_loss: 1.1277 - val_accuracy: 0.7563\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.76021\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.00300704.\n",
      "68/68 [==============================] - 46s 672ms/step - loss: 0.6597 - accuracy: 0.8543 - val_loss: 1.0043 - val_accuracy: 0.7488\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.76021\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0029713599999999997.\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.6627 - accuracy: 0.8544 - val_loss: 1.1138 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.76021\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.002936.\n",
      "68/68 [==============================] - 51s 748ms/step - loss: 0.6547 - accuracy: 0.8563 - val_loss: 1.0248 - val_accuracy: 0.7598\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.76021\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.00290096.\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 0.6534 - accuracy: 0.8539 - val_loss: 1.0425 - val_accuracy: 0.7551\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.76021\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0028662400000000004.\n",
      "68/68 [==============================] - 51s 749ms/step - loss: 0.6472 - accuracy: 0.8585 - val_loss: 1.1047 - val_accuracy: 0.7583\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.76021\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0028318400000000004.\n",
      "68/68 [==============================] - 53s 774ms/step - loss: 0.6416 - accuracy: 0.8599 - val_loss: 0.9982 - val_accuracy: 0.7559\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.76021\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0027977600000000007.\n",
      "68/68 [==============================] - 53s 779ms/step - loss: 0.6397 - accuracy: 0.8605 - val_loss: 1.1739 - val_accuracy: 0.7586\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.93343\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.76021\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0027640000000000004.\n",
      "68/68 [==============================] - 55s 806ms/step - loss: 0.6406 - accuracy: 0.8609 - val_loss: 0.9216 - val_accuracy: 0.7571\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.93343 to 0.92163, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.76021\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.002730560000000001.\n",
      "68/68 [==============================] - 56s 826ms/step - loss: 0.6342 - accuracy: 0.8594 - val_loss: 1.0524 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.92163\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.76021\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0026974400000000006.\n",
      "68/68 [==============================] - 53s 776ms/step - loss: 0.6266 - accuracy: 0.8653 - val_loss: 1.2630 - val_accuracy: 0.7577\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.92163\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.76021\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0026646400000000002.\n",
      "68/68 [==============================] - 49s 714ms/step - loss: 0.6296 - accuracy: 0.8625 - val_loss: 1.0359 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.92163\n",
      "\n",
      "Epoch 00149: val_accuracy improved from 0.76021 to 0.76135, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0026321600000000006.\n",
      "68/68 [==============================] - 48s 699ms/step - loss: 0.6217 - accuracy: 0.8652 - val_loss: 0.9631 - val_accuracy: 0.7577\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.92163\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.76135\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.0026000000000000003.\n",
      "68/68 [==============================] - 49s 723ms/step - loss: 0.6207 - accuracy: 0.8656 - val_loss: 0.8954 - val_accuracy: 0.7597\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.92163 to 0.89542, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.76135\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.00256816.\n",
      "68/68 [==============================] - 46s 679ms/step - loss: 0.6202 - accuracy: 0.8635 - val_loss: 1.1675 - val_accuracy: 0.7588\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.89542\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.76135\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.0025366400000000006.\n",
      "68/68 [==============================] - 46s 676ms/step - loss: 0.6156 - accuracy: 0.8674 - val_loss: 1.0278 - val_accuracy: 0.7603\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.89542\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.76135\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.0025054400000000003.\n",
      "68/68 [==============================] - 48s 706ms/step - loss: 0.6059 - accuracy: 0.8688 - val_loss: 1.0452 - val_accuracy: 0.7612\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.89542\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.76135\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.0024745599999999998.\n",
      "68/68 [==============================] - 46s 681ms/step - loss: 0.6105 - accuracy: 0.8671 - val_loss: 0.9882 - val_accuracy: 0.7586\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.89542\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.76135\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.002444.\n",
      "68/68 [==============================] - 57s 846ms/step - loss: 0.6069 - accuracy: 0.8694 - val_loss: 1.0176 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.89542\n",
      "\n",
      "Epoch 00156: val_accuracy improved from 0.76135 to 0.76244, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 157/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.00241376.\n",
      "68/68 [==============================] - 65s 956ms/step - loss: 0.6087 - accuracy: 0.8695 - val_loss: 1.0381 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.89542\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.76244\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.00238384.\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.6022 - accuracy: 0.8707 - val_loss: 0.8798 - val_accuracy: 0.7618\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.89542 to 0.87980, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.76244\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.0023542399999999996.\n",
      "68/68 [==============================] - 51s 743ms/step - loss: 0.5956 - accuracy: 0.8707 - val_loss: 1.0051 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.76244\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.00232496.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 0.5899 - accuracy: 0.8741 - val_loss: 0.9126 - val_accuracy: 0.7621\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.76244\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0022960000000000003.\n",
      "68/68 [==============================] - 48s 709ms/step - loss: 0.5975 - accuracy: 0.8726 - val_loss: 1.0651 - val_accuracy: 0.7618\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.76244\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.00226736.\n",
      "68/68 [==============================] - 48s 700ms/step - loss: 0.5898 - accuracy: 0.8739 - val_loss: 1.0396 - val_accuracy: 0.7642\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00162: val_accuracy improved from 0.76244 to 0.76419, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.00223904.\n",
      "68/68 [==============================] - 50s 741ms/step - loss: 0.5900 - accuracy: 0.8752 - val_loss: 1.0298 - val_accuracy: 0.7601\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.76419\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.00221104.\n",
      "68/68 [==============================] - 48s 700ms/step - loss: 0.5863 - accuracy: 0.8744 - val_loss: 1.0780 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.76419\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.0021833599999999996.\n",
      "68/68 [==============================] - 49s 720ms/step - loss: 0.5836 - accuracy: 0.8760 - val_loss: 1.1507 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.76419\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.002156.\n",
      "68/68 [==============================] - 48s 706ms/step - loss: 0.5841 - accuracy: 0.8752 - val_loss: 1.0223 - val_accuracy: 0.7582\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.76419\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.00212896.\n",
      "68/68 [==============================] - 47s 698ms/step - loss: 0.5778 - accuracy: 0.8765 - val_loss: 1.3618 - val_accuracy: 0.7593\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.76419\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.00210224.\n",
      "68/68 [==============================] - 48s 712ms/step - loss: 0.5763 - accuracy: 0.8767 - val_loss: 1.2912 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.87980\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.76419\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.00207584.\n",
      "68/68 [==============================] - 45s 662ms/step - loss: 0.5735 - accuracy: 0.8781 - val_loss: 0.8534 - val_accuracy: 0.7623\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.87980 to 0.85335, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.76419\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.00204976.\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 0.5717 - accuracy: 0.8788 - val_loss: 1.1155 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.76419\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.0020239999999999998.\n",
      "68/68 [==============================] - 49s 726ms/step - loss: 0.5700 - accuracy: 0.8780 - val_loss: 1.0800 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.76419\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.00199856.\n",
      "68/68 [==============================] - 49s 721ms/step - loss: 0.5661 - accuracy: 0.8795 - val_loss: 1.0849 - val_accuracy: 0.7582\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.76419\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.0019734400000000004.\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.5633 - accuracy: 0.8789 - val_loss: 0.9220 - val_accuracy: 0.7580\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.76419\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.0019486400000000004.\n",
      "68/68 [==============================] - 49s 721ms/step - loss: 0.5640 - accuracy: 0.8809 - val_loss: 0.9623 - val_accuracy: 0.7589\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.76419\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.0019241600000000003.\n",
      "68/68 [==============================] - 49s 727ms/step - loss: 0.5531 - accuracy: 0.8820 - val_loss: 0.9511 - val_accuracy: 0.7612\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.76419\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.0019000000000000002.\n",
      "68/68 [==============================] - 48s 709ms/step - loss: 0.5586 - accuracy: 0.8817 - val_loss: 1.0092 - val_accuracy: 0.7610\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.76419\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.0018761600000000004.\n",
      "68/68 [==============================] - 49s 727ms/step - loss: 0.5583 - accuracy: 0.8807 - val_loss: 0.9477 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.76419\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.0018526400000000002.\n",
      "68/68 [==============================] - 47s 690ms/step - loss: 0.5522 - accuracy: 0.8834 - val_loss: 1.2008 - val_accuracy: 0.7567\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.76419\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.0018294400000000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 49s 725ms/step - loss: 0.5503 - accuracy: 0.8816 - val_loss: 0.9570 - val_accuracy: 0.7580\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.76419\n",
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.0018065600000000002.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 0.5498 - accuracy: 0.8838 - val_loss: 1.0024 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.76419\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.001784.\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.5469 - accuracy: 0.8847 - val_loss: 1.1389 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.76419\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.0017617600000000002.\n",
      "68/68 [==============================] - 48s 706ms/step - loss: 0.5415 - accuracy: 0.8875 - val_loss: 1.1467 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.76419\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.00173984.\n",
      "68/68 [==============================] - 46s 670ms/step - loss: 0.5448 - accuracy: 0.8868 - val_loss: 1.0149 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.76419\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.0017182400000000002.\n",
      "68/68 [==============================] - 48s 704ms/step - loss: 0.5428 - accuracy: 0.8867 - val_loss: 1.2692 - val_accuracy: 0.7661\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00184: val_accuracy improved from 0.76419 to 0.76606, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.00169696.\n",
      "68/68 [==============================] - 49s 717ms/step - loss: 0.5380 - accuracy: 0.8896 - val_loss: 0.9991 - val_accuracy: 0.7620\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.76606\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.001676.\n",
      "68/68 [==============================] - 48s 713ms/step - loss: 0.5340 - accuracy: 0.8882 - val_loss: 1.0898 - val_accuracy: 0.7630\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.76606\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.00165536.\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.5329 - accuracy: 0.8880 - val_loss: 1.1650 - val_accuracy: 0.7633\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.76606\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.00163504.\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 0.5324 - accuracy: 0.8893 - val_loss: 1.0192 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.76606\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.0016150399999999999.\n",
      "68/68 [==============================] - 48s 711ms/step - loss: 0.5329 - accuracy: 0.8910 - val_loss: 1.0261 - val_accuracy: 0.7621\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.76606\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.00159536.\n",
      "68/68 [==============================] - 49s 726ms/step - loss: 0.5379 - accuracy: 0.8867 - val_loss: 1.0507 - val_accuracy: 0.7606\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.76606\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0015760000000000001.\n",
      "68/68 [==============================] - 47s 689ms/step - loss: 0.5260 - accuracy: 0.8916 - val_loss: 1.0448 - val_accuracy: 0.7597\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.76606\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.00155696.\n",
      "68/68 [==============================] - 47s 693ms/step - loss: 0.5236 - accuracy: 0.8906 - val_loss: 1.0140 - val_accuracy: 0.7615\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.76606\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.00153824.\n",
      "68/68 [==============================] - 47s 698ms/step - loss: 0.5259 - accuracy: 0.8927 - val_loss: 1.1960 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.76606\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.00151984.\n",
      "68/68 [==============================] - 47s 684ms/step - loss: 0.5269 - accuracy: 0.8915 - val_loss: 1.0340 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.76606\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.00150176.\n",
      "68/68 [==============================] - 47s 697ms/step - loss: 0.5175 - accuracy: 0.8909 - val_loss: 1.1718 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.76606\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.001484.\n",
      "68/68 [==============================] - 46s 673ms/step - loss: 0.5171 - accuracy: 0.8917 - val_loss: 1.1411 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.76606\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.00146656.\n",
      "68/68 [==============================] - 48s 704ms/step - loss: 0.5200 - accuracy: 0.8924 - val_loss: 1.1094 - val_accuracy: 0.7631\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.76606\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.0014494399999999998.\n",
      "68/68 [==============================] - 47s 690ms/step - loss: 0.5158 - accuracy: 0.8919 - val_loss: 1.0964 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.76606\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.0014326399999999998.\n",
      "68/68 [==============================] - 50s 728ms/step - loss: 0.5134 - accuracy: 0.8931 - val_loss: 0.9902 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.76606\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.0014161599999999999.\n",
      "68/68 [==============================] - 50s 732ms/step - loss: 0.5129 - accuracy: 0.8951 - val_loss: 1.0136 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.76606\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.0013999999999999998.\n",
      "68/68 [==============================] - 48s 713ms/step - loss: 0.5161 - accuracy: 0.8940 - val_loss: 1.0508 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.76606\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.0013841599999999997.\n",
      "68/68 [==============================] - 50s 729ms/step - loss: 0.5085 - accuracy: 0.8949 - val_loss: 1.1574 - val_accuracy: 0.7652\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.76606\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.00136864.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 49s 726ms/step - loss: 0.5109 - accuracy: 0.8943 - val_loss: 0.9934 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.76606\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.0013534399999999998.\n",
      "68/68 [==============================] - 48s 710ms/step - loss: 0.5054 - accuracy: 0.8972 - val_loss: 1.1028 - val_accuracy: 0.7604\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.76606\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.0013385600000000001.\n",
      "68/68 [==============================] - 48s 710ms/step - loss: 0.5078 - accuracy: 0.8961 - val_loss: 1.0147 - val_accuracy: 0.7668\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00205: val_accuracy improved from 0.76606 to 0.76685, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.001324.\n",
      "68/68 [==============================] - 54s 798ms/step - loss: 0.5070 - accuracy: 0.8976 - val_loss: 0.9822 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.76685\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.00130976.\n",
      "68/68 [==============================] - 52s 761ms/step - loss: 0.5072 - accuracy: 0.8960 - val_loss: 1.0417 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.76685\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.0012958400000000001.\n",
      "68/68 [==============================] - 51s 753ms/step - loss: 0.5037 - accuracy: 0.8977 - val_loss: 1.0416 - val_accuracy: 0.7650\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.76685\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.00128224.\n",
      "68/68 [==============================] - 48s 712ms/step - loss: 0.5050 - accuracy: 0.8970 - val_loss: 1.0838 - val_accuracy: 0.7626\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.76685\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.0012689600000000002.\n",
      "68/68 [==============================] - 50s 728ms/step - loss: 0.4970 - accuracy: 0.8977 - val_loss: 1.1038 - val_accuracy: 0.7621\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.76685\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.0012560000000000002.\n",
      "68/68 [==============================] - 48s 704ms/step - loss: 0.4968 - accuracy: 0.8984 - val_loss: 1.1527 - val_accuracy: 0.7655\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.76685\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.0012433600000000002.\n",
      "68/68 [==============================] - 47s 685ms/step - loss: 0.5031 - accuracy: 0.8978 - val_loss: 1.0544 - val_accuracy: 0.7651\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.76685\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.00123104.\n",
      "68/68 [==============================] - 52s 762ms/step - loss: 0.4961 - accuracy: 0.8988 - val_loss: 1.2451 - val_accuracy: 0.7632\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.76685\n",
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.00121904.\n",
      "68/68 [==============================] - 47s 692ms/step - loss: 0.4986 - accuracy: 0.8959 - val_loss: 0.9816 - val_accuracy: 0.7632\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.76685\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.00120736.\n",
      "68/68 [==============================] - 48s 705ms/step - loss: 0.4947 - accuracy: 0.8985 - val_loss: 1.0698 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.76685\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.001196.\n",
      "68/68 [==============================] - 47s 684ms/step - loss: 0.4949 - accuracy: 0.8989 - val_loss: 1.0796 - val_accuracy: 0.7656\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.76685\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.00118496.\n",
      "68/68 [==============================] - 45s 667ms/step - loss: 0.5001 - accuracy: 0.9002 - val_loss: 1.1879 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.76685\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.00117424.\n",
      "68/68 [==============================] - 47s 687ms/step - loss: 0.4964 - accuracy: 0.8988 - val_loss: 1.2255 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.76685\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.00116384.\n",
      "68/68 [==============================] - 45s 663ms/step - loss: 0.4892 - accuracy: 0.9013 - val_loss: 1.1938 - val_accuracy: 0.7610\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.76685\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.00115376.\n",
      "68/68 [==============================] - 46s 672ms/step - loss: 0.4900 - accuracy: 0.8990 - val_loss: 1.2124 - val_accuracy: 0.7620\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.76685\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.001144.\n",
      "68/68 [==============================] - 46s 684ms/step - loss: 0.4880 - accuracy: 0.9000 - val_loss: 1.1154 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.76685\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.00113456.\n",
      "68/68 [==============================] - 47s 698ms/step - loss: 0.4887 - accuracy: 0.9023 - val_loss: 1.0713 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.76685\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.0011254400000000001.\n",
      "68/68 [==============================] - 58s 856ms/step - loss: 0.4854 - accuracy: 0.9031 - val_loss: 1.1232 - val_accuracy: 0.7623\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.76685\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.00111664.\n",
      "68/68 [==============================] - 38s 557ms/step - loss: 0.4842 - accuracy: 0.9014 - val_loss: 1.1269 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.76685\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.00110816.\n",
      "68/68 [==============================] - 35s 518ms/step - loss: 0.4861 - accuracy: 0.9002 - val_loss: 1.1966 - val_accuracy: 0.7652\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.76685\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.0011.\n",
      "68/68 [==============================] - 49s 728ms/step - loss: 0.4858 - accuracy: 0.9011 - val_loss: 1.1737 - val_accuracy: 0.7638\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.76685\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.00109216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 51s 751ms/step - loss: 0.4858 - accuracy: 0.9002 - val_loss: 1.1019 - val_accuracy: 0.7633\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.76685\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.00108464.\n",
      "68/68 [==============================] - 52s 763ms/step - loss: 0.4777 - accuracy: 0.9027 - val_loss: 1.0420 - val_accuracy: 0.7618\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.76685\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.00107744.\n",
      "68/68 [==============================] - 48s 713ms/step - loss: 0.4829 - accuracy: 0.9025 - val_loss: 1.1712 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.76685\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.00107056.\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.4804 - accuracy: 0.9024 - val_loss: 0.9755 - val_accuracy: 0.7648\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.76685\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.0010639999999999998.\n",
      "68/68 [==============================] - 49s 722ms/step - loss: 0.4844 - accuracy: 0.9027 - val_loss: 1.1409 - val_accuracy: 0.7638\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.76685\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.00105776.\n",
      "68/68 [==============================] - 48s 712ms/step - loss: 0.4765 - accuracy: 0.9043 - val_loss: 1.0887 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.76685\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.00105184.\n",
      "68/68 [==============================] - 48s 711ms/step - loss: 0.4819 - accuracy: 0.9004 - val_loss: 1.0629 - val_accuracy: 0.7635\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.76685\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.00104624.\n",
      "68/68 [==============================] - 50s 736ms/step - loss: 0.4751 - accuracy: 0.9054 - val_loss: 0.9365 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.76685\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0010409599999999998.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 0.4745 - accuracy: 0.9062 - val_loss: 1.0076 - val_accuracy: 0.7653\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.76685\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.001036.\n",
      "68/68 [==============================] - 47s 688ms/step - loss: 0.4780 - accuracy: 0.9029 - val_loss: 0.9293 - val_accuracy: 0.7635\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.76685\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.00103136.\n",
      "68/68 [==============================] - 49s 725ms/step - loss: 0.4751 - accuracy: 0.9058 - val_loss: 1.1477 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.76685\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0010270400000000001.\n",
      "68/68 [==============================] - 50s 735ms/step - loss: 0.4748 - accuracy: 0.9062 - val_loss: 1.0597 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.76685\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.00102304.\n",
      "68/68 [==============================] - 47s 696ms/step - loss: 0.4737 - accuracy: 0.9048 - val_loss: 1.0676 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.76685\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.00101936.\n",
      "68/68 [==============================] - 50s 732ms/step - loss: 0.4738 - accuracy: 0.9067 - val_loss: 1.2807 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.76685\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.001016.\n",
      "68/68 [==============================] - 49s 714ms/step - loss: 0.4710 - accuracy: 0.9052 - val_loss: 1.0146 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.76685\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.00101296.\n",
      "68/68 [==============================] - 49s 718ms/step - loss: 0.4726 - accuracy: 0.9063 - val_loss: 1.0405 - val_accuracy: 0.7623\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.76685\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.0010102400000000001.\n",
      "68/68 [==============================] - 51s 743ms/step - loss: 0.4686 - accuracy: 0.9048 - val_loss: 1.1410 - val_accuracy: 0.7612\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.76685\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.00100784.\n",
      "68/68 [==============================] - 49s 725ms/step - loss: 0.4668 - accuracy: 0.9059 - val_loss: 1.3170 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.76685\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.00100576.\n",
      "68/68 [==============================] - 50s 731ms/step - loss: 0.4646 - accuracy: 0.9079 - val_loss: 1.0164 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.76685\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.0010040000000000001.\n",
      "68/68 [==============================] - 46s 673ms/step - loss: 0.4675 - accuracy: 0.9081 - val_loss: 1.2902 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.76685\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.00100256.\n",
      "68/68 [==============================] - 46s 671ms/step - loss: 0.4654 - accuracy: 0.9060 - val_loss: 1.1631 - val_accuracy: 0.7620\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.76685\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.00100144.\n",
      "68/68 [==============================] - 46s 676ms/step - loss: 0.4683 - accuracy: 0.9063 - val_loss: 1.0737 - val_accuracy: 0.7631\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.85335\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.76685\n",
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.0010006400000000001.\n",
      "68/68 [==============================] - 47s 694ms/step - loss: 0.4686 - accuracy: 0.9063 - val_loss: 0.8488 - val_accuracy: 0.7621\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.85335 to 0.84880, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.76685\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.00100016.\n",
      "68/68 [==============================] - 48s 707ms/step - loss: 0.4666 - accuracy: 0.9064 - val_loss: 0.9459 - val_accuracy: 0.7610\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.76685\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 46s 682ms/step - loss: 0.4658 - accuracy: 0.9061 - val_loss: 1.1787 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00251: val_accuracy improved from 0.76685 to 0.76793, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 693ms/step - loss: 0.4641 - accuracy: 0.9069 - val_loss: 1.0646 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.76793\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 716ms/step - loss: 0.4612 - accuracy: 0.9068 - val_loss: 1.0622 - val_accuracy: 0.7634\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.76793\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 701ms/step - loss: 0.4659 - accuracy: 0.9076 - val_loss: 1.1509 - val_accuracy: 0.7622\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.76793\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 701ms/step - loss: 0.4589 - accuracy: 0.9074 - val_loss: 0.9953 - val_accuracy: 0.7633\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.76793\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 686ms/step - loss: 0.4625 - accuracy: 0.9079 - val_loss: 1.0468 - val_accuracy: 0.7615\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.76793\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 728ms/step - loss: 0.4635 - accuracy: 0.9083 - val_loss: 1.0266 - val_accuracy: 0.7620\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.76793\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 722ms/step - loss: 0.4662 - accuracy: 0.9057 - val_loss: 0.9502 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.76793\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 696ms/step - loss: 0.4598 - accuracy: 0.9071 - val_loss: 1.1051 - val_accuracy: 0.7634\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.76793\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 46s 678ms/step - loss: 0.4613 - accuracy: 0.9099 - val_loss: 1.2679 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.76793\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 44s 653ms/step - loss: 0.4639 - accuracy: 0.9086 - val_loss: 1.1360 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.76793\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 702ms/step - loss: 0.4602 - accuracy: 0.9075 - val_loss: 1.0448 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.76793\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 686ms/step - loss: 0.4568 - accuracy: 0.9102 - val_loss: 1.0565 - val_accuracy: 0.7649\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.76793\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 709ms/step - loss: 0.4567 - accuracy: 0.9098 - val_loss: 1.1931 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.76793\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 699ms/step - loss: 0.4601 - accuracy: 0.9095 - val_loss: 1.0963 - val_accuracy: 0.7626\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.76793\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 690ms/step - loss: 0.4592 - accuracy: 0.9075 - val_loss: 1.0569 - val_accuracy: 0.7630\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.76793\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 739ms/step - loss: 0.4552 - accuracy: 0.9092 - val_loss: 1.0816 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.76793\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 749ms/step - loss: 0.4533 - accuracy: 0.9102 - val_loss: 1.0740 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.76793\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 52s 765ms/step - loss: 0.4565 - accuracy: 0.9083 - val_loss: 1.2951 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.76793\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 745ms/step - loss: 0.4545 - accuracy: 0.9113 - val_loss: 1.0035 - val_accuracy: 0.7642\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.76793\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 52s 763ms/step - loss: 0.4594 - accuracy: 0.9090 - val_loss: 1.1508 - val_accuracy: 0.7642\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.76793\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 743ms/step - loss: 0.4533 - accuracy: 0.9096 - val_loss: 1.1934 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.76793\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 713ms/step - loss: 0.4509 - accuracy: 0.9116 - val_loss: 1.0258 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.76793\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 0.4536 - accuracy: 0.9110 - val_loss: 1.0896 - val_accuracy: 0.7618\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.76793\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 52s 757ms/step - loss: 0.4546 - accuracy: 0.9103 - val_loss: 1.1753 - val_accuracy: 0.7615\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.76793\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 47s 689ms/step - loss: 0.4517 - accuracy: 0.9111 - val_loss: 0.9736 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.76793\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 698ms/step - loss: 0.4499 - accuracy: 0.9103 - val_loss: 1.0425 - val_accuracy: 0.7642\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.76793\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 704ms/step - loss: 0.4489 - accuracy: 0.9127 - val_loss: 0.9703 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.76793\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 709ms/step - loss: 0.4497 - accuracy: 0.9117 - val_loss: 1.0723 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.76793\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 691ms/step - loss: 0.4511 - accuracy: 0.9122 - val_loss: 1.0364 - val_accuracy: 0.7644\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.76793\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 733ms/step - loss: 0.4497 - accuracy: 0.9101 - val_loss: 1.0742 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.76793\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 737ms/step - loss: 0.4474 - accuracy: 0.9097 - val_loss: 0.9310 - val_accuracy: 0.7621\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.76793\n",
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 685ms/step - loss: 0.4502 - accuracy: 0.9110 - val_loss: 0.9899 - val_accuracy: 0.7635\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.76793\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 750ms/step - loss: 0.4461 - accuracy: 0.9112 - val_loss: 1.1357 - val_accuracy: 0.7623\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.76793\n",
      "Epoch 285/2000\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 714ms/step - loss: 0.4503 - accuracy: 0.9094 - val_loss: 1.0554 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.76793\n",
      "Epoch 286/2000\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 749ms/step - loss: 0.4484 - accuracy: 0.9113 - val_loss: 1.3144 - val_accuracy: 0.7637\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.76793\n",
      "Epoch 287/2000\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 0.4496 - accuracy: 0.9095 - val_loss: 0.9623 - val_accuracy: 0.7638\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.84880\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.76793\n",
      "Epoch 288/2000\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 721ms/step - loss: 0.4434 - accuracy: 0.9120 - val_loss: 0.8304 - val_accuracy: 0.7670\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.84880 to 0.83043, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.76793\n",
      "Epoch 289/2000\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 715ms/step - loss: 0.4481 - accuracy: 0.9119 - val_loss: 1.1082 - val_accuracy: 0.7644\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.76793\n",
      "Epoch 290/2000\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 703ms/step - loss: 0.4453 - accuracy: 0.9123 - val_loss: 1.1075 - val_accuracy: 0.7615\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.76793\n",
      "Epoch 291/2000\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 686ms/step - loss: 0.4448 - accuracy: 0.9109 - val_loss: 1.1226 - val_accuracy: 0.7622\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.76793\n",
      "Epoch 292/2000\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 715ms/step - loss: 0.4438 - accuracy: 0.9127 - val_loss: 1.1387 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.76793\n",
      "Epoch 293/2000\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 0.4446 - accuracy: 0.9117 - val_loss: 1.0726 - val_accuracy: 0.7635\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.76793\n",
      "Epoch 294/2000\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 700ms/step - loss: 0.4421 - accuracy: 0.9130 - val_loss: 1.0290 - val_accuracy: 0.7653\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.76793\n",
      "Epoch 295/2000\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 704ms/step - loss: 0.4440 - accuracy: 0.9130 - val_loss: 1.0588 - val_accuracy: 0.7646\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.76793\n",
      "Epoch 296/2000\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 704ms/step - loss: 0.4426 - accuracy: 0.9128 - val_loss: 1.0865 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.76793\n",
      "Epoch 297/2000\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 46s 681ms/step - loss: 0.4389 - accuracy: 0.9150 - val_loss: 1.1718 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.76793\n",
      "Epoch 298/2000\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 46s 684ms/step - loss: 0.4400 - accuracy: 0.9140 - val_loss: 1.0177 - val_accuracy: 0.7629\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.76793\n",
      "Epoch 299/2000\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 721ms/step - loss: 0.4412 - accuracy: 0.9140 - val_loss: 1.1217 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.76793\n",
      "Epoch 300/2000\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 734ms/step - loss: 0.4466 - accuracy: 0.9131 - val_loss: 1.1087 - val_accuracy: 0.7632\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.76793\n",
      "Epoch 301/2000\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 50s 731ms/step - loss: 0.4421 - accuracy: 0.9130 - val_loss: 0.9916 - val_accuracy: 0.7655\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.76793\n",
      "Epoch 302/2000\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 733ms/step - loss: 0.4415 - accuracy: 0.9144 - val_loss: 1.0294 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.76793\n",
      "Epoch 303/2000\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 728ms/step - loss: 0.4437 - accuracy: 0.9135 - val_loss: 1.1035 - val_accuracy: 0.7652\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.76793\n",
      "Epoch 304/2000\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 731ms/step - loss: 0.4347 - accuracy: 0.9166 - val_loss: 0.9125 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.76793\n",
      "Epoch 305/2000\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 726ms/step - loss: 0.4402 - accuracy: 0.9138 - val_loss: 1.1528 - val_accuracy: 0.7620\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.76793\n",
      "Epoch 306/2000\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 726ms/step - loss: 0.4369 - accuracy: 0.9156 - val_loss: 0.9554 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.76793\n",
      "Epoch 307/2000\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 744ms/step - loss: 0.4387 - accuracy: 0.9152 - val_loss: 1.0572 - val_accuracy: 0.7655\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.76793\n",
      "Epoch 308/2000\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 711ms/step - loss: 0.4408 - accuracy: 0.9130 - val_loss: 0.8814 - val_accuracy: 0.7630\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.76793\n",
      "Epoch 309/2000\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 692ms/step - loss: 0.4370 - accuracy: 0.9147 - val_loss: 1.2559 - val_accuracy: 0.7665\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.76793\n",
      "Epoch 310/2000\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 695ms/step - loss: 0.4396 - accuracy: 0.9133 - val_loss: 1.0643 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.76793\n",
      "Epoch 311/2000\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 695ms/step - loss: 0.4361 - accuracy: 0.9152 - val_loss: 0.9820 - val_accuracy: 0.7659\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.76793\n",
      "Epoch 312/2000\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 685ms/step - loss: 0.4390 - accuracy: 0.9143 - val_loss: 1.0272 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.76793\n",
      "Epoch 313/2000\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 703ms/step - loss: 0.4392 - accuracy: 0.9154 - val_loss: 1.0808 - val_accuracy: 0.7653\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.76793\n",
      "Epoch 314/2000\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 720ms/step - loss: 0.4356 - accuracy: 0.9151 - val_loss: 1.1534 - val_accuracy: 0.7644\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.76793\n",
      "Epoch 315/2000\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 694ms/step - loss: 0.4343 - accuracy: 0.9166 - val_loss: 1.0143 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.76793\n",
      "Epoch 316/2000\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 701ms/step - loss: 0.4326 - accuracy: 0.9158 - val_loss: 0.9211 - val_accuracy: 0.7659\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.76793\n",
      "Epoch 317/2000\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 703ms/step - loss: 0.4358 - accuracy: 0.9145 - val_loss: 1.0441 - val_accuracy: 0.7626\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.76793\n",
      "Epoch 318/2000\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 745ms/step - loss: 0.4343 - accuracy: 0.9144 - val_loss: 1.1143 - val_accuracy: 0.7599\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.76793\n",
      "Epoch 319/2000\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 697ms/step - loss: 0.4313 - accuracy: 0.9151 - val_loss: 1.1005 - val_accuracy: 0.7637\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.76793\n",
      "Epoch 320/2000\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 696ms/step - loss: 0.4361 - accuracy: 0.9149 - val_loss: 0.8980 - val_accuracy: 0.7646\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.76793\n",
      "Epoch 321/2000\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 699ms/step - loss: 0.4347 - accuracy: 0.9147 - val_loss: 1.1385 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.76793\n",
      "Epoch 322/2000\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 0.4364 - accuracy: 0.9136 - val_loss: 1.1573 - val_accuracy: 0.7587\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.76793\n",
      "Epoch 323/2000\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 713ms/step - loss: 0.4305 - accuracy: 0.9158 - val_loss: 0.9097 - val_accuracy: 0.7642\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.76793\n",
      "Epoch 324/2000\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 0.4319 - accuracy: 0.9162 - val_loss: 1.1117 - val_accuracy: 0.7633\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.76793\n",
      "Epoch 325/2000\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 0.4298 - accuracy: 0.9164 - val_loss: 1.0655 - val_accuracy: 0.7626\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.76793\n",
      "Epoch 326/2000\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 716ms/step - loss: 0.4281 - accuracy: 0.9177 - val_loss: 1.1249 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00326: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.76793\n",
      "Epoch 327/2000\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 723ms/step - loss: 0.4331 - accuracy: 0.9163 - val_loss: 1.1765 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.76793\n",
      "Epoch 328/2000\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 746ms/step - loss: 0.4306 - accuracy: 0.9163 - val_loss: 0.9960 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.76793\n",
      "Epoch 329/2000\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 52s 761ms/step - loss: 0.4325 - accuracy: 0.9154 - val_loss: 1.2737 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.76793\n",
      "Epoch 330/2000\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 46s 681ms/step - loss: 0.4322 - accuracy: 0.9153 - val_loss: 0.9721 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.76793\n",
      "Epoch 331/2000\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 45s 665ms/step - loss: 0.4280 - accuracy: 0.9172 - val_loss: 1.1582 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.76793\n",
      "Epoch 332/2000\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 721ms/step - loss: 0.4258 - accuracy: 0.9179 - val_loss: 1.1209 - val_accuracy: 0.7621\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.76793\n",
      "Epoch 333/2000\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 700ms/step - loss: 0.4301 - accuracy: 0.9161 - val_loss: 1.1869 - val_accuracy: 0.7656\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.76793\n",
      "Epoch 334/2000\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 685ms/step - loss: 0.4226 - accuracy: 0.9175 - val_loss: 1.1704 - val_accuracy: 0.7603\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.76793\n",
      "Epoch 335/2000\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 686ms/step - loss: 0.4304 - accuracy: 0.9162 - val_loss: 1.1167 - val_accuracy: 0.7644\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.76793\n",
      "Epoch 336/2000\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 714ms/step - loss: 0.4294 - accuracy: 0.9167 - val_loss: 1.2380 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.76793\n",
      "Epoch 337/2000\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 708ms/step - loss: 0.4282 - accuracy: 0.9177 - val_loss: 1.1024 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.76793\n",
      "Epoch 338/2000\n",
      "\n",
      "Epoch 00338: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 712ms/step - loss: 0.4229 - accuracy: 0.9196 - val_loss: 1.0857 - val_accuracy: 0.7655\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.76793\n",
      "Epoch 339/2000\n",
      "\n",
      "Epoch 00339: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 715ms/step - loss: 0.4259 - accuracy: 0.9161 - val_loss: 1.2308 - val_accuracy: 0.7631\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.76793\n",
      "Epoch 340/2000\n",
      "\n",
      "Epoch 00340: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 0.4235 - accuracy: 0.9170 - val_loss: 1.1068 - val_accuracy: 0.7664\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.76793\n",
      "Epoch 341/2000\n",
      "\n",
      "Epoch 00341: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 715ms/step - loss: 0.4205 - accuracy: 0.9202 - val_loss: 1.2572 - val_accuracy: 0.7630\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.76793\n",
      "Epoch 342/2000\n",
      "\n",
      "Epoch 00342: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 49s 716ms/step - loss: 0.4219 - accuracy: 0.9197 - val_loss: 1.3535 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.76793\n",
      "Epoch 343/2000\n",
      "\n",
      "Epoch 00343: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 747ms/step - loss: 0.4258 - accuracy: 0.9158 - val_loss: 1.0277 - val_accuracy: 0.7614\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.76793\n",
      "Epoch 344/2000\n",
      "\n",
      "Epoch 00344: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 702ms/step - loss: 0.4240 - accuracy: 0.9184 - val_loss: 1.0366 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.76793\n",
      "Epoch 345/2000\n",
      "\n",
      "Epoch 00345: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 710ms/step - loss: 0.4224 - accuracy: 0.9200 - val_loss: 1.0824 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.76793\n",
      "Epoch 346/2000\n",
      "\n",
      "Epoch 00346: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 47s 687ms/step - loss: 0.4224 - accuracy: 0.9179 - val_loss: 1.1256 - val_accuracy: 0.7658\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.76793\n",
      "Epoch 347/2000\n",
      "\n",
      "Epoch 00347: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 738ms/step - loss: 0.4218 - accuracy: 0.9174 - val_loss: 1.1012 - val_accuracy: 0.7649\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.76793\n",
      "Epoch 348/2000\n",
      "\n",
      "Epoch 00348: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 747ms/step - loss: 0.4205 - accuracy: 0.9188 - val_loss: 1.1022 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.76793\n",
      "Epoch 349/2000\n",
      "\n",
      "Epoch 00349: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 754ms/step - loss: 0.4213 - accuracy: 0.9178 - val_loss: 1.1465 - val_accuracy: 0.7623\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.76793\n",
      "Epoch 350/2000\n",
      "\n",
      "Epoch 00350: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 51s 745ms/step - loss: 0.4199 - accuracy: 0.9188 - val_loss: 0.9887 - val_accuracy: 0.7645\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.76793\n",
      "Epoch 351/2000\n",
      "\n",
      "Epoch 00351: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 48s 710ms/step - loss: 0.4191 - accuracy: 0.9186 - val_loss: 1.1306 - val_accuracy: 0.7650\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.83043\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.76793\n",
      "Restoring model weights from the end of the best epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00351: early stopping\n",
      "## Saved in /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.pickle ###\n",
      "\n",
      "\n",
      "Loading maxAccModelName\n",
      "moving maxAccModelName to modelFileNamePath\n",
      "Model for MAX ACCURACY test_acc: 76.793 val_acc: 76.793\n",
      "Model for MIN LOSS test_acc: 76.703 val_acc: 76.703\n",
      "Loading previous results...\n",
      "Dumping results...\n",
      "######## 2/16 - pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05 - Cross_view/ ########\n",
      "touching /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.h5\n",
      "## To be saved in [...]/savedModels/Cross_view/ ###\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_VIEW-dataset.pickle\n",
      "train_set shape: (30336,)\n",
      "train_set zero elements: 4314940/100491930 (4.3%)\n",
      "val_set shape: (7584,)\n",
      "val_set zero elements: 1225598/25026006 (4.9%)\n",
      "test_set shape: (18960,)\n",
      "test_set zero elements: 1832022/62663190 (2.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 30336\n",
      "## NEW LENGHT OF DATSET: 30336\n",
      "## OLD LENGHT OF DATSET: 7584\n",
      "## NEW LENGHT OF DATSET: 7584\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (30336, 299, 34, 2)\n",
      "train set zero elements (after padding): 517520120 (83.91%)\n",
      "val set shape: (7584, 299, 34, 2)\n",
      "val set zero elements (after padding): 129477032 (83.97%)\n",
      "test set shape: (18960, 299, 34, 2)\n",
      "test set zero elements (after padding): 323594354 (83.94%)\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_VIEW-dataset.pickle\n",
      "train_set shape: (30336,)\n",
      "train_set zero elements: 4314940/100491930 (4.3%)\n",
      "val_set shape: (7584,)\n",
      "val_set zero elements: 1225598/25026006 (4.9%)\n",
      "test_set shape: (18960,)\n",
      "test_set zero elements: 1832022/62663190 (2.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 30336\n",
      "## NEW LENGHT OF DATSET: 30336\n",
      "## OLD LENGHT OF DATSET: 7584\n",
      "## NEW LENGHT OF DATSET: 7584\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (30336, 300, 34, 2)\n",
      "train set zero elements (after padding): 518362470 (83.76%)\n",
      "val set shape: (7584, 300, 34, 2)\n",
      "val set zero elements (after padding): 129687594 (83.82%)\n",
      "test set shape: (18960, 300, 34, 2)\n",
      "test set zero elements (after padding): 324120810 (83.80%)\n",
      "## MERGING TRAIN+VAL ##\n",
      "#### CREATINGS COMBINATION OF BEST STRUCTURES #######\n",
      "### FITTING WITH GENERATORS  ####\n",
      "## TRAINING len of data 37920 - batch size 600## VALIDATION len of data 18960 - batch size 600\n",
      "## VALIDATION missing_train = 240\n",
      "\n",
      "## TRAINING missing_train = 480\n",
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.011.\n",
      "64/64 [==============================] - 62s 965ms/step - loss: 4.1215 - accuracy: 0.0179 - val_loss: 4.1061 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.10608, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.01667, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.010920160000000002.\n",
      "64/64 [==============================] - 55s 854ms/step - loss: 4.0993 - accuracy: 0.0159 - val_loss: 4.0942 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.10608 to 4.09418, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.01667\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.010840639999999999.\n",
      "64/64 [==============================] - 50s 785ms/step - loss: 4.0969 - accuracy: 0.0159 - val_loss: 4.0992 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.09418\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.01667 to 0.01672, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.01076144.\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 4.1047 - accuracy: 0.0157 - val_loss: 4.0938 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.09418 to 4.09381, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.01672\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.01068256.\n",
      "64/64 [==============================] - 50s 783ms/step - loss: 4.1017 - accuracy: 0.0150 - val_loss: 4.0958 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.09381\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.01672\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.010603999999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 49s 772ms/step - loss: 4.0969 - accuracy: 0.0152 - val_loss: 4.0944 - val_accuracy: 0.0170\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.09381\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.01672 to 0.01698, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.010525759999999999.\n",
      "64/64 [==============================] - 49s 759ms/step - loss: 4.0951 - accuracy: 0.0157 - val_loss: 4.0966 - val_accuracy: 0.0170\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.09381\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.01698 to 0.01704, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.01044784.\n",
      "64/64 [==============================] - 51s 804ms/step - loss: 4.1222 - accuracy: 0.0158 - val_loss: 4.0972 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.09381\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.01704\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.01037024.\n",
      "64/64 [==============================] - 53s 830ms/step - loss: 4.1111 - accuracy: 0.0150 - val_loss: 4.0954 - val_accuracy: 0.0169\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.09381\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.01704\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.01029296.\n",
      "64/64 [==============================] - 54s 840ms/step - loss: 4.1053 - accuracy: 0.0156 - val_loss: 4.1039 - val_accuracy: 0.0169\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.09381\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.01704\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.010216.\n",
      "64/64 [==============================] - 52s 812ms/step - loss: 4.0967 - accuracy: 0.0165 - val_loss: 4.0947 - val_accuracy: 0.0169\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.09381\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.01704\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.01013936.\n",
      "64/64 [==============================] - 51s 790ms/step - loss: 4.0953 - accuracy: 0.0161 - val_loss: 4.0926 - val_accuracy: 0.0170\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.09381 to 4.09256, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.01704\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.010063039999999999.\n",
      "64/64 [==============================] - 52s 811ms/step - loss: 4.1236 - accuracy: 0.0172 - val_loss: 4.0879 - val_accuracy: 0.0188\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.09256 to 4.08788, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.01704 to 0.01878, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.009987039999999999.\n",
      "64/64 [==============================] - 50s 783ms/step - loss: 3.9453 - accuracy: 0.0297 - val_loss: 3.7703 - val_accuracy: 0.0350\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.08788 to 3.77027, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.01878 to 0.03497, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.009911360000000001.\n",
      "64/64 [==============================] - 50s 780ms/step - loss: 3.8635 - accuracy: 0.0394 - val_loss: 4.0981 - val_accuracy: 0.0169\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.77027\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.03497\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.009836000000000001.\n",
      "64/64 [==============================] - 51s 804ms/step - loss: 3.7790 - accuracy: 0.0499 - val_loss: 4.3242 - val_accuracy: 0.0170\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.77027\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.03497\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.009760959999999999.\n",
      "64/64 [==============================] - 52s 818ms/step - loss: 3.5603 - accuracy: 0.0781 - val_loss: 3.4095 - val_accuracy: 0.1118\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.77027 to 3.40948, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.03497 to 0.11176, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.009686239999999999.\n",
      "64/64 [==============================] - 51s 792ms/step - loss: 3.2717 - accuracy: 0.1234 - val_loss: 3.1718 - val_accuracy: 0.1557\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.40948 to 3.17181, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.11176 to 0.15575, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.00961184.\n",
      "64/64 [==============================] - 52s 808ms/step - loss: 3.0785 - accuracy: 0.1815 - val_loss: 2.9180 - val_accuracy: 0.2207\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.17181 to 2.91804, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.15575 to 0.22073, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.009537760000000003.\n",
      "64/64 [==============================] - 51s 796ms/step - loss: 4.0171 - accuracy: 0.0327 - val_loss: 4.0653 - val_accuracy: 0.0171\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.91804\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.22073\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.009464.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 51s 803ms/step - loss: 3.7370 - accuracy: 0.0417 - val_loss: 3.3344 - val_accuracy: 0.0775\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.91804\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.22073\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.00939056.\n",
      "64/64 [==============================] - 53s 826ms/step - loss: 3.3150 - accuracy: 0.0741 - val_loss: 3.1990 - val_accuracy: 0.0995\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.91804\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.22073\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.00931744.\n",
      "64/64 [==============================] - 52s 812ms/step - loss: 3.2000 - accuracy: 0.1061 - val_loss: 3.0196 - val_accuracy: 0.1245\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.91804\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.22073\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.009244640000000002.\n",
      "64/64 [==============================] - 51s 795ms/step - loss: 2.9040 - accuracy: 0.1864 - val_loss: 2.6628 - val_accuracy: 0.2325\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.91804 to 2.66280, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.22073 to 0.23254, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.009172160000000002.\n",
      "64/64 [==============================] - 50s 783ms/step - loss: 2.7171 - accuracy: 0.2334 - val_loss: 2.4767 - val_accuracy: 0.3000\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.66280 to 2.47671, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.23254 to 0.30000, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0091.\n",
      "64/64 [==============================] - 50s 778ms/step - loss: 2.5380 - accuracy: 0.2862 - val_loss: 2.2643 - val_accuracy: 0.3383\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.47671 to 2.26432, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.30000 to 0.33829, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.00902816.\n",
      "64/64 [==============================] - 50s 784ms/step - loss: 2.3828 - accuracy: 0.3320 - val_loss: 2.2444 - val_accuracy: 0.3921\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.26432 to 2.24440, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.33829 to 0.39209, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.008956640000000002.\n",
      "64/64 [==============================] - 50s 785ms/step - loss: 2.2517 - accuracy: 0.3720 - val_loss: 2.1587 - val_accuracy: 0.4127\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.24440 to 2.15869, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.39209 to 0.41266, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.008885440000000001.\n",
      "64/64 [==============================] - 50s 777ms/step - loss: 2.1820 - accuracy: 0.3948 - val_loss: 2.0039 - val_accuracy: 0.4610\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.15869 to 2.00392, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.41266 to 0.46102, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.008814559999999999.\n",
      "64/64 [==============================] - 54s 837ms/step - loss: 2.0776 - accuracy: 0.4292 - val_loss: 1.7790 - val_accuracy: 0.5052\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.00392 to 1.77897, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.46102 to 0.50522, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.008744.\n",
      "64/64 [==============================] - 50s 781ms/step - loss: 2.0088 - accuracy: 0.4577 - val_loss: 1.8021 - val_accuracy: 0.5018\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.77897\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.50522\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.008673759999999999.\n",
      "64/64 [==============================] - 52s 815ms/step - loss: 1.9192 - accuracy: 0.4890 - val_loss: 1.7652 - val_accuracy: 0.5730\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.77897 to 1.76518, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.50522 to 0.57305, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.00860384.\n",
      "64/64 [==============================] - 50s 776ms/step - loss: 1.8385 - accuracy: 0.5133 - val_loss: 1.5965 - val_accuracy: 0.5864\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.76518 to 1.59648, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.57305 to 0.58645, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.00853424.\n",
      "64/64 [==============================] - 50s 782ms/step - loss: 1.7801 - accuracy: 0.5310 - val_loss: 1.5626 - val_accuracy: 0.6002\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.59648 to 1.56256, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.58645 to 0.60021, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.00846496.\n",
      "64/64 [==============================] - 50s 785ms/step - loss: 1.7062 - accuracy: 0.5539 - val_loss: 1.6393 - val_accuracy: 0.5949\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.56256\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.60021\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.008396.\n",
      "64/64 [==============================] - 53s 828ms/step - loss: 1.6665 - accuracy: 0.5698 - val_loss: 1.4903 - val_accuracy: 0.6255\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.56256 to 1.49029, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.60021 to 0.62553, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.008327359999999999.\n",
      "64/64 [==============================] - 51s 790ms/step - loss: 1.6129 - accuracy: 0.5839 - val_loss: 1.4865 - val_accuracy: 0.6200\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.49029 to 1.48654, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.62553\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.00825904.\n",
      "64/64 [==============================] - 50s 788ms/step - loss: 1.5523 - accuracy: 0.6042 - val_loss: 1.3282 - val_accuracy: 0.6670\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.48654 to 1.32818, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.62553 to 0.66704, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.00819104.\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 1.5074 - accuracy: 0.6148 - val_loss: 1.2003 - val_accuracy: 0.6681\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.32818 to 1.20034, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.66704 to 0.66814, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.00812336.\n",
      "64/64 [==============================] - 51s 792ms/step - loss: 1.4639 - accuracy: 0.6242 - val_loss: 1.3213 - val_accuracy: 0.6623\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.20034\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66814\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.008055999999999999.\n",
      "64/64 [==============================] - 52s 810ms/step - loss: 1.4049 - accuracy: 0.6393 - val_loss: 1.2809 - val_accuracy: 0.6820\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.20034\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.66814 to 0.68196, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00798896.\n",
      "64/64 [==============================] - 54s 842ms/step - loss: 1.3659 - accuracy: 0.6508 - val_loss: 1.2644 - val_accuracy: 0.6871\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.20034\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.68196 to 0.68708, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00792224.\n",
      "64/64 [==============================] - 52s 820ms/step - loss: 1.3259 - accuracy: 0.6597 - val_loss: 1.1864 - val_accuracy: 0.6891\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.20034 to 1.18644, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.68708 to 0.68908, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.007855840000000001.\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 1.2928 - accuracy: 0.6712 - val_loss: 1.2627 - val_accuracy: 0.6929\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.18644\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.68908 to 0.69293, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0077897600000000015.\n",
      "64/64 [==============================] - 49s 766ms/step - loss: 1.2709 - accuracy: 0.6747 - val_loss: 1.0457 - val_accuracy: 0.7282\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.18644 to 1.04574, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.69293 to 0.72822, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.007724000000000001.\n",
      "64/64 [==============================] - 48s 753ms/step - loss: 1.2379 - accuracy: 0.6876 - val_loss: 1.1229 - val_accuracy: 0.7347\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.04574\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.72822 to 0.73470, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.007658560000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 51s 791ms/step - loss: 1.2112 - accuracy: 0.6927 - val_loss: 1.0057 - val_accuracy: 0.7287\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.04574 to 1.00570, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.73470\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.007593440000000001.\n",
      "64/64 [==============================] - 52s 813ms/step - loss: 1.1812 - accuracy: 0.7006 - val_loss: 1.0180 - val_accuracy: 0.7223\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.00570\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.73470\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.007528640000000001.\n",
      "64/64 [==============================] - 53s 824ms/step - loss: 1.1573 - accuracy: 0.7039 - val_loss: 1.0506 - val_accuracy: 0.7291\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.00570\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.73470\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.007464160000000001.\n",
      "64/64 [==============================] - 53s 826ms/step - loss: 1.1328 - accuracy: 0.7116 - val_loss: 1.0216 - val_accuracy: 0.7343\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.00570\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.73470\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.007400000000000001.\n",
      "64/64 [==============================] - 53s 821ms/step - loss: 1.1094 - accuracy: 0.7181 - val_loss: 1.1204 - val_accuracy: 0.7503\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.00570\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.73470 to 0.75032, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00733616.\n",
      "64/64 [==============================] - 53s 824ms/step - loss: 1.0805 - accuracy: 0.7236 - val_loss: 0.9802 - val_accuracy: 0.7523\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.00570 to 0.98016, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.75032 to 0.75232, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00727264.\n",
      "64/64 [==============================] - 52s 810ms/step - loss: 1.0587 - accuracy: 0.7298 - val_loss: 0.8990 - val_accuracy: 0.7511\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.98016 to 0.89895, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.75232\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.007209440000000001.\n",
      "64/64 [==============================] - 55s 856ms/step - loss: 1.0505 - accuracy: 0.7328 - val_loss: 0.9343 - val_accuracy: 0.7581\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.89895\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.75232 to 0.75807, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0071465600000000015.\n",
      "64/64 [==============================] - 52s 817ms/step - loss: 1.0211 - accuracy: 0.7383 - val_loss: 0.8825 - val_accuracy: 0.7631\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.89895 to 0.88252, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.75807 to 0.76313, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.007084000000000001.\n",
      "64/64 [==============================] - 50s 779ms/step - loss: 1.0045 - accuracy: 0.7429 - val_loss: 1.0070 - val_accuracy: 0.7620\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.88252\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.76313\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.007021760000000001.\n",
      "64/64 [==============================] - 51s 798ms/step - loss: 0.9908 - accuracy: 0.7450 - val_loss: 0.8902 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.88252\n",
      "\n",
      "Epoch 00057: val_accuracy improved from 0.76313 to 0.76667, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.006959840000000001.\n",
      "64/64 [==============================] - 53s 823ms/step - loss: 0.9792 - accuracy: 0.7522 - val_loss: 0.8375 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.88252 to 0.83751, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.76667 to 0.77252, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00689824.\n",
      "64/64 [==============================] - 49s 773ms/step - loss: 0.9620 - accuracy: 0.7523 - val_loss: 0.9183 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.83751\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.77252\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00683696.\n",
      "64/64 [==============================] - 49s 767ms/step - loss: 0.9423 - accuracy: 0.7605 - val_loss: 0.8485 - val_accuracy: 0.7680\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.83751\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.77252\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.006776.\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 0.9369 - accuracy: 0.7587 - val_loss: 0.8899 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.83751\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.77252 to 0.77611, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.006715360000000001.\n",
      "64/64 [==============================] - 48s 755ms/step - loss: 0.9171 - accuracy: 0.7633 - val_loss: 0.8561 - val_accuracy: 0.7682\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.83751\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.77611\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00665504.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 52s 812ms/step - loss: 0.9015 - accuracy: 0.7693 - val_loss: 0.8495 - val_accuracy: 0.7796\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.83751\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.77611 to 0.77964, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.00659504.\n",
      "64/64 [==============================] - 51s 801ms/step - loss: 0.8959 - accuracy: 0.7748 - val_loss: 0.8748 - val_accuracy: 0.7822\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.83751\n",
      "\n",
      "Epoch 00064: val_accuracy improved from 0.77964 to 0.78223, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0065353600000000005.\n",
      "64/64 [==============================] - 52s 807ms/step - loss: 0.8799 - accuracy: 0.7771 - val_loss: 0.8264 - val_accuracy: 0.7803\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.83751 to 0.82642, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.78223\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.006476.\n",
      "64/64 [==============================] - 51s 790ms/step - loss: 0.8737 - accuracy: 0.7770 - val_loss: 0.7646 - val_accuracy: 0.7931\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.82642 to 0.76460, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.78223 to 0.79314, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.006416959999999999.\n",
      "64/64 [==============================] - 51s 801ms/step - loss: 0.8665 - accuracy: 0.7809 - val_loss: 0.7575 - val_accuracy: 0.7884\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.76460 to 0.75746, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.79314\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.006358239999999999.\n",
      "64/64 [==============================] - 50s 781ms/step - loss: 0.8532 - accuracy: 0.7865 - val_loss: 0.7709 - val_accuracy: 0.7977\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.75746\n",
      "\n",
      "Epoch 00068: val_accuracy improved from 0.79314 to 0.79768, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.00629984.\n",
      "64/64 [==============================] - 54s 850ms/step - loss: 0.8490 - accuracy: 0.7855 - val_loss: 0.6717 - val_accuracy: 0.7939\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.75746 to 0.67173, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.79768\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.00624176.\n",
      "64/64 [==============================] - 56s 880ms/step - loss: 0.8265 - accuracy: 0.7916 - val_loss: 0.8756 - val_accuracy: 0.7967\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.67173\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.79768\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.006184.\n",
      "64/64 [==============================] - 56s 873ms/step - loss: 0.8194 - accuracy: 0.7914 - val_loss: 0.6840 - val_accuracy: 0.8064\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.67173\n",
      "\n",
      "Epoch 00071: val_accuracy improved from 0.79768 to 0.80643, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0061265600000000005.\n",
      "64/64 [==============================] - 53s 823ms/step - loss: 0.8061 - accuracy: 0.7974 - val_loss: 0.7860 - val_accuracy: 0.7973\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.67173\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.80643\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.00606944.\n",
      "64/64 [==============================] - 51s 795ms/step - loss: 0.8028 - accuracy: 0.7983 - val_loss: 0.7851 - val_accuracy: 0.7892\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.67173\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.80643\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.00601264.\n",
      "64/64 [==============================] - 49s 768ms/step - loss: 0.7932 - accuracy: 0.8027 - val_loss: 0.6629 - val_accuracy: 0.8071\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.67173 to 0.66289, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.80643 to 0.80707, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.005956159999999999.\n",
      "64/64 [==============================] - 51s 799ms/step - loss: 0.7806 - accuracy: 0.8043 - val_loss: 0.7443 - val_accuracy: 0.7971\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.66289\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.80707\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0059.\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 0.7777 - accuracy: 0.8076 - val_loss: 0.6125 - val_accuracy: 0.8080\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.66289 to 0.61249, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00076: val_accuracy improved from 0.80707 to 0.80796, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.005844159999999999.\n",
      "64/64 [==============================] - 51s 793ms/step - loss: 0.7689 - accuracy: 0.8075 - val_loss: 0.8582 - val_accuracy: 0.7998\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.80796\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.005788639999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 49s 764ms/step - loss: 0.7593 - accuracy: 0.8097 - val_loss: 0.7799 - val_accuracy: 0.8126\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00078: val_accuracy improved from 0.80796 to 0.81255, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.005733439999999999.\n",
      "64/64 [==============================] - 49s 767ms/step - loss: 0.7519 - accuracy: 0.8091 - val_loss: 0.7673 - val_accuracy: 0.8114\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.81255\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.005678559999999999.\n",
      "64/64 [==============================] - 50s 774ms/step - loss: 0.7429 - accuracy: 0.8124 - val_loss: 0.7274 - val_accuracy: 0.8099\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.81255\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.005624.\n",
      "64/64 [==============================] - 56s 876ms/step - loss: 0.7376 - accuracy: 0.8150 - val_loss: 0.7436 - val_accuracy: 0.8063\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.81255\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.005569759999999999.\n",
      "64/64 [==============================] - 57s 884ms/step - loss: 0.7287 - accuracy: 0.8158 - val_loss: 0.8537 - val_accuracy: 0.8032\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.81255\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.005515839999999999.\n",
      "64/64 [==============================] - 52s 808ms/step - loss: 0.7244 - accuracy: 0.8190 - val_loss: 0.6665 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00083: val_accuracy improved from 0.81255 to 0.82073, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.005462239999999999.\n",
      "64/64 [==============================] - 55s 852ms/step - loss: 0.7217 - accuracy: 0.8191 - val_loss: 0.6845 - val_accuracy: 0.8156\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.82073\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.005408959999999999.\n",
      "64/64 [==============================] - 47s 734ms/step - loss: 0.7084 - accuracy: 0.8255 - val_loss: 0.7052 - val_accuracy: 0.8169\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.82073\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.005355999999999999.\n",
      "64/64 [==============================] - 48s 746ms/step - loss: 0.7075 - accuracy: 0.8255 - val_loss: 0.7017 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.82073\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.005303360000000001.\n",
      "64/64 [==============================] - 49s 766ms/step - loss: 0.6926 - accuracy: 0.8291 - val_loss: 0.7267 - val_accuracy: 0.8142\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.82073\n",
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.00525104.\n",
      "64/64 [==============================] - 47s 734ms/step - loss: 0.6934 - accuracy: 0.8275 - val_loss: 0.7017 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.82073\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.00519904.\n",
      "64/64 [==============================] - 48s 744ms/step - loss: 0.6862 - accuracy: 0.8313 - val_loss: 0.7023 - val_accuracy: 0.8177\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.61249\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.82073\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.005147360000000001.\n",
      "64/64 [==============================] - 75s 1s/step - loss: 0.6734 - accuracy: 0.8329 - val_loss: 0.6055 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.61249 to 0.60549, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.82073\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.005096000000000001.\n",
      "64/64 [==============================] - 91s 1s/step - loss: 0.6686 - accuracy: 0.8351 - val_loss: 0.6872 - val_accuracy: 0.8220\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.60549\n",
      "\n",
      "Epoch 00091: val_accuracy improved from 0.82073 to 0.82205, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.00504496.\n",
      "64/64 [==============================] - 77s 1s/step - loss: 0.6619 - accuracy: 0.8350 - val_loss: 0.7381 - val_accuracy: 0.8217\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.60549\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.82205\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0049942400000000005.\n",
      "64/64 [==============================] - 48s 748ms/step - loss: 0.6593 - accuracy: 0.8362 - val_loss: 0.6602 - val_accuracy: 0.8218\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.60549\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.82205\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0049438400000000006.\n",
      "64/64 [==============================] - 66s 1s/step - loss: 0.6496 - accuracy: 0.8380 - val_loss: 0.7066 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.60549\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.82205 to 0.82289, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0048937600000000005.\n",
      "64/64 [==============================] - 59s 920ms/step - loss: 0.6394 - accuracy: 0.8409 - val_loss: 0.7341 - val_accuracy: 0.8271\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.60549\n",
      "\n",
      "Epoch 00095: val_accuracy improved from 0.82289 to 0.82711, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.004844.\n",
      "64/64 [==============================] - 53s 832ms/step - loss: 0.6376 - accuracy: 0.8400 - val_loss: 0.6073 - val_accuracy: 0.8223\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.60549\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.82711\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.00479456.\n",
      "64/64 [==============================] - 56s 871ms/step - loss: 0.6318 - accuracy: 0.8437 - val_loss: 0.5793 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.60549 to 0.57925, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.82711\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.00474544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 45s 700ms/step - loss: 0.6284 - accuracy: 0.8459 - val_loss: 0.6859 - val_accuracy: 0.8152\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.82711\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.00469664.\n",
      "64/64 [==============================] - 55s 855ms/step - loss: 0.6200 - accuracy: 0.8436 - val_loss: 0.6000 - val_accuracy: 0.8273\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00099: val_accuracy improved from 0.82711 to 0.82732, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.00464816.\n",
      "64/64 [==============================] - 49s 769ms/step - loss: 0.6243 - accuracy: 0.8448 - val_loss: 0.7200 - val_accuracy: 0.8313\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00100: val_accuracy improved from 0.82732 to 0.83133, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0046.\n",
      "64/64 [==============================] - 46s 723ms/step - loss: 0.6125 - accuracy: 0.8502 - val_loss: 0.6378 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00101: val_accuracy improved from 0.83133 to 0.83344, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.0045521599999999995.\n",
      "64/64 [==============================] - 34s 533ms/step - loss: 0.6109 - accuracy: 0.8494 - val_loss: 0.6968 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.83344\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.004504640000000001.\n",
      "64/64 [==============================] - 48s 756ms/step - loss: 0.6038 - accuracy: 0.8520 - val_loss: 0.6007 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.83344\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.004457440000000002.\n",
      "64/64 [==============================] - 47s 737ms/step - loss: 0.5989 - accuracy: 0.8563 - val_loss: 0.6091 - val_accuracy: 0.8326\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.83344\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.004410560000000001.\n",
      "64/64 [==============================] - 44s 694ms/step - loss: 0.5967 - accuracy: 0.8551 - val_loss: 0.6972 - val_accuracy: 0.8360\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00105: val_accuracy improved from 0.83344 to 0.83602, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.0043640000000000016.\n",
      "64/64 [==============================] - 48s 744ms/step - loss: 0.5908 - accuracy: 0.8543 - val_loss: 0.6262 - val_accuracy: 0.8295\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.83602\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.00431776.\n",
      "64/64 [==============================] - 55s 860ms/step - loss: 0.5890 - accuracy: 0.8567 - val_loss: 0.5923 - val_accuracy: 0.8323\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.57925\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.83602\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.004271840000000001.\n",
      "64/64 [==============================] - 49s 770ms/step - loss: 0.5816 - accuracy: 0.8585 - val_loss: 0.5163 - val_accuracy: 0.8358\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.57925 to 0.51631, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.83602\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.004226240000000001.\n",
      "64/64 [==============================] - 46s 716ms/step - loss: 0.5729 - accuracy: 0.8602 - val_loss: 0.5823 - val_accuracy: 0.8336\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.83602\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.004180960000000001.\n",
      "64/64 [==============================] - 46s 726ms/step - loss: 0.5744 - accuracy: 0.8618 - val_loss: 0.6155 - val_accuracy: 0.8328\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.83602\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.004136000000000001.\n",
      "64/64 [==============================] - 48s 750ms/step - loss: 0.5690 - accuracy: 0.8636 - val_loss: 0.6714 - val_accuracy: 0.8284\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.83602\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0040913600000000005.\n",
      "64/64 [==============================] - 50s 780ms/step - loss: 0.5684 - accuracy: 0.8635 - val_loss: 0.5677 - val_accuracy: 0.8290\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.83602\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.00404704.\n",
      "64/64 [==============================] - 47s 739ms/step - loss: 0.5579 - accuracy: 0.8693 - val_loss: 0.6650 - val_accuracy: 0.8319\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.83602\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.004003040000000001.\n",
      "64/64 [==============================] - 48s 750ms/step - loss: 0.5581 - accuracy: 0.8661 - val_loss: 0.6115 - val_accuracy: 0.8294\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.83602\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.00395936.\n",
      "64/64 [==============================] - 49s 761ms/step - loss: 0.5508 - accuracy: 0.8670 - val_loss: 0.6401 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.83602\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.003916.\n",
      "64/64 [==============================] - 50s 786ms/step - loss: 0.5494 - accuracy: 0.8682 - val_loss: 0.5576 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.83602\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0038729600000000004.\n",
      "64/64 [==============================] - 46s 718ms/step - loss: 0.5475 - accuracy: 0.8684 - val_loss: 0.6350 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00117: val_accuracy improved from 0.83602 to 0.83808, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.003830240000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 49s 759ms/step - loss: 0.5469 - accuracy: 0.8701 - val_loss: 0.7354 - val_accuracy: 0.8303\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.83808\n",
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0037878400000000002.\n",
      "64/64 [==============================] - 49s 760ms/step - loss: 0.5376 - accuracy: 0.8715 - val_loss: 0.7031 - val_accuracy: 0.8370\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.83808\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0037457600000000003.\n",
      "64/64 [==============================] - 50s 778ms/step - loss: 0.5327 - accuracy: 0.8735 - val_loss: 0.6206 - val_accuracy: 0.8387\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00120: val_accuracy improved from 0.83808 to 0.83871, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0037040000000000003.\n",
      "64/64 [==============================] - 50s 780ms/step - loss: 0.5331 - accuracy: 0.8741 - val_loss: 0.5792 - val_accuracy: 0.8415\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00121: val_accuracy improved from 0.83871 to 0.84146, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.00366256.\n",
      "64/64 [==============================] - 49s 758ms/step - loss: 0.5276 - accuracy: 0.8733 - val_loss: 0.5736 - val_accuracy: 0.8385\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.84146\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.00362144.\n",
      "64/64 [==============================] - 48s 758ms/step - loss: 0.5338 - accuracy: 0.8718 - val_loss: 0.5849 - val_accuracy: 0.8421\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00123: val_accuracy improved from 0.84146 to 0.84214, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0035806400000000004.\n",
      "64/64 [==============================] - 45s 706ms/step - loss: 0.5291 - accuracy: 0.8760 - val_loss: 0.6482 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00124: val_accuracy improved from 0.84214 to 0.84541, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.00354016.\n",
      "64/64 [==============================] - 49s 767ms/step - loss: 0.5178 - accuracy: 0.8767 - val_loss: 0.5187 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00125: val_accuracy improved from 0.84541 to 0.84657, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0035.\n",
      "64/64 [==============================] - 51s 791ms/step - loss: 0.5190 - accuracy: 0.8774 - val_loss: 0.5929 - val_accuracy: 0.8391\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.84657\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.00346016.\n",
      "64/64 [==============================] - 47s 738ms/step - loss: 0.5153 - accuracy: 0.8792 - val_loss: 0.6026 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.84657\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.00342064.\n",
      "64/64 [==============================] - 99s 2s/step - loss: 0.5158 - accuracy: 0.8793 - val_loss: 0.6111 - val_accuracy: 0.8382\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.84657\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.00338144.\n",
      "64/64 [==============================] - 96s 2s/step - loss: 0.5086 - accuracy: 0.8806 - val_loss: 0.5832 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.84657\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.00334256.\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 0.5021 - accuracy: 0.8814 - val_loss: 0.6516 - val_accuracy: 0.8437\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.84657\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.003304.\n",
      "64/64 [==============================] - 107s 2s/step - loss: 0.5015 - accuracy: 0.8815 - val_loss: 0.5060 - val_accuracy: 0.8467\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.51631 to 0.50602, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00131: val_accuracy improved from 0.84657 to 0.84668, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.00326576.\n",
      "64/64 [==============================] - 53s 821ms/step - loss: 0.4960 - accuracy: 0.8811 - val_loss: 0.5330 - val_accuracy: 0.8407\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.84668\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.00322784.\n",
      "64/64 [==============================] - 84s 1s/step - loss: 0.4946 - accuracy: 0.8833 - val_loss: 0.5105 - val_accuracy: 0.8434\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.84668\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0031902399999999996.\n",
      "64/64 [==============================] - 90s 1s/step - loss: 0.4925 - accuracy: 0.8859 - val_loss: 0.6551 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00134: val_accuracy improved from 0.84668 to 0.84773, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 135/2000\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.00315296.\n",
      "64/64 [==============================] - 60s 943ms/step - loss: 0.4937 - accuracy: 0.8855 - val_loss: 0.5690 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00135: val_accuracy improved from 0.84773 to 0.84831, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0031159999999999994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 154s 2s/step - loss: 0.4869 - accuracy: 0.8899 - val_loss: 0.6756 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.84831\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0030793599999999997.\n",
      "64/64 [==============================] - 92s 1s/step - loss: 0.4844 - accuracy: 0.8924 - val_loss: 0.5661 - val_accuracy: 0.8451\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.84831\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0030430399999999995.\n",
      "64/64 [==============================] - 47s 741ms/step - loss: 0.4819 - accuracy: 0.8907 - val_loss: 0.5912 - val_accuracy: 0.8450\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.84831\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.00300704.\n",
      "64/64 [==============================] - 67s 1s/step - loss: 0.4838 - accuracy: 0.8876 - val_loss: 0.5131 - val_accuracy: 0.8431\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.84831\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0029713599999999997.\n",
      "18/64 [=======>......................] - ETA: 1:08 - loss: 0.4761 - accuracy: 0.8919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/keras/utils/data_utils.py:718: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 10234s 160s/step - loss: 0.4676 - accuracy: 0.8949 - val_loss: 0.6487 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.84831\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.002936.\n",
      "64/64 [==============================] - 699s 11s/step - loss: 0.4775 - accuracy: 0.8910 - val_loss: 0.5203 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.84831\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.00290096.\n",
      "64/64 [==============================] - 614s 10s/step - loss: 0.4700 - accuracy: 0.8929 - val_loss: 0.5523 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.84831\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0028662400000000004.\n",
      "64/64 [==============================] - 150s 2s/step - loss: 0.4744 - accuracy: 0.8930 - val_loss: 0.5815 - val_accuracy: 0.8451\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.84831\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0028318400000000004.\n",
      "64/64 [==============================] - 34s 535ms/step - loss: 0.4707 - accuracy: 0.8909 - val_loss: 0.5068 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00144: val_accuracy improved from 0.84831 to 0.84968, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0027977600000000007.\n",
      "64/64 [==============================] - 33s 509ms/step - loss: 0.4681 - accuracy: 0.8922 - val_loss: 0.6263 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.84968\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0027640000000000004.\n",
      "64/64 [==============================] - 32s 500ms/step - loss: 0.4635 - accuracy: 0.8956 - val_loss: 0.5767 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.84968\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.002730560000000001.\n",
      "64/64 [==============================] - 35s 543ms/step - loss: 0.4597 - accuracy: 0.8971 - val_loss: 0.6510 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.84968\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0026974400000000006.\n",
      "64/64 [==============================] - 32s 504ms/step - loss: 0.4559 - accuracy: 0.8969 - val_loss: 0.5205 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.50602\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.84968\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0026646400000000002.\n",
      "64/64 [==============================] - 31s 480ms/step - loss: 0.4617 - accuracy: 0.8970 - val_loss: 0.4709 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.50602 to 0.47090, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.84968\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0026321600000000006.\n",
      "64/64 [==============================] - 34s 532ms/step - loss: 0.4527 - accuracy: 0.8990 - val_loss: 0.5846 - val_accuracy: 0.8473\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.47090\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.84968\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.0026000000000000003.\n",
      "64/64 [==============================] - 30s 468ms/step - loss: 0.4562 - accuracy: 0.8961 - val_loss: 0.6895 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.47090\n",
      "\n",
      "Epoch 00151: val_accuracy improved from 0.84968 to 0.85037, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.00256816.\n",
      "64/64 [==============================] - 31s 479ms/step - loss: 0.4503 - accuracy: 0.8974 - val_loss: 0.6078 - val_accuracy: 0.8491\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.47090\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.85037\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.0025366400000000006.\n",
      "64/64 [==============================] - 27s 425ms/step - loss: 0.4501 - accuracy: 0.8990 - val_loss: 0.5960 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.47090\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.85037\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.0025054400000000003.\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.4473 - accuracy: 0.8980 - val_loss: 0.6437 - val_accuracy: 0.8515\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.47090\n",
      "\n",
      "Epoch 00154: val_accuracy improved from 0.85037 to 0.85148, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.0024745599999999998.\n",
      "64/64 [==============================] - 34s 537ms/step - loss: 0.4434 - accuracy: 0.9004 - val_loss: 0.6418 - val_accuracy: 0.8480\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.47090\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.85148\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.002444.\n",
      "64/64 [==============================] - 30s 475ms/step - loss: 0.4483 - accuracy: 0.8992 - val_loss: 0.4880 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.47090\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.85148\n",
      "Epoch 157/2000\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.00241376.\n",
      "64/64 [==============================] - 38s 594ms/step - loss: 0.4422 - accuracy: 0.9031 - val_loss: 0.4634 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.47090 to 0.46338, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.85148\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.00238384.\n",
      "64/64 [==============================] - 37s 574ms/step - loss: 0.4347 - accuracy: 0.9046 - val_loss: 0.4906 - val_accuracy: 0.8425\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.46338\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.85148\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.0023542399999999996.\n",
      "64/64 [==============================] - 36s 567ms/step - loss: 0.4347 - accuracy: 0.9041 - val_loss: 0.5005 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.46338\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.85148\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.00232496.\n",
      "64/64 [==============================] - 35s 548ms/step - loss: 0.4385 - accuracy: 0.9014 - val_loss: 0.4534 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.46338 to 0.45342, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.85148\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0022960000000000003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 30s 474ms/step - loss: 0.4336 - accuracy: 0.9041 - val_loss: 0.5415 - val_accuracy: 0.8535\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.45342\n",
      "\n",
      "Epoch 00161: val_accuracy improved from 0.85148 to 0.85353, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.00226736.\n",
      "64/64 [==============================] - 31s 478ms/step - loss: 0.4335 - accuracy: 0.9040 - val_loss: 0.5372 - val_accuracy: 0.8543\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.45342\n",
      "\n",
      "Epoch 00162: val_accuracy improved from 0.85353 to 0.85427, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.00223904.\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 0.4342 - accuracy: 0.9008 - val_loss: 0.4873 - val_accuracy: 0.8476\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.45342\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.85427\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.00221104.\n",
      "64/64 [==============================] - 40s 632ms/step - loss: 0.4267 - accuracy: 0.9047 - val_loss: 0.5621 - val_accuracy: 0.8463\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.45342\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.85427\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.0021833599999999996.\n",
      "64/64 [==============================] - 42s 659ms/step - loss: 0.4281 - accuracy: 0.9036 - val_loss: 0.5484 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.45342\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.85427\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.002156.\n",
      "64/64 [==============================] - 46s 724ms/step - loss: 0.4249 - accuracy: 0.9060 - val_loss: 0.5370 - val_accuracy: 0.8509\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.45342\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.85427\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.00212896.\n",
      "64/64 [==============================] - 52s 809ms/step - loss: 0.4188 - accuracy: 0.9073 - val_loss: 0.4367 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.45342 to 0.43675, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.85427\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.00210224.\n",
      "64/64 [==============================] - 188s 3s/step - loss: 0.4199 - accuracy: 0.9044 - val_loss: 0.6313 - val_accuracy: 0.8473\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.85427\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.00207584.\n",
      "64/64 [==============================] - 87s 1s/step - loss: 0.4182 - accuracy: 0.9055 - val_loss: 0.5627 - val_accuracy: 0.8521\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.85427\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.00204976.\n",
      "64/64 [==============================] - 73s 1s/step - loss: 0.4185 - accuracy: 0.9056 - val_loss: 0.6107 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.85427\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.0020239999999999998.\n",
      "64/64 [==============================] - 129s 2s/step - loss: 0.4147 - accuracy: 0.9079 - val_loss: 0.5762 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.85427\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.00199856.\n",
      "64/64 [==============================] - 50s 781ms/step - loss: 0.4146 - accuracy: 0.9078 - val_loss: 0.6160 - val_accuracy: 0.8471\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.85427\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.0019734400000000004.\n",
      "64/64 [==============================] - 48s 746ms/step - loss: 0.4088 - accuracy: 0.9086 - val_loss: 0.5995 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.85427\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.0019486400000000004.\n",
      "64/64 [==============================] - 47s 730ms/step - loss: 0.4125 - accuracy: 0.9070 - val_loss: 0.4838 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.85427\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.0019241600000000003.\n",
      "64/64 [==============================] - 45s 710ms/step - loss: 0.4123 - accuracy: 0.9091 - val_loss: 0.5421 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.85427\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.0019000000000000002.\n",
      "64/64 [==============================] - 45s 702ms/step - loss: 0.4015 - accuracy: 0.9085 - val_loss: 0.6073 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.85427\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.0018761600000000004.\n",
      "64/64 [==============================] - 48s 745ms/step - loss: 0.4030 - accuracy: 0.9114 - val_loss: 0.5144 - val_accuracy: 0.8551\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00177: val_accuracy improved from 0.85427 to 0.85506, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.0018526400000000002.\n",
      "64/64 [==============================] - 45s 698ms/step - loss: 0.4051 - accuracy: 0.9129 - val_loss: 0.5394 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.85506\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.0018294400000000003.\n",
      "64/64 [==============================] - 47s 742ms/step - loss: 0.4072 - accuracy: 0.9095 - val_loss: 0.6020 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.85506\n",
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.0018065600000000002.\n",
      "64/64 [==============================] - 53s 828ms/step - loss: 0.4049 - accuracy: 0.9123 - val_loss: 0.5578 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.85506\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.001784.\n",
      "64/64 [==============================] - 68s 1s/step - loss: 0.4011 - accuracy: 0.9163 - val_loss: 0.5766 - val_accuracy: 0.8545\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.85506\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.0017617600000000002.\n",
      "64/64 [==============================] - 30s 469ms/step - loss: 0.3993 - accuracy: 0.9154 - val_loss: 0.5572 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.85506\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.00173984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 133s 2s/step - loss: 0.3976 - accuracy: 0.9127 - val_loss: 0.5439 - val_accuracy: 0.8518\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.85506\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.0017182400000000002.\n",
      "64/64 [==============================] - 65s 1s/step - loss: 0.3971 - accuracy: 0.9132 - val_loss: 0.4632 - val_accuracy: 0.8527\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.85506\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.00169696.\n",
      "64/64 [==============================] - 63s 992ms/step - loss: 0.3961 - accuracy: 0.9144 - val_loss: 0.5358 - val_accuracy: 0.8520\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.85506\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.001676.\n",
      "64/64 [==============================] - 58s 914ms/step - loss: 0.3922 - accuracy: 0.9144 - val_loss: 0.6317 - val_accuracy: 0.8539\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.85506\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.00165536.\n",
      "64/64 [==============================] - 69s 1s/step - loss: 0.3934 - accuracy: 0.9128 - val_loss: 0.5591 - val_accuracy: 0.8488\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.85506\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.00163504.\n",
      "64/64 [==============================] - 57s 894ms/step - loss: 0.3889 - accuracy: 0.9155 - val_loss: 0.6031 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.85506\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.0016150399999999999.\n",
      "64/64 [==============================] - 94s 1s/step - loss: 0.3868 - accuracy: 0.9161 - val_loss: 0.6194 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00189: val_accuracy improved from 0.85506 to 0.85612, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.00159536.\n",
      "64/64 [==============================] - 55s 854ms/step - loss: 0.3867 - accuracy: 0.9157 - val_loss: 0.5084 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.85612\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0015760000000000001.\n",
      "64/64 [==============================] - 60s 944ms/step - loss: 0.3843 - accuracy: 0.9170 - val_loss: 0.5181 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.85612\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.00155696.\n",
      "64/64 [==============================] - 50s 782ms/step - loss: 0.3880 - accuracy: 0.9159 - val_loss: 0.5440 - val_accuracy: 0.8534\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.85612\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.00153824.\n",
      "64/64 [==============================] - 46s 726ms/step - loss: 0.3840 - accuracy: 0.9182 - val_loss: 0.4558 - val_accuracy: 0.8512\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.85612\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.00151984.\n",
      "64/64 [==============================] - 44s 686ms/step - loss: 0.3845 - accuracy: 0.9150 - val_loss: 0.6199 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.85612\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.00150176.\n",
      "64/64 [==============================] - 44s 688ms/step - loss: 0.3858 - accuracy: 0.9161 - val_loss: 0.5844 - val_accuracy: 0.8532\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.85612\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.001484.\n",
      "64/64 [==============================] - 45s 707ms/step - loss: 0.3817 - accuracy: 0.9168 - val_loss: 0.4796 - val_accuracy: 0.8532\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.85612\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.00146656.\n",
      "64/64 [==============================] - 48s 755ms/step - loss: 0.3808 - accuracy: 0.9150 - val_loss: 0.5815 - val_accuracy: 0.8540\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.85612\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.0014494399999999998.\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 0.3767 - accuracy: 0.9183 - val_loss: 0.5864 - val_accuracy: 0.8540\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.85612\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.0014326399999999998.\n",
      "64/64 [==============================] - 47s 737ms/step - loss: 0.3779 - accuracy: 0.9187 - val_loss: 0.5496 - val_accuracy: 0.8527\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.85612\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.0014161599999999999.\n",
      "64/64 [==============================] - 38s 593ms/step - loss: 0.3765 - accuracy: 0.9169 - val_loss: 0.5657 - val_accuracy: 0.8528\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.85612\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.0013999999999999998.\n",
      "64/64 [==============================] - 47s 741ms/step - loss: 0.3761 - accuracy: 0.9199 - val_loss: 0.5291 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00201: val_accuracy improved from 0.85612 to 0.85807, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.0013841599999999997.\n",
      "64/64 [==============================] - 58s 913ms/step - loss: 0.3739 - accuracy: 0.9208 - val_loss: 0.5537 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.85807\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.00136864.\n",
      "64/64 [==============================] - 284s 4s/step - loss: 0.3731 - accuracy: 0.9220 - val_loss: 0.5134 - val_accuracy: 0.8557\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.85807\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.0013534399999999998.\n",
      "64/64 [==============================] - 47s 727ms/step - loss: 0.3716 - accuracy: 0.9213 - val_loss: 0.5391 - val_accuracy: 0.8530\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.85807\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.0013385600000000001.\n",
      "64/64 [==============================] - 53s 833ms/step - loss: 0.3723 - accuracy: 0.9209 - val_loss: 0.6075 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.85807\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.001324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 57s 887ms/step - loss: 0.3752 - accuracy: 0.9199 - val_loss: 0.6053 - val_accuracy: 0.8568\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.85807\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.00130976.\n",
      "64/64 [==============================] - 70s 1s/step - loss: 0.3716 - accuracy: 0.9192 - val_loss: 0.5035 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.85807\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.0012958400000000001.\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 0.3672 - accuracy: 0.9208 - val_loss: 0.4736 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.85807\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.00128224.\n",
      "64/64 [==============================] - 55s 852ms/step - loss: 0.3732 - accuracy: 0.9193 - val_loss: 0.5828 - val_accuracy: 0.8509\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.85807\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.0012689600000000002.\n",
      "64/64 [==============================] - 46s 724ms/step - loss: 0.3622 - accuracy: 0.9215 - val_loss: 0.5374 - val_accuracy: 0.8527\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.85807\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.0012560000000000002.\n",
      "64/64 [==============================] - 60s 943ms/step - loss: 0.3667 - accuracy: 0.9203 - val_loss: 0.4947 - val_accuracy: 0.8544\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.85807\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.0012433600000000002.\n",
      "64/64 [==============================] - 48s 751ms/step - loss: 0.3650 - accuracy: 0.9233 - val_loss: 0.5462 - val_accuracy: 0.8555\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.85807\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.00123104.\n",
      "64/64 [==============================] - 54s 844ms/step - loss: 0.3641 - accuracy: 0.9224 - val_loss: 0.5656 - val_accuracy: 0.8509\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.85807\n",
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.00121904.\n",
      "64/64 [==============================] - 52s 818ms/step - loss: 0.3599 - accuracy: 0.9237 - val_loss: 0.5386 - val_accuracy: 0.8567\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.85807\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.00120736.\n",
      "64/64 [==============================] - 49s 765ms/step - loss: 0.3599 - accuracy: 0.9267 - val_loss: 0.5108 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00215: val_accuracy improved from 0.85807 to 0.85833, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.001196.\n",
      "64/64 [==============================] - 60s 942ms/step - loss: 0.3627 - accuracy: 0.9218 - val_loss: 0.5667 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.85833\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.00118496.\n",
      "64/64 [==============================] - 63s 984ms/step - loss: 0.3603 - accuracy: 0.9239 - val_loss: 0.5361 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.85833\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.00117424.\n",
      "64/64 [==============================] - 49s 771ms/step - loss: 0.3586 - accuracy: 0.9255 - val_loss: 0.5087 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.85833\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.00116384.\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 0.3578 - accuracy: 0.9248 - val_loss: 0.5733 - val_accuracy: 0.8544\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.85833\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.00115376.\n",
      "64/64 [==============================] - 48s 748ms/step - loss: 0.3573 - accuracy: 0.9230 - val_loss: 0.4683 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.85833\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.001144.\n",
      "64/64 [==============================] - 49s 773ms/step - loss: 0.3515 - accuracy: 0.9254 - val_loss: 0.5472 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.85833\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.00113456.\n",
      "64/64 [==============================] - 50s 776ms/step - loss: 0.3565 - accuracy: 0.9247 - val_loss: 0.5483 - val_accuracy: 0.8551\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.85833\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.0011254400000000001.\n",
      "64/64 [==============================] - 53s 833ms/step - loss: 0.3552 - accuracy: 0.9267 - val_loss: 0.4705 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.85833\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.00111664.\n",
      "64/64 [==============================] - 51s 801ms/step - loss: 0.3533 - accuracy: 0.9253 - val_loss: 0.5099 - val_accuracy: 0.8579\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.85833\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.00110816.\n",
      "64/64 [==============================] - 49s 763ms/step - loss: 0.3515 - accuracy: 0.9273 - val_loss: 0.4818 - val_accuracy: 0.8565\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.85833\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.0011.\n",
      "64/64 [==============================] - 49s 763ms/step - loss: 0.3573 - accuracy: 0.9244 - val_loss: 0.5783 - val_accuracy: 0.8585\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00226: val_accuracy improved from 0.85833 to 0.85849, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.00109216.\n",
      "64/64 [==============================] - 54s 838ms/step - loss: 0.3514 - accuracy: 0.9263 - val_loss: 0.4865 - val_accuracy: 0.8574\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.85849\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.00108464.\n",
      "64/64 [==============================] - 50s 789ms/step - loss: 0.3509 - accuracy: 0.9277 - val_loss: 0.5949 - val_accuracy: 0.8568\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.85849\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.00107744.\n",
      "64/64 [==============================] - 54s 839ms/step - loss: 0.3477 - accuracy: 0.9264 - val_loss: 0.5443 - val_accuracy: 0.8585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00229: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00229: val_accuracy improved from 0.85849 to 0.85854, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.00107056.\n",
      "64/64 [==============================] - 55s 858ms/step - loss: 0.3457 - accuracy: 0.9301 - val_loss: 0.6159 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00230: val_accuracy improved from 0.85854 to 0.85870, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.0010639999999999998.\n",
      "64/64 [==============================] - 49s 761ms/step - loss: 0.3472 - accuracy: 0.9289 - val_loss: 0.6244 - val_accuracy: 0.8572\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.85870\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.00105776.\n",
      "64/64 [==============================] - 51s 791ms/step - loss: 0.3504 - accuracy: 0.9290 - val_loss: 0.5686 - val_accuracy: 0.8596\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00232: val_accuracy improved from 0.85870 to 0.85960, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.00105184.\n",
      "64/64 [==============================] - 54s 837ms/step - loss: 0.3517 - accuracy: 0.9283 - val_loss: 0.6888 - val_accuracy: 0.8559\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.85960\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.00104624.\n",
      "64/64 [==============================] - 53s 824ms/step - loss: 0.3451 - accuracy: 0.9279 - val_loss: 0.5231 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.85960\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0010409599999999998.\n",
      "64/64 [==============================] - 51s 792ms/step - loss: 0.3503 - accuracy: 0.9278 - val_loss: 0.5640 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00235: val_accuracy improved from 0.85960 to 0.86076, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.001036.\n",
      "64/64 [==============================] - 51s 800ms/step - loss: 0.3477 - accuracy: 0.9289 - val_loss: 0.5245 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.86076\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.00103136.\n",
      "64/64 [==============================] - 50s 786ms/step - loss: 0.3510 - accuracy: 0.9283 - val_loss: 0.5395 - val_accuracy: 0.8630\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00237: val_accuracy improved from 0.86076 to 0.86303, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0010270400000000001.\n",
      "64/64 [==============================] - 52s 815ms/step - loss: 0.3430 - accuracy: 0.9308 - val_loss: 0.5241 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.86303\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.00102304.\n",
      "64/64 [==============================] - 50s 783ms/step - loss: 0.3439 - accuracy: 0.9305 - val_loss: 0.6568 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.86303\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.00101936.\n",
      "64/64 [==============================] - 50s 782ms/step - loss: 0.3432 - accuracy: 0.9294 - val_loss: 0.5511 - val_accuracy: 0.8588\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.86303\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.001016.\n",
      "64/64 [==============================] - 49s 764ms/step - loss: 0.3485 - accuracy: 0.9290 - val_loss: 0.5132 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.86303\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.00101296.\n",
      "64/64 [==============================] - 49s 762ms/step - loss: 0.3440 - accuracy: 0.9291 - val_loss: 0.5066 - val_accuracy: 0.8572\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.86303\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.0010102400000000001.\n",
      "64/64 [==============================] - 51s 793ms/step - loss: 0.3477 - accuracy: 0.9272 - val_loss: 0.4878 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.86303\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.00100784.\n",
      "64/64 [==============================] - 49s 767ms/step - loss: 0.3421 - accuracy: 0.9279 - val_loss: 0.4977 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.86303\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.00100576.\n",
      "64/64 [==============================] - 49s 771ms/step - loss: 0.3421 - accuracy: 0.9280 - val_loss: 0.6196 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.86303\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.0010040000000000001.\n",
      "64/64 [==============================] - 55s 860ms/step - loss: 0.3411 - accuracy: 0.9277 - val_loss: 0.5247 - val_accuracy: 0.8564\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.86303\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.00100256.\n",
      "64/64 [==============================] - 51s 803ms/step - loss: 0.3403 - accuracy: 0.9303 - val_loss: 0.5605 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.86303\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.00100144.\n",
      "64/64 [==============================] - 50s 774ms/step - loss: 0.3382 - accuracy: 0.9273 - val_loss: 0.5236 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.86303\n",
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.0010006400000000001.\n",
      "64/64 [==============================] - 50s 779ms/step - loss: 0.3402 - accuracy: 0.9291 - val_loss: 0.5117 - val_accuracy: 0.8565\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.86303\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.00100016.\n",
      "64/64 [==============================] - 52s 811ms/step - loss: 0.3398 - accuracy: 0.9314 - val_loss: 0.4531 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.86303\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 55s 852ms/step - loss: 0.3423 - accuracy: 0.9306 - val_loss: 0.5328 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.86303\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 831ms/step - loss: 0.3361 - accuracy: 0.9297 - val_loss: 0.5899 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.86303\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 805ms/step - loss: 0.3407 - accuracy: 0.9284 - val_loss: 0.5258 - val_accuracy: 0.8567\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.86303\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 829ms/step - loss: 0.3393 - accuracy: 0.9308 - val_loss: 0.4667 - val_accuracy: 0.8569\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.86303\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 826ms/step - loss: 0.3386 - accuracy: 0.9266 - val_loss: 0.5240 - val_accuracy: 0.8514\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.86303\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 843ms/step - loss: 0.3414 - accuracy: 0.9253 - val_loss: 0.5388 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.86303\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 56s 870ms/step - loss: 0.3392 - accuracy: 0.9279 - val_loss: 0.5643 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.86303\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 55s 864ms/step - loss: 0.3425 - accuracy: 0.9278 - val_loss: 0.6199 - val_accuracy: 0.8564\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.86303\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 810ms/step - loss: 0.3389 - accuracy: 0.9299 - val_loss: 0.5039 - val_accuracy: 0.8553\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.86303\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 848ms/step - loss: 0.3352 - accuracy: 0.9292 - val_loss: 0.5349 - val_accuracy: 0.8559\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.86303\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 60s 940ms/step - loss: 0.3352 - accuracy: 0.9297 - val_loss: 0.6237 - val_accuracy: 0.8537\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.86303\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 55s 859ms/step - loss: 0.3355 - accuracy: 0.9300 - val_loss: 0.5712 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.86303\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 140s 2s/step - loss: 0.3376 - accuracy: 0.9301 - val_loss: 0.6251 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.86303\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 842ms/step - loss: 0.3353 - accuracy: 0.9297 - val_loss: 0.5297 - val_accuracy: 0.8572\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.86303\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 817ms/step - loss: 0.3325 - accuracy: 0.9309 - val_loss: 0.5396 - val_accuracy: 0.8555\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.86303\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 828ms/step - loss: 0.3338 - accuracy: 0.9296 - val_loss: 0.5095 - val_accuracy: 0.8578\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.86303\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 62s 968ms/step - loss: 0.3384 - accuracy: 0.9283 - val_loss: 0.5953 - val_accuracy: 0.8541\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.86303\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 819ms/step - loss: 0.3377 - accuracy: 0.9297 - val_loss: 0.6096 - val_accuracy: 0.8568\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.86303\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 827ms/step - loss: 0.3299 - accuracy: 0.9303 - val_loss: 0.5688 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.86303\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 797ms/step - loss: 0.3347 - accuracy: 0.9299 - val_loss: 0.5205 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.86303\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 797ms/step - loss: 0.3342 - accuracy: 0.9315 - val_loss: 0.5301 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.86303\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 850ms/step - loss: 0.3332 - accuracy: 0.9322 - val_loss: 0.5547 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.86303\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 845ms/step - loss: 0.3302 - accuracy: 0.9310 - val_loss: 0.5394 - val_accuracy: 0.8543\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.86303\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 807ms/step - loss: 0.3301 - accuracy: 0.9326 - val_loss: 0.4701 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.86303\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 800ms/step - loss: 0.3327 - accuracy: 0.9321 - val_loss: 0.5744 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.86303\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 844ms/step - loss: 0.3329 - accuracy: 0.9318 - val_loss: 0.6105 - val_accuracy: 0.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00276: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.86303\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 55s 854ms/step - loss: 0.3296 - accuracy: 0.9322 - val_loss: 0.4751 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.86303\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 828ms/step - loss: 0.3333 - accuracy: 0.9327 - val_loss: 0.5767 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.86303\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 810ms/step - loss: 0.3252 - accuracy: 0.9346 - val_loss: 0.5079 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.86303\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 801ms/step - loss: 0.3304 - accuracy: 0.9294 - val_loss: 0.4802 - val_accuracy: 0.8566\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.86303\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 814ms/step - loss: 0.3280 - accuracy: 0.9305 - val_loss: 0.5697 - val_accuracy: 0.8539\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.86303\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 811ms/step - loss: 0.3254 - accuracy: 0.9308 - val_loss: 0.5921 - val_accuracy: 0.8555\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.86303\n",
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 784ms/step - loss: 0.3304 - accuracy: 0.9291 - val_loss: 0.5897 - val_accuracy: 0.8543\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.86303\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 812ms/step - loss: 0.3262 - accuracy: 0.9313 - val_loss: 0.4725 - val_accuracy: 0.8575\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.86303\n",
      "Epoch 285/2000\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 825ms/step - loss: 0.3347 - accuracy: 0.9285 - val_loss: 0.6353 - val_accuracy: 0.8541\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.86303\n",
      "Epoch 286/2000\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 803ms/step - loss: 0.3236 - accuracy: 0.9314 - val_loss: 0.5178 - val_accuracy: 0.8575\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.86303\n",
      "Epoch 287/2000\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 847ms/step - loss: 0.3236 - accuracy: 0.9311 - val_loss: 0.5270 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.86303\n",
      "Epoch 288/2000\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 56s 874ms/step - loss: 0.3284 - accuracy: 0.9318 - val_loss: 0.6118 - val_accuracy: 0.8554\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.86303\n",
      "Epoch 289/2000\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 56s 875ms/step - loss: 0.3328 - accuracy: 0.9290 - val_loss: 0.6184 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.86303\n",
      "Epoch 290/2000\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 55s 857ms/step - loss: 0.3299 - accuracy: 0.9310 - val_loss: 0.5960 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.86303\n",
      "Epoch 291/2000\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 803ms/step - loss: 0.3276 - accuracy: 0.9332 - val_loss: 0.5572 - val_accuracy: 0.8557\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.86303\n",
      "Epoch 292/2000\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 784ms/step - loss: 0.3243 - accuracy: 0.9340 - val_loss: 0.4807 - val_accuracy: 0.8621\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.86303\n",
      "Epoch 293/2000\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 795ms/step - loss: 0.3254 - accuracy: 0.9345 - val_loss: 0.5571 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.86303\n",
      "Epoch 294/2000\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 847ms/step - loss: 0.3260 - accuracy: 0.9316 - val_loss: 0.4525 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.86303\n",
      "Epoch 295/2000\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 821ms/step - loss: 0.3254 - accuracy: 0.9332 - val_loss: 0.6010 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.86303\n",
      "Epoch 296/2000\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 827ms/step - loss: 0.3266 - accuracy: 0.9325 - val_loss: 0.5383 - val_accuracy: 0.8575\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.86303\n",
      "Epoch 297/2000\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 810ms/step - loss: 0.3309 - accuracy: 0.9295 - val_loss: 0.5745 - val_accuracy: 0.8557\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.86303\n",
      "Epoch 298/2000\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 57s 896ms/step - loss: 0.3263 - accuracy: 0.9322 - val_loss: 0.5146 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.86303\n",
      "Epoch 299/2000\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 57s 892ms/step - loss: 0.3217 - accuracy: 0.9333 - val_loss: 0.6756 - val_accuracy: 0.8569\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.86303\n",
      "Epoch 300/2000\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 55s 854ms/step - loss: 0.3223 - accuracy: 0.9349 - val_loss: 0.5413 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.86303\n",
      "Epoch 301/2000\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 852ms/step - loss: 0.3232 - accuracy: 0.9335 - val_loss: 0.5962 - val_accuracy: 0.8585\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.86303\n",
      "Epoch 302/2000\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 52s 818ms/step - loss: 0.3255 - accuracy: 0.9328 - val_loss: 0.5792 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.86303\n",
      "Epoch 303/2000\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 780ms/step - loss: 0.3197 - accuracy: 0.9333 - val_loss: 0.5234 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.86303\n",
      "Epoch 304/2000\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 815ms/step - loss: 0.3205 - accuracy: 0.9324 - val_loss: 0.5645 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.86303\n",
      "Epoch 305/2000\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 793ms/step - loss: 0.3264 - accuracy: 0.9319 - val_loss: 0.5692 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.86303\n",
      "Epoch 306/2000\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 49s 767ms/step - loss: 0.3245 - accuracy: 0.9340 - val_loss: 0.6027 - val_accuracy: 0.8578\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.86303\n",
      "Epoch 307/2000\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 808ms/step - loss: 0.3223 - accuracy: 0.9326 - val_loss: 0.5357 - val_accuracy: 0.8546\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.86303\n",
      "Epoch 308/2000\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 800ms/step - loss: 0.3183 - accuracy: 0.9348 - val_loss: 0.4918 - val_accuracy: 0.8576\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.86303\n",
      "Epoch 309/2000\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 48s 756ms/step - loss: 0.3202 - accuracy: 0.9347 - val_loss: 0.5580 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.86303\n",
      "Epoch 310/2000\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 831ms/step - loss: 0.3212 - accuracy: 0.9338 - val_loss: 0.5040 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.86303\n",
      "Epoch 311/2000\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 49s 772ms/step - loss: 0.3217 - accuracy: 0.9321 - val_loss: 0.4905 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.86303\n",
      "Epoch 312/2000\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 804ms/step - loss: 0.3205 - accuracy: 0.9326 - val_loss: 0.5452 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.86303\n",
      "Epoch 313/2000\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 810ms/step - loss: 0.3182 - accuracy: 0.9330 - val_loss: 0.5468 - val_accuracy: 0.8556\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.86303\n",
      "Epoch 314/2000\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 48s 757ms/step - loss: 0.3220 - accuracy: 0.9317 - val_loss: 0.5624 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.86303\n",
      "Epoch 315/2000\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 790ms/step - loss: 0.3216 - accuracy: 0.9326 - val_loss: 0.5142 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.86303\n",
      "Epoch 316/2000\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 51s 799ms/step - loss: 0.3167 - accuracy: 0.9336 - val_loss: 0.5149 - val_accuracy: 0.8559\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.86303\n",
      "Epoch 317/2000\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 49s 758ms/step - loss: 0.3216 - accuracy: 0.9321 - val_loss: 0.5298 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.86303\n",
      "Epoch 318/2000\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 48s 749ms/step - loss: 0.3195 - accuracy: 0.9348 - val_loss: 0.5009 - val_accuracy: 0.8614\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.86303\n",
      "Epoch 319/2000\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 782ms/step - loss: 0.3223 - accuracy: 0.9370 - val_loss: 0.5460 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.86303\n",
      "Epoch 320/2000\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 824ms/step - loss: 0.3213 - accuracy: 0.9350 - val_loss: 0.5534 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.86303\n",
      "Epoch 321/2000\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 777ms/step - loss: 0.3205 - accuracy: 0.9346 - val_loss: 0.5390 - val_accuracy: 0.8588\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.86303\n",
      "Epoch 322/2000\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 779ms/step - loss: 0.3129 - accuracy: 0.9367 - val_loss: 0.5195 - val_accuracy: 0.8577\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.86303\n",
      "Epoch 323/2000\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 55s 852ms/step - loss: 0.3213 - accuracy: 0.9346 - val_loss: 0.5237 - val_accuracy: 0.8563\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.86303\n",
      "Epoch 324/2000\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 49s 770ms/step - loss: 0.3185 - accuracy: 0.9342 - val_loss: 0.5963 - val_accuracy: 0.8572\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.86303\n",
      "Epoch 325/2000\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 823ms/step - loss: 0.3166 - accuracy: 0.9373 - val_loss: 0.5238 - val_accuracy: 0.8630\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.86303\n",
      "Epoch 326/2000\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 832ms/step - loss: 0.3188 - accuracy: 0.9349 - val_loss: 0.4517 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.86303\n",
      "Epoch 327/2000\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 57s 887ms/step - loss: 0.3196 - accuracy: 0.9358 - val_loss: 0.5680 - val_accuracy: 0.8629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00327: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.86303\n",
      "Epoch 328/2000\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 55s 853ms/step - loss: 0.3156 - accuracy: 0.9366 - val_loss: 0.4801 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.86303\n",
      "Epoch 329/2000\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 846ms/step - loss: 0.3172 - accuracy: 0.9337 - val_loss: 0.6570 - val_accuracy: 0.8559\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.86303\n",
      "Epoch 330/2000\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 778ms/step - loss: 0.3142 - accuracy: 0.9348 - val_loss: 0.5254 - val_accuracy: 0.8601\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.86303\n",
      "Epoch 331/2000\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 807ms/step - loss: 0.3165 - accuracy: 0.9365 - val_loss: 0.6319 - val_accuracy: 0.8551\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.86303\n",
      "Epoch 332/2000\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 777ms/step - loss: 0.3161 - accuracy: 0.9360 - val_loss: 0.6113 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.86303\n",
      "Epoch 333/2000\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 52s 814ms/step - loss: 0.3122 - accuracy: 0.9365 - val_loss: 0.6032 - val_accuracy: 0.8563\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.86303\n",
      "Epoch 334/2000\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 54s 841ms/step - loss: 0.3199 - accuracy: 0.9364 - val_loss: 0.5660 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.86303\n",
      "Epoch 335/2000\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 53s 832ms/step - loss: 0.3157 - accuracy: 0.9371 - val_loss: 0.5052 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.86303\n",
      "Epoch 336/2000\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 47s 737ms/step - loss: 0.3100 - accuracy: 0.9369 - val_loss: 0.6064 - val_accuracy: 0.8568\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.86303\n",
      "Epoch 337/2000\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 50s 779ms/step - loss: 0.3125 - accuracy: 0.9341 - val_loss: 0.5809 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.43675\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.86303\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00337: early stopping\n",
      "## Saved in /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.pickle ###\n",
      "\n",
      "\n",
      "Loading maxAccModelName\n",
      "moving maxAccModelName to modelFileNamePath\n",
      "Model for MAX ACCURACY test_acc: 86.329 val_acc: 86.329\n",
      "Model for MIN LOSS test_acc: 84.578 val_acc: 84.578\n",
      "Loading previous results...\n",
      "Dumping results...\n",
      "######## 3/16 - pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05 - Cross_subject/ ########\n",
      "touching /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.h5\n",
      "## To be saved in [...]/savedModels/Cross_subject/ ###\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_SUBJECT-dataset.pickle\n",
      "train_set shape: (32256,)\n",
      "train_set zero elements: 4070412/104805544 (3.9%)\n",
      "val_set shape: (8064,)\n",
      "val_set zero elements: 1067838/26143382 (4.1%)\n",
      "test_set shape: (16560,)\n",
      "test_set zero elements: 2234310/57232200 (3.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 32256\n",
      "## NEW LENGHT OF DATSET: 32256\n",
      "## OLD LENGHT OF DATSET: 8064\n",
      "## NEW LENGHT OF DATSET: 8064\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (32256, 299, 34, 2)\n",
      "train set zero elements (after padding): 552321296 (84.22%)\n",
      "val set shape: (8064, 299, 34, 2)\n",
      "val set zero elements (after padding): 138138226 (84.25%)\n",
      "test set shape: (16560, 299, 34, 2)\n",
      "test set zero elements (after padding): 280131984 (83.20%)\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_SUBJECT-dataset.pickle\n",
      "train_set shape: (32256,)\n",
      "train_set zero elements: 4070412/104805544 (3.9%)\n",
      "val_set shape: (8064,)\n",
      "val_set zero elements: 1067838/26143382 (4.1%)\n",
      "test_set shape: (16560,)\n",
      "test_set zero elements: 2234310/57232200 (3.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 32256\n",
      "## NEW LENGHT OF DATSET: 32256\n",
      "## OLD LENGHT OF DATSET: 8064\n",
      "## NEW LENGHT OF DATSET: 8064\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (32256, 300, 34, 2)\n",
      "train set zero elements (after padding): 553216856 (84.07%)\n",
      "val set shape: (8064, 300, 34, 2)\n",
      "val set zero elements (after padding): 138362218 (84.11%)\n",
      "test set shape: (16560, 300, 34, 2)\n",
      "test set zero elements (after padding): 280591800 (83.06%)\n",
      "## MERGING TRAIN+VAL ##\n",
      "#### CREATINGS COMBINATION OF BEST STRUCTURES #######\n",
      "### FITTING WITH GENERATORS  ####\n",
      "## VALIDATION len of data 16560 - batch size 600\n",
      "## VALIDATION missing_train = 240\n",
      "## TRAINING len of data 40320 - batch size 600\n",
      "## TRAINING missing_train = 480\n",
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.011.\n",
      "68/68 [==============================] - 61s 891ms/step - loss: 4.1124 - accuracy: 0.0167 - val_loss: 4.0988 - val_accuracy: 0.0170\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.09878, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.01703, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.010920160000000002.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 4.0970 - accuracy: 0.0156 - val_loss: 4.1020 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.09878\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.01703\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.010840639999999999.\n",
      "68/68 [==============================] - 49s 714ms/step - loss: 4.1051 - accuracy: 0.0174 - val_loss: 4.0883 - val_accuracy: 0.0170\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.09878 to 4.08830, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.01703\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.01076144.\n",
      "68/68 [==============================] - 48s 712ms/step - loss: 4.0967 - accuracy: 0.0170 - val_loss: 3.9054 - val_accuracy: 0.0313\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.08830 to 3.90542, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.01703 to 0.03134, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.01068256.\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 3.8390 - accuracy: 0.0299 - val_loss: 3.8041 - val_accuracy: 0.0333\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.90542 to 3.80405, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.03134 to 0.03327, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.010603999999999999.\n",
      "68/68 [==============================] - 51s 743ms/step - loss: 3.8740 - accuracy: 0.0305 - val_loss: 3.7719 - val_accuracy: 0.0373\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.80405 to 3.77193, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.03327 to 0.03726, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.010525759999999999.\n",
      "68/68 [==============================] - 50s 736ms/step - loss: 3.7379 - accuracy: 0.0463 - val_loss: 3.6077 - val_accuracy: 0.0519\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.77193 to 3.60772, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.03726 to 0.05193, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.01044784.\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 3.4520 - accuracy: 0.0951 - val_loss: 3.3404 - val_accuracy: 0.1071\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.60772 to 3.34038, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.05193 to 0.10713, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.01037024.\n",
      "68/68 [==============================] - 48s 705ms/step - loss: 3.2446 - accuracy: 0.1307 - val_loss: 3.0843 - val_accuracy: 0.1386\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.34038 to 3.08430, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.10713 to 0.13859, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.01029296.\n",
      "68/68 [==============================] - 48s 710ms/step - loss: 3.1157 - accuracy: 0.1570 - val_loss: 3.0877 - val_accuracy: 0.1742\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.08430\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.13859 to 0.17421, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.010216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 48s 707ms/step - loss: 3.0057 - accuracy: 0.1941 - val_loss: 3.0425 - val_accuracy: 0.1882\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.08430 to 3.04252, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.17421 to 0.18816, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.01013936.\n",
      "68/68 [==============================] - 49s 724ms/step - loss: 2.9107 - accuracy: 0.2201 - val_loss: 2.9474 - val_accuracy: 0.2297\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.04252 to 2.94744, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.18816 to 0.22971, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.010063039999999999.\n",
      "68/68 [==============================] - 49s 715ms/step - loss: 2.8410 - accuracy: 0.2421 - val_loss: 2.8109 - val_accuracy: 0.2433\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.94744 to 2.81095, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.22971 to 0.24330, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.009987039999999999.\n",
      "68/68 [==============================] - 48s 708ms/step - loss: 2.7918 - accuracy: 0.2592 - val_loss: 2.7804 - val_accuracy: 0.2807\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.81095 to 2.78043, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.24330 to 0.28068, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.009911360000000001.\n",
      "68/68 [==============================] - 49s 721ms/step - loss: 2.7424 - accuracy: 0.2787 - val_loss: 2.7151 - val_accuracy: 0.3114\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.78043 to 2.71506, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.28068 to 0.31135, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.009836000000000001.\n",
      "68/68 [==============================] - 47s 694ms/step - loss: 2.6658 - accuracy: 0.3049 - val_loss: 2.5844 - val_accuracy: 0.3377\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.71506 to 2.58441, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.31135 to 0.33768, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.009760959999999999.\n",
      "68/68 [==============================] - 48s 706ms/step - loss: 2.5749 - accuracy: 0.3353 - val_loss: 2.6342 - val_accuracy: 0.3557\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.58441\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.33768 to 0.35568, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.009686239999999999.\n",
      "68/68 [==============================] - 51s 744ms/step - loss: 2.5088 - accuracy: 0.3546 - val_loss: 2.5329 - val_accuracy: 0.3803\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.58441 to 2.53288, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.35568 to 0.38025, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.00961184.\n",
      "68/68 [==============================] - 50s 742ms/step - loss: 2.4412 - accuracy: 0.3765 - val_loss: 2.3582 - val_accuracy: 0.4132\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.53288 to 2.35821, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.38025 to 0.41316, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.009537760000000003.\n",
      "68/68 [==============================] - 48s 705ms/step - loss: 2.3763 - accuracy: 0.3945 - val_loss: 2.2695 - val_accuracy: 0.4431\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.35821 to 2.26953, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.41316 to 0.44306, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.009464.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 48s 710ms/step - loss: 2.3222 - accuracy: 0.4134 - val_loss: 2.1652 - val_accuracy: 0.4571\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.26953 to 2.16521, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.44306 to 0.45707, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.00939056.\n",
      "68/68 [==============================] - 50s 734ms/step - loss: 2.2874 - accuracy: 0.4236 - val_loss: 2.2221 - val_accuracy: 0.4531\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.16521\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.45707\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.00931744.\n",
      "68/68 [==============================] - 50s 736ms/step - loss: 2.2289 - accuracy: 0.4425 - val_loss: 2.2311 - val_accuracy: 0.4818\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.16521\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.45707 to 0.48182, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.009244640000000002.\n",
      "68/68 [==============================] - 49s 719ms/step - loss: 2.1752 - accuracy: 0.4639 - val_loss: 2.1670 - val_accuracy: 0.4763\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.16521\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.48182\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.009172160000000002.\n",
      "68/68 [==============================] - 48s 708ms/step - loss: 2.1482 - accuracy: 0.4674 - val_loss: 1.9899 - val_accuracy: 0.5141\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.16521 to 1.98990, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.48182 to 0.51413, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0091.\n",
      "68/68 [==============================] - 49s 717ms/step - loss: 2.0923 - accuracy: 0.4906 - val_loss: 1.9937 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.98990\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.51413 to 0.52754, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.00902816.\n",
      "68/68 [==============================] - 47s 693ms/step - loss: 2.0642 - accuracy: 0.5006 - val_loss: 2.0393 - val_accuracy: 0.5229\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.98990\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.52754\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.008956640000000002.\n",
      "68/68 [==============================] - 35s 517ms/step - loss: 2.0097 - accuracy: 0.5189 - val_loss: 1.9018 - val_accuracy: 0.5471\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.98990 to 1.90182, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.52754 to 0.54710, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.008885440000000001.\n",
      "68/68 [==============================] - 27s 396ms/step - loss: 1.9824 - accuracy: 0.5298 - val_loss: 1.9331 - val_accuracy: 0.5640\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.90182\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.54710 to 0.56401, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.008814559999999999.\n",
      "68/68 [==============================] - 26s 377ms/step - loss: 1.9546 - accuracy: 0.5369 - val_loss: 1.8564 - val_accuracy: 0.5774\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.90182 to 1.85638, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.56401 to 0.57736, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.008744.\n",
      "68/68 [==============================] - 28s 409ms/step - loss: 1.9361 - accuracy: 0.5450 - val_loss: 1.8928 - val_accuracy: 0.5566\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.85638\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.57736\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.008673759999999999.\n",
      "68/68 [==============================] - 44s 652ms/step - loss: 1.9053 - accuracy: 0.5548 - val_loss: 1.8709 - val_accuracy: 0.5945\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.85638\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.57736 to 0.59450, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.00860384.\n",
      "68/68 [==============================] - 44s 648ms/step - loss: 1.8723 - accuracy: 0.5642 - val_loss: 1.7763 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.85638 to 1.77631, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.59450\n",
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.00853424.\n",
      "68/68 [==============================] - 39s 567ms/step - loss: 1.8323 - accuracy: 0.5711 - val_loss: 1.8848 - val_accuracy: 0.5889\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.77631\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.59450\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.00846496.\n",
      "68/68 [==============================] - 44s 649ms/step - loss: 1.7717 - accuracy: 0.5752 - val_loss: 1.7548 - val_accuracy: 0.5713\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.77631 to 1.75475, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.59450\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.008396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 45s 666ms/step - loss: 1.8224 - accuracy: 0.5671 - val_loss: 2.1283 - val_accuracy: 0.5190\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.75475\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.59450\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.008327359999999999.\n",
      "68/68 [==============================] - 39s 580ms/step - loss: 1.7971 - accuracy: 0.5926 - val_loss: 1.7947 - val_accuracy: 0.6141\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.75475\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.59450 to 0.61413, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.00825904.\n",
      "68/68 [==============================] - 45s 664ms/step - loss: 1.7217 - accuracy: 0.6031 - val_loss: 1.7403 - val_accuracy: 0.6303\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.75475 to 1.74034, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.61413 to 0.63025, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.00819104.\n",
      "68/68 [==============================] - 44s 653ms/step - loss: 1.6737 - accuracy: 0.6107 - val_loss: 1.7602 - val_accuracy: 0.6021\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.74034\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.63025\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.00812336.\n",
      "68/68 [==============================] - 29s 433ms/step - loss: 1.6279 - accuracy: 0.6177 - val_loss: 1.7592 - val_accuracy: 0.6290\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.74034\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.63025\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.008055999999999999.\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 1.5953 - accuracy: 0.6280 - val_loss: 1.6851 - val_accuracy: 0.6268\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.74034 to 1.68514, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.63025\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00798896.\n",
      "68/68 [==============================] - 26s 385ms/step - loss: 1.5724 - accuracy: 0.6331 - val_loss: 1.6961 - val_accuracy: 0.6432\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.68514\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.63025 to 0.64324, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00792224.\n",
      "68/68 [==============================] - 27s 391ms/step - loss: 1.5434 - accuracy: 0.6368 - val_loss: 1.5835 - val_accuracy: 0.6549\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.68514 to 1.58354, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.64324 to 0.65489, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.007855840000000001.\n",
      "68/68 [==============================] - 26s 389ms/step - loss: 1.5108 - accuracy: 0.6450 - val_loss: 1.4808 - val_accuracy: 0.6425\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.58354 to 1.48081, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.65489\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0077897600000000015.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 1.6225 - accuracy: 0.6438 - val_loss: 1.6371 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.48081\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.65489\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.007724000000000001.\n",
      "68/68 [==============================] - 26s 382ms/step - loss: 1.5120 - accuracy: 0.6551 - val_loss: 1.5185 - val_accuracy: 0.6554\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.48081\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.65489 to 0.65537, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.007658560000000001.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 1.4889 - accuracy: 0.6546 - val_loss: 1.4213 - val_accuracy: 0.6702\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.48081 to 1.42126, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.65537 to 0.67023, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.007593440000000001.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 1.4294 - accuracy: 0.6595 - val_loss: 1.5233 - val_accuracy: 0.6533\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.42126\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.67023\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.007528640000000001.\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 1.3932 - accuracy: 0.6675 - val_loss: 1.4552 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.42126\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.67023\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.007464160000000001.\n",
      "68/68 [==============================] - 26s 385ms/step - loss: 1.3713 - accuracy: 0.6676 - val_loss: 1.4957 - val_accuracy: 0.6603\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.42126\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.67023\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.007400000000000001.\n",
      "68/68 [==============================] - 26s 385ms/step - loss: 1.3392 - accuracy: 0.6760 - val_loss: 1.4080 - val_accuracy: 0.6666\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.42126 to 1.40801, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.67023\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00733616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 27s 398ms/step - loss: 1.3096 - accuracy: 0.6841 - val_loss: 1.2925 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.40801 to 1.29248, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.67023 to 0.68400, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00727264.\n",
      "68/68 [==============================] - 26s 382ms/step - loss: 1.2570 - accuracy: 0.6895 - val_loss: 1.3641 - val_accuracy: 0.6715\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.29248\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.68400\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.007209440000000001.\n",
      "68/68 [==============================] - 26s 382ms/step - loss: 1.2417 - accuracy: 0.6887 - val_loss: 1.3039 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.29248\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.68400\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0071465600000000015.\n",
      "68/68 [==============================] - 27s 393ms/step - loss: 1.2161 - accuracy: 0.6945 - val_loss: 1.3645 - val_accuracy: 0.6762\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.29248\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.68400\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.007084000000000001.\n",
      "68/68 [==============================] - 26s 383ms/step - loss: 1.1904 - accuracy: 0.6970 - val_loss: 1.2776 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.29248 to 1.27763, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.68400\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.007021760000000001.\n",
      "68/68 [==============================] - 26s 383ms/step - loss: 1.1603 - accuracy: 0.7021 - val_loss: 1.2533 - val_accuracy: 0.6915\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.27763 to 1.25327, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00057: val_accuracy improved from 0.68400 to 0.69155, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.006959840000000001.\n",
      "68/68 [==============================] - 26s 379ms/step - loss: 1.1308 - accuracy: 0.7100 - val_loss: 1.1503 - val_accuracy: 0.6982\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.25327 to 1.15028, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.69155 to 0.69819, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00689824.\n",
      "68/68 [==============================] - 26s 382ms/step - loss: 1.1145 - accuracy: 0.7121 - val_loss: 1.1286 - val_accuracy: 0.6891\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.15028 to 1.12857, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.69819\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00683696.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 1.0919 - accuracy: 0.7169 - val_loss: 1.1514 - val_accuracy: 0.7088\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.12857\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.69819 to 0.70876, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.006776.\n",
      "68/68 [==============================] - 27s 392ms/step - loss: 1.0638 - accuracy: 0.7217 - val_loss: 1.3676 - val_accuracy: 0.6830\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.12857\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.70876\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.006715360000000001.\n",
      "68/68 [==============================] - 26s 389ms/step - loss: 1.0591 - accuracy: 0.7230 - val_loss: 1.0051 - val_accuracy: 0.7022\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.12857 to 1.00506, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.70876\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00665504.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 1.0439 - accuracy: 0.7222 - val_loss: 1.0975 - val_accuracy: 0.7096\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.70876 to 0.70960, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.00659504.\n",
      "68/68 [==============================] - 26s 379ms/step - loss: 1.0217 - accuracy: 0.7293 - val_loss: 1.1105 - val_accuracy: 0.6977\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.70960\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0065353600000000005.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.9991 - accuracy: 0.7360 - val_loss: 1.1517 - val_accuracy: 0.7169\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00065: val_accuracy improved from 0.70960 to 0.71691, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.006476.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 0.9840 - accuracy: 0.7400 - val_loss: 1.0693 - val_accuracy: 0.7247\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.71691 to 0.72470, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.006416959999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 26s 386ms/step - loss: 0.9706 - accuracy: 0.7427 - val_loss: 1.0314 - val_accuracy: 0.7211\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.72470\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.006358239999999999.\n",
      "68/68 [==============================] - 26s 382ms/step - loss: 0.9615 - accuracy: 0.7459 - val_loss: 1.0887 - val_accuracy: 0.7092\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.72470\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.00629984.\n",
      "68/68 [==============================] - 26s 389ms/step - loss: 0.9453 - accuracy: 0.7459 - val_loss: 1.1412 - val_accuracy: 0.7134\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.72470\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.00624176.\n",
      "68/68 [==============================] - 26s 385ms/step - loss: 0.9241 - accuracy: 0.7507 - val_loss: 1.0339 - val_accuracy: 0.7111\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.00506\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.72470\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.006184.\n",
      "68/68 [==============================] - 26s 386ms/step - loss: 0.9170 - accuracy: 0.7521 - val_loss: 0.9751 - val_accuracy: 0.7171\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.00506 to 0.97511, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.72470\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0061265600000000005.\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 0.9004 - accuracy: 0.7560 - val_loss: 1.0113 - val_accuracy: 0.7263\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.97511\n",
      "\n",
      "Epoch 00072: val_accuracy improved from 0.72470 to 0.72633, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.00606944.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 0.8842 - accuracy: 0.7594 - val_loss: 1.0691 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.97511\n",
      "\n",
      "Epoch 00073: val_accuracy improved from 0.72633 to 0.73333, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.00601264.\n",
      "68/68 [==============================] - 26s 379ms/step - loss: 0.8821 - accuracy: 0.7629 - val_loss: 1.0150 - val_accuracy: 0.7245\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.97511\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.73333\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.005956159999999999.\n",
      "68/68 [==============================] - 26s 380ms/step - loss: 0.8622 - accuracy: 0.7685 - val_loss: 0.9391 - val_accuracy: 0.7261\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.97511 to 0.93905, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.73333\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0059.\n",
      "68/68 [==============================] - 26s 380ms/step - loss: 0.8516 - accuracy: 0.7702 - val_loss: 1.0240 - val_accuracy: 0.7362\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.93905\n",
      "\n",
      "Epoch 00076: val_accuracy improved from 0.73333 to 0.73617, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.005844159999999999.\n",
      "68/68 [==============================] - 26s 386ms/step - loss: 0.8393 - accuracy: 0.7730 - val_loss: 1.0574 - val_accuracy: 0.7312\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.93905\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.73617\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.005788639999999999.\n",
      "68/68 [==============================] - 26s 379ms/step - loss: 0.8265 - accuracy: 0.7743 - val_loss: 0.9373 - val_accuracy: 0.7319\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.93905 to 0.93733, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.73617\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.005733439999999999.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 0.8108 - accuracy: 0.7817 - val_loss: 0.9088 - val_accuracy: 0.7194\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.93733 to 0.90885, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.73617\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.005678559999999999.\n",
      "68/68 [==============================] - 27s 390ms/step - loss: 0.8025 - accuracy: 0.7821 - val_loss: 0.9800 - val_accuracy: 0.7399\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.90885\n",
      "\n",
      "Epoch 00080: val_accuracy improved from 0.73617 to 0.73986, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.005624.\n",
      "68/68 [==============================] - 26s 386ms/step - loss: 0.7954 - accuracy: 0.7869 - val_loss: 0.8860 - val_accuracy: 0.7355\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.90885 to 0.88602, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.73986\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.005569759999999999.\n",
      "68/68 [==============================] - 28s 409ms/step - loss: 0.7797 - accuracy: 0.7898 - val_loss: 1.0604 - val_accuracy: 0.7297\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.73986\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.005515839999999999.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.7688 - accuracy: 0.7923 - val_loss: 0.9098 - val_accuracy: 0.7473\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00083: val_accuracy improved from 0.73986 to 0.74728, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.005462239999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 26s 384ms/step - loss: 0.7631 - accuracy: 0.7937 - val_loss: 0.9292 - val_accuracy: 0.7340\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.74728\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.005408959999999999.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 0.7526 - accuracy: 0.7972 - val_loss: 0.9227 - val_accuracy: 0.7442\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.74728\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.005355999999999999.\n",
      "68/68 [==============================] - 27s 396ms/step - loss: 0.7495 - accuracy: 0.7977 - val_loss: 1.1881 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.74728\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.005303360000000001.\n",
      "68/68 [==============================] - 26s 386ms/step - loss: 0.7337 - accuracy: 0.8014 - val_loss: 0.9763 - val_accuracy: 0.7437\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.74728\n",
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.00525104.\n",
      "68/68 [==============================] - 26s 386ms/step - loss: 0.7222 - accuracy: 0.8048 - val_loss: 0.9078 - val_accuracy: 0.7402\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.74728\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.00519904.\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 0.7219 - accuracy: 0.8041 - val_loss: 0.9247 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.74728\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.005147360000000001.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.7107 - accuracy: 0.8062 - val_loss: 0.9830 - val_accuracy: 0.7482\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00090: val_accuracy improved from 0.74728 to 0.74819, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.005096000000000001.\n",
      "68/68 [==============================] - 27s 393ms/step - loss: 0.7001 - accuracy: 0.8110 - val_loss: 0.9773 - val_accuracy: 0.7463\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.74819\n",
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.00504496.\n",
      "68/68 [==============================] - 27s 393ms/step - loss: 0.6916 - accuracy: 0.8131 - val_loss: 1.0265 - val_accuracy: 0.7416\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.74819\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0049942400000000005.\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 0.6912 - accuracy: 0.8126 - val_loss: 0.9246 - val_accuracy: 0.7329\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.74819\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0049438400000000006.\n",
      "68/68 [==============================] - 27s 394ms/step - loss: 0.6890 - accuracy: 0.8147 - val_loss: 1.0623 - val_accuracy: 0.7546\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.74819 to 0.75459, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0048937600000000005.\n",
      "68/68 [==============================] - 27s 392ms/step - loss: 0.6769 - accuracy: 0.8168 - val_loss: 0.9152 - val_accuracy: 0.7490\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.75459\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.004844.\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 0.6681 - accuracy: 0.8196 - val_loss: 0.9054 - val_accuracy: 0.7478\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.75459\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.00479456.\n",
      "68/68 [==============================] - 26s 389ms/step - loss: 0.6573 - accuracy: 0.8213 - val_loss: 0.9476 - val_accuracy: 0.7498\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.75459\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.00474544.\n",
      "68/68 [==============================] - 26s 389ms/step - loss: 0.6530 - accuracy: 0.8238 - val_loss: 0.9061 - val_accuracy: 0.7524\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.75459\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.00469664.\n",
      "68/68 [==============================] - 26s 385ms/step - loss: 0.6453 - accuracy: 0.8260 - val_loss: 0.9231 - val_accuracy: 0.7539\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.88602\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.75459\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.00464816.\n",
      "68/68 [==============================] - 27s 390ms/step - loss: 0.6316 - accuracy: 0.8307 - val_loss: 0.8500 - val_accuracy: 0.7496\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.88602 to 0.84996, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.75459\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0046.\n",
      "68/68 [==============================] - 26s 381ms/step - loss: 0.6390 - accuracy: 0.8270 - val_loss: 0.8660 - val_accuracy: 0.7598\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00101: val_accuracy improved from 0.75459 to 0.75978, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.0045521599999999995.\n",
      "68/68 [==============================] - 26s 382ms/step - loss: 0.6313 - accuracy: 0.8315 - val_loss: 1.0733 - val_accuracy: 0.7581\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.75978\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.004504640000000001.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.6227 - accuracy: 0.8342 - val_loss: 1.0988 - val_accuracy: 0.7593\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.75978\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.004457440000000002.\n",
      "68/68 [==============================] - 28s 418ms/step - loss: 0.6211 - accuracy: 0.8362 - val_loss: 0.9007 - val_accuracy: 0.7482\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.75978\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.004410560000000001.\n",
      "68/68 [==============================] - 27s 393ms/step - loss: 0.6137 - accuracy: 0.8375 - val_loss: 0.9810 - val_accuracy: 0.7596\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.75978\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.0043640000000000016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 26s 386ms/step - loss: 0.6121 - accuracy: 0.8377 - val_loss: 1.1150 - val_accuracy: 0.7476\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.75978\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.00431776.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.6021 - accuracy: 0.8402 - val_loss: 0.9584 - val_accuracy: 0.7583\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.75978\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.004271840000000001.\n",
      "68/68 [==============================] - 27s 392ms/step - loss: 0.5966 - accuracy: 0.8437 - val_loss: 1.0422 - val_accuracy: 0.7586\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.75978\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.004226240000000001.\n",
      "68/68 [==============================] - 26s 380ms/step - loss: 0.5936 - accuracy: 0.8447 - val_loss: 0.9077 - val_accuracy: 0.7433\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.75978\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.004180960000000001.\n",
      "68/68 [==============================] - 26s 387ms/step - loss: 0.5862 - accuracy: 0.8451 - val_loss: 0.9117 - val_accuracy: 0.7601\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.84996\n",
      "\n",
      "Epoch 00110: val_accuracy improved from 0.75978 to 0.76014, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.004136000000000001.\n",
      "68/68 [==============================] - 26s 386ms/step - loss: 0.5781 - accuracy: 0.8477 - val_loss: 0.8272 - val_accuracy: 0.7627\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.84996 to 0.82716, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00111: val_accuracy improved from 0.76014 to 0.76268, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0040913600000000005.\n",
      "68/68 [==============================] - 27s 399ms/step - loss: 0.5745 - accuracy: 0.8484 - val_loss: 0.9403 - val_accuracy: 0.7587\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.76268\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.00404704.\n",
      "68/68 [==============================] - 26s 390ms/step - loss: 0.5807 - accuracy: 0.8489 - val_loss: 0.9624 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.76268\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.004003040000000001.\n",
      "68/68 [==============================] - 26s 380ms/step - loss: 0.5629 - accuracy: 0.8504 - val_loss: 0.9362 - val_accuracy: 0.7595\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.76268\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.00395936.\n",
      "68/68 [==============================] - 26s 385ms/step - loss: 0.5601 - accuracy: 0.8498 - val_loss: 1.1868 - val_accuracy: 0.7536\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.76268\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.003916.\n",
      "68/68 [==============================] - 27s 395ms/step - loss: 0.5477 - accuracy: 0.8558 - val_loss: 0.9811 - val_accuracy: 0.7612\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.76268\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0038729600000000004.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.5460 - accuracy: 0.8557 - val_loss: 0.8414 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.76268\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.003830240000000001.\n",
      "68/68 [==============================] - 26s 376ms/step - loss: 0.5423 - accuracy: 0.8566 - val_loss: 0.8738 - val_accuracy: 0.7530\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.76268\n",
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0037878400000000002.\n",
      "68/68 [==============================] - 25s 373ms/step - loss: 0.5349 - accuracy: 0.8570 - val_loss: 0.9668 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00119: val_accuracy improved from 0.76268 to 0.76667, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0037457600000000003.\n",
      "68/68 [==============================] - 28s 407ms/step - loss: 0.5342 - accuracy: 0.8599 - val_loss: 0.8556 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00120: val_accuracy improved from 0.76667 to 0.76793, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0037040000000000003.\n",
      "68/68 [==============================] - 27s 401ms/step - loss: 0.5249 - accuracy: 0.8629 - val_loss: 0.9559 - val_accuracy: 0.7647\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.76793\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.00366256.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.5295 - accuracy: 0.8629 - val_loss: 0.8407 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.76793\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.00362144.\n",
      "68/68 [==============================] - 26s 379ms/step - loss: 0.5172 - accuracy: 0.8646 - val_loss: 0.9012 - val_accuracy: 0.7605\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.76793\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0035806400000000004.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.5133 - accuracy: 0.8650 - val_loss: 0.9158 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.76793\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.00354016.\n",
      "68/68 [==============================] - 25s 372ms/step - loss: 0.5131 - accuracy: 0.8661 - val_loss: 1.0328 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.76793\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0035.\n",
      "68/68 [==============================] - 26s 389ms/step - loss: 0.5032 - accuracy: 0.8662 - val_loss: 0.9298 - val_accuracy: 0.7628\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.76793\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.00346016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 25s 372ms/step - loss: 0.5092 - accuracy: 0.8671 - val_loss: 0.9188 - val_accuracy: 0.7694\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00127: val_accuracy improved from 0.76793 to 0.76938, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.00342064.\n",
      "68/68 [==============================] - 25s 371ms/step - loss: 0.5097 - accuracy: 0.8682 - val_loss: 0.8353 - val_accuracy: 0.7585\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.76938\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.00338144.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.4989 - accuracy: 0.8700 - val_loss: 0.8757 - val_accuracy: 0.7678\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.76938\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.00334256.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.4918 - accuracy: 0.8728 - val_loss: 0.9137 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.82716\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.76938\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.003304.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.4930 - accuracy: 0.8718 - val_loss: 0.7822 - val_accuracy: 0.7648\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.82716 to 0.78225, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.76938\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.00326576.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.4911 - accuracy: 0.8719 - val_loss: 0.8809 - val_accuracy: 0.7693\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.76938\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.00322784.\n",
      "68/68 [==============================] - 25s 369ms/step - loss: 0.4849 - accuracy: 0.8737 - val_loss: 0.8519 - val_accuracy: 0.7664\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.76938\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0031902399999999996.\n",
      "68/68 [==============================] - 25s 370ms/step - loss: 0.4808 - accuracy: 0.8754 - val_loss: 0.9423 - val_accuracy: 0.7698\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00134: val_accuracy improved from 0.76938 to 0.76981, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 135/2000\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.00315296.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.4796 - accuracy: 0.8762 - val_loss: 0.8634 - val_accuracy: 0.7669\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.76981\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0031159999999999994.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.4725 - accuracy: 0.8773 - val_loss: 0.9818 - val_accuracy: 0.7654\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.76981\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0030793599999999997.\n",
      "68/68 [==============================] - 25s 362ms/step - loss: 0.4704 - accuracy: 0.8794 - val_loss: 1.0558 - val_accuracy: 0.7745\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00137: val_accuracy improved from 0.76981 to 0.77452, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0030430399999999995.\n",
      "68/68 [==============================] - 25s 370ms/step - loss: 0.4714 - accuracy: 0.8800 - val_loss: 1.0224 - val_accuracy: 0.7620\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.77452\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.00300704.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.4651 - accuracy: 0.8783 - val_loss: 0.8572 - val_accuracy: 0.7646\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.77452\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0029713599999999997.\n",
      "68/68 [==============================] - 26s 389ms/step - loss: 0.4659 - accuracy: 0.8784 - val_loss: 0.9118 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.77452\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.002936.\n",
      "68/68 [==============================] - 25s 370ms/step - loss: 0.4595 - accuracy: 0.8817 - val_loss: 1.0027 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.77452\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.00290096.\n",
      "68/68 [==============================] - 26s 380ms/step - loss: 0.4551 - accuracy: 0.8834 - val_loss: 0.8828 - val_accuracy: 0.7649\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.77452\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0028662400000000004.\n",
      "68/68 [==============================] - 25s 375ms/step - loss: 0.4586 - accuracy: 0.8820 - val_loss: 0.8946 - val_accuracy: 0.7684\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.77452\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0028318400000000004.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.4608 - accuracy: 0.8833 - val_loss: 1.0258 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.77452\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0027977600000000007.\n",
      "68/68 [==============================] - 25s 375ms/step - loss: 0.4499 - accuracy: 0.8847 - val_loss: 0.9237 - val_accuracy: 0.7635\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.77452\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0027640000000000004.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.4510 - accuracy: 0.8867 - val_loss: 0.9857 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.77452\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.002730560000000001.\n",
      "68/68 [==============================] - 25s 370ms/step - loss: 0.4420 - accuracy: 0.8888 - val_loss: 0.8963 - val_accuracy: 0.7653\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.77452\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0026974400000000006.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.4405 - accuracy: 0.8882 - val_loss: 0.9752 - val_accuracy: 0.7632\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.77452\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0026646400000000002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 25s 366ms/step - loss: 0.4447 - accuracy: 0.8885 - val_loss: 0.8922 - val_accuracy: 0.7663\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.77452\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0026321600000000006.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.4339 - accuracy: 0.8906 - val_loss: 0.8538 - val_accuracy: 0.7621\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.78225\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.77452\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.0026000000000000003.\n",
      "68/68 [==============================] - 25s 370ms/step - loss: 0.4395 - accuracy: 0.8886 - val_loss: 0.7512 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.78225 to 0.75115, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.77452\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.00256816.\n",
      "68/68 [==============================] - 25s 372ms/step - loss: 0.4320 - accuracy: 0.8933 - val_loss: 0.9676 - val_accuracy: 0.7694\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.77452\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.0025366400000000006.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.4279 - accuracy: 0.8935 - val_loss: 1.0368 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.77452\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.0025054400000000003.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.4273 - accuracy: 0.8942 - val_loss: 0.9090 - val_accuracy: 0.7689\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.77452\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.0024745599999999998.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.4274 - accuracy: 0.8931 - val_loss: 1.0502 - val_accuracy: 0.7596\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.77452\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.002444.\n",
      "68/68 [==============================] - 24s 357ms/step - loss: 0.4190 - accuracy: 0.8938 - val_loss: 0.8898 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.77452\n",
      "Epoch 157/2000\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.00241376.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.4202 - accuracy: 0.8954 - val_loss: 0.8894 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.77452\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.00238384.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.4206 - accuracy: 0.8976 - val_loss: 1.2068 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.77452\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.0023542399999999996.\n",
      "68/68 [==============================] - 24s 350ms/step - loss: 0.4188 - accuracy: 0.8962 - val_loss: 0.9981 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.77452\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.00232496.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.4171 - accuracy: 0.8987 - val_loss: 1.0230 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.77452\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0022960000000000003.\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.4167 - accuracy: 0.8989 - val_loss: 1.0026 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.77452\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.00226736.\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.4137 - accuracy: 0.8973 - val_loss: 0.8833 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.77452\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.00223904.\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.4054 - accuracy: 0.9006 - val_loss: 0.9980 - val_accuracy: 0.7655\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.77452\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.00221104.\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.4083 - accuracy: 0.9002 - val_loss: 0.9312 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.77452\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.0021833599999999996.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.4050 - accuracy: 0.9009 - val_loss: 0.8380 - val_accuracy: 0.7710\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.77452\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.002156.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.3971 - accuracy: 0.9029 - val_loss: 1.0540 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.77452\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.00212896.\n",
      "68/68 [==============================] - 31s 458ms/step - loss: 0.3990 - accuracy: 0.9037 - val_loss: 1.0587 - val_accuracy: 0.7704\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.77452\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.00210224.\n",
      "68/68 [==============================] - 43s 630ms/step - loss: 0.4012 - accuracy: 0.9035 - val_loss: 1.0383 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.75115\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.77452\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.00207584.\n",
      "68/68 [==============================] - 36s 528ms/step - loss: 0.3945 - accuracy: 0.9052 - val_loss: 0.7178 - val_accuracy: 0.7746\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.75115 to 0.71783, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00169: val_accuracy improved from 0.77452 to 0.77458, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.00204976.\n",
      "68/68 [==============================] - 33s 487ms/step - loss: 0.3932 - accuracy: 0.9040 - val_loss: 0.9778 - val_accuracy: 0.7659\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.77458\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.0020239999999999998.\n",
      "68/68 [==============================] - 31s 462ms/step - loss: 0.3884 - accuracy: 0.9052 - val_loss: 0.9506 - val_accuracy: 0.7691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00171: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.77458\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.00199856.\n",
      "68/68 [==============================] - 33s 482ms/step - loss: 0.3940 - accuracy: 0.9046 - val_loss: 0.8736 - val_accuracy: 0.7664\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.77458\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.0019734400000000004.\n",
      "68/68 [==============================] - 32s 463ms/step - loss: 0.3922 - accuracy: 0.9051 - val_loss: 0.9508 - val_accuracy: 0.7724\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.77458\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.0019486400000000004.\n",
      "68/68 [==============================] - 30s 442ms/step - loss: 0.3864 - accuracy: 0.9060 - val_loss: 0.9178 - val_accuracy: 0.7695\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.77458\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.0019241600000000003.\n",
      "68/68 [==============================] - 30s 439ms/step - loss: 0.3888 - accuracy: 0.9075 - val_loss: 0.9985 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.77458\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.0019000000000000002.\n",
      "68/68 [==============================] - 30s 446ms/step - loss: 0.3825 - accuracy: 0.9087 - val_loss: 0.9064 - val_accuracy: 0.7682\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.77458\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.0018761600000000004.\n",
      "68/68 [==============================] - 31s 456ms/step - loss: 0.3818 - accuracy: 0.9082 - val_loss: 0.8728 - val_accuracy: 0.7737\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.77458\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.0018526400000000002.\n",
      "68/68 [==============================] - 33s 490ms/step - loss: 0.3792 - accuracy: 0.9099 - val_loss: 1.0785 - val_accuracy: 0.7686\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.77458\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.0018294400000000003.\n",
      "68/68 [==============================] - 33s 480ms/step - loss: 0.3819 - accuracy: 0.9086 - val_loss: 1.0431 - val_accuracy: 0.7672\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.77458\n",
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.0018065600000000002.\n",
      "68/68 [==============================] - 31s 454ms/step - loss: 0.3821 - accuracy: 0.9096 - val_loss: 1.0482 - val_accuracy: 0.7675\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.77458\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.001784.\n",
      "68/68 [==============================] - 31s 449ms/step - loss: 0.3811 - accuracy: 0.9095 - val_loss: 0.8273 - val_accuracy: 0.7740\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.77458\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.0017617600000000002.\n",
      "68/68 [==============================] - 30s 441ms/step - loss: 0.3773 - accuracy: 0.9113 - val_loss: 0.7643 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.77458\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.00173984.\n",
      "68/68 [==============================] - 30s 446ms/step - loss: 0.3751 - accuracy: 0.9122 - val_loss: 0.9854 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.77458\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.0017182400000000002.\n",
      "68/68 [==============================] - 31s 449ms/step - loss: 0.3750 - accuracy: 0.9102 - val_loss: 0.8837 - val_accuracy: 0.7690\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.77458\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.00169696.\n",
      "68/68 [==============================] - 31s 462ms/step - loss: 0.3688 - accuracy: 0.9108 - val_loss: 0.8638 - val_accuracy: 0.7719\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.77458\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.001676.\n",
      "68/68 [==============================] - 32s 477ms/step - loss: 0.3668 - accuracy: 0.9134 - val_loss: 1.0273 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.77458\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.00165536.\n",
      "68/68 [==============================] - 31s 450ms/step - loss: 0.3660 - accuracy: 0.9133 - val_loss: 0.8854 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.77458\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.00163504.\n",
      "68/68 [==============================] - 31s 451ms/step - loss: 0.3706 - accuracy: 0.9125 - val_loss: 0.9943 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.77458\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.0016150399999999999.\n",
      "68/68 [==============================] - 31s 457ms/step - loss: 0.3657 - accuracy: 0.9128 - val_loss: 0.9650 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.77458\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.00159536.\n",
      "68/68 [==============================] - 30s 437ms/step - loss: 0.3618 - accuracy: 0.9146 - val_loss: 1.0236 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.77458\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0015760000000000001.\n",
      "68/68 [==============================] - 31s 452ms/step - loss: 0.3637 - accuracy: 0.9158 - val_loss: 1.0809 - val_accuracy: 0.7671\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.77458\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.00155696.\n",
      "68/68 [==============================] - 31s 457ms/step - loss: 0.3595 - accuracy: 0.9159 - val_loss: 1.0097 - val_accuracy: 0.7718\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.77458\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.00153824.\n",
      "68/68 [==============================] - 30s 444ms/step - loss: 0.3581 - accuracy: 0.9151 - val_loss: 0.9649 - val_accuracy: 0.7713\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.77458\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.00151984.\n",
      "68/68 [==============================] - 31s 453ms/step - loss: 0.3560 - accuracy: 0.9168 - val_loss: 0.9350 - val_accuracy: 0.7732\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.77458\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.00150176.\n",
      "68/68 [==============================] - 31s 454ms/step - loss: 0.3614 - accuracy: 0.9155 - val_loss: 0.9585 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.77458\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.001484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 34s 502ms/step - loss: 0.3554 - accuracy: 0.9173 - val_loss: 0.9719 - val_accuracy: 0.7704\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.77458\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.00146656.\n",
      "68/68 [==============================] - 36s 523ms/step - loss: 0.3556 - accuracy: 0.9165 - val_loss: 1.1487 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.77458\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.0014494399999999998.\n",
      "68/68 [==============================] - 34s 495ms/step - loss: 0.3532 - accuracy: 0.9177 - val_loss: 1.0424 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.77458\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.0014326399999999998.\n",
      "68/68 [==============================] - 31s 458ms/step - loss: 0.3566 - accuracy: 0.9176 - val_loss: 1.0527 - val_accuracy: 0.7722\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.77458\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.0014161599999999999.\n",
      "68/68 [==============================] - 32s 475ms/step - loss: 0.3524 - accuracy: 0.9183 - val_loss: 0.9685 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.77458\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.0013999999999999998.\n",
      "68/68 [==============================] - 34s 505ms/step - loss: 0.3532 - accuracy: 0.9184 - val_loss: 0.8806 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.77458\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.0013841599999999997.\n",
      "68/68 [==============================] - 30s 442ms/step - loss: 0.3448 - accuracy: 0.9197 - val_loss: 1.0282 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.77458\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.00136864.\n",
      "68/68 [==============================] - 29s 425ms/step - loss: 0.3406 - accuracy: 0.9212 - val_loss: 0.9791 - val_accuracy: 0.7693\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.77458\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.0013534399999999998.\n",
      "68/68 [==============================] - 31s 453ms/step - loss: 0.3463 - accuracy: 0.9195 - val_loss: 0.7890 - val_accuracy: 0.7712\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.77458\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.0013385600000000001.\n",
      "68/68 [==============================] - 30s 446ms/step - loss: 0.3434 - accuracy: 0.9204 - val_loss: 0.8576 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.77458\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.001324.\n",
      "68/68 [==============================] - 30s 440ms/step - loss: 0.3470 - accuracy: 0.9191 - val_loss: 0.8409 - val_accuracy: 0.7723\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.77458\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.00130976.\n",
      "68/68 [==============================] - 30s 443ms/step - loss: 0.3426 - accuracy: 0.9210 - val_loss: 0.9225 - val_accuracy: 0.7651\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.77458\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.0012958400000000001.\n",
      "68/68 [==============================] - 31s 457ms/step - loss: 0.3441 - accuracy: 0.9205 - val_loss: 0.9489 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.77458\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.00128224.\n",
      "68/68 [==============================] - 31s 450ms/step - loss: 0.3463 - accuracy: 0.9202 - val_loss: 0.9662 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.77458\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.0012689600000000002.\n",
      "68/68 [==============================] - 30s 442ms/step - loss: 0.3412 - accuracy: 0.9211 - val_loss: 0.9583 - val_accuracy: 0.7616\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.77458\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.0012560000000000002.\n",
      "68/68 [==============================] - 28s 418ms/step - loss: 0.3433 - accuracy: 0.9207 - val_loss: 0.9422 - val_accuracy: 0.7665\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.77458\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.0012433600000000002.\n",
      "68/68 [==============================] - 28s 412ms/step - loss: 0.3387 - accuracy: 0.9226 - val_loss: 0.9226 - val_accuracy: 0.7672\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.77458\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.00123104.\n",
      "68/68 [==============================] - 30s 439ms/step - loss: 0.3387 - accuracy: 0.9224 - val_loss: 0.9459 - val_accuracy: 0.7737\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.77458\n",
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.00121904.\n",
      "68/68 [==============================] - 31s 458ms/step - loss: 0.3348 - accuracy: 0.9250 - val_loss: 1.2803 - val_accuracy: 0.7712\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.77458\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.00120736.\n",
      "68/68 [==============================] - 33s 487ms/step - loss: 0.3395 - accuracy: 0.9235 - val_loss: 1.0388 - val_accuracy: 0.7693\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.77458\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.001196.\n",
      "68/68 [==============================] - 29s 427ms/step - loss: 0.3330 - accuracy: 0.9253 - val_loss: 0.9180 - val_accuracy: 0.7735\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.77458\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.00118496.\n",
      "68/68 [==============================] - 27s 392ms/step - loss: 0.3376 - accuracy: 0.9233 - val_loss: 0.8726 - val_accuracy: 0.7723\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.77458\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.00117424.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.3319 - accuracy: 0.9253 - val_loss: 1.0847 - val_accuracy: 0.7737\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.77458\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.00116384.\n",
      "68/68 [==============================] - 26s 380ms/step - loss: 0.3321 - accuracy: 0.9253 - val_loss: 0.9730 - val_accuracy: 0.7721\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.77458\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.00115376.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.3342 - accuracy: 0.9249 - val_loss: 0.9325 - val_accuracy: 0.7732\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.77458\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.001144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 25s 362ms/step - loss: 0.3298 - accuracy: 0.9237 - val_loss: 1.0840 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.77458\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.00113456.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.3305 - accuracy: 0.9266 - val_loss: 0.8814 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.77458\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.0011254400000000001.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.3325 - accuracy: 0.9254 - val_loss: 0.9156 - val_accuracy: 0.7684\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.77458\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.00111664.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.3304 - accuracy: 0.9244 - val_loss: 1.0183 - val_accuracy: 0.7716\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.77458\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.00110816.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.3300 - accuracy: 0.9248 - val_loss: 0.9089 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.77458\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.0011.\n",
      "68/68 [==============================] - 25s 362ms/step - loss: 0.3296 - accuracy: 0.9257 - val_loss: 1.1768 - val_accuracy: 0.7713\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.77458\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.00109216.\n",
      "68/68 [==============================] - 25s 362ms/step - loss: 0.3245 - accuracy: 0.9250 - val_loss: 1.0039 - val_accuracy: 0.7737\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.77458\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.00108464.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3254 - accuracy: 0.9260 - val_loss: 0.9828 - val_accuracy: 0.7688\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.77458\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.00107744.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.3266 - accuracy: 0.9255 - val_loss: 0.7825 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.77458\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.00107056.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3267 - accuracy: 0.9288 - val_loss: 0.9993 - val_accuracy: 0.7688\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.77458\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.0010639999999999998.\n",
      "68/68 [==============================] - 24s 359ms/step - loss: 0.3220 - accuracy: 0.9279 - val_loss: 1.0702 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.77458\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.00105776.\n",
      "68/68 [==============================] - 24s 357ms/step - loss: 0.3235 - accuracy: 0.9280 - val_loss: 1.1164 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.77458\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.00105184.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3254 - accuracy: 0.9263 - val_loss: 0.8844 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.77458\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.00104624.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3237 - accuracy: 0.9282 - val_loss: 1.0665 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.77458\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0010409599999999998.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3249 - accuracy: 0.9274 - val_loss: 1.2020 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.77458\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.001036.\n",
      "68/68 [==============================] - 25s 362ms/step - loss: 0.3170 - accuracy: 0.9307 - val_loss: 0.8861 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.77458\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.00103136.\n",
      "68/68 [==============================] - 24s 358ms/step - loss: 0.3187 - accuracy: 0.9279 - val_loss: 0.9755 - val_accuracy: 0.7706\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.77458\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0010270400000000001.\n",
      "68/68 [==============================] - 25s 363ms/step - loss: 0.3198 - accuracy: 0.9283 - val_loss: 0.9467 - val_accuracy: 0.7706\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.77458\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.00102304.\n",
      "68/68 [==============================] - 26s 383ms/step - loss: 0.3200 - accuracy: 0.9281 - val_loss: 0.9050 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.77458\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.00101936.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.3141 - accuracy: 0.9306 - val_loss: 0.8438 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.77458\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.001016.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.3172 - accuracy: 0.9298 - val_loss: 1.0973 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.77458\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.00101296.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3169 - accuracy: 0.9301 - val_loss: 0.8396 - val_accuracy: 0.7689\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.77458\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.0010102400000000001.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3161 - accuracy: 0.9294 - val_loss: 0.7733 - val_accuracy: 0.7723\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.77458\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.00100784.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.3160 - accuracy: 0.9299 - val_loss: 1.0268 - val_accuracy: 0.7715\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.77458\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.00100576.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3152 - accuracy: 0.9298 - val_loss: 1.0937 - val_accuracy: 0.7717\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.77458\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.0010040000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 25s 360ms/step - loss: 0.3161 - accuracy: 0.9291 - val_loss: 0.9880 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.77458\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.00100256.\n",
      "68/68 [==============================] - 25s 362ms/step - loss: 0.3151 - accuracy: 0.9296 - val_loss: 1.0019 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.77458\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.00100144.\n",
      "68/68 [==============================] - 24s 357ms/step - loss: 0.3176 - accuracy: 0.9289 - val_loss: 1.2001 - val_accuracy: 0.7723\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.77458\n",
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.0010006400000000001.\n",
      "68/68 [==============================] - 24s 360ms/step - loss: 0.3144 - accuracy: 0.9301 - val_loss: 0.9580 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.77458\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.00100016.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.3170 - accuracy: 0.9308 - val_loss: 1.0929 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.77458\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3202 - accuracy: 0.9294 - val_loss: 1.0547 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.77458\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 358ms/step - loss: 0.3092 - accuracy: 0.9305 - val_loss: 0.9645 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.77458\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3131 - accuracy: 0.9297 - val_loss: 0.7192 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.77458\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 359ms/step - loss: 0.3096 - accuracy: 0.9312 - val_loss: 1.0926 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.77458\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3145 - accuracy: 0.9289 - val_loss: 1.0586 - val_accuracy: 0.7737\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.77458\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 358ms/step - loss: 0.3107 - accuracy: 0.9305 - val_loss: 1.1385 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.77458\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3122 - accuracy: 0.9315 - val_loss: 0.8894 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.77458\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.3127 - accuracy: 0.9309 - val_loss: 0.9270 - val_accuracy: 0.7733\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.77458\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.3130 - accuracy: 0.9319 - val_loss: 0.9441 - val_accuracy: 0.7731\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.77458\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3105 - accuracy: 0.9309 - val_loss: 0.9994 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.77458\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.3105 - accuracy: 0.9332 - val_loss: 0.8760 - val_accuracy: 0.7704\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.77458\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.3076 - accuracy: 0.9330 - val_loss: 0.9258 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00262: val_accuracy improved from 0.77458 to 0.77500, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 358ms/step - loss: 0.3074 - accuracy: 0.9319 - val_loss: 1.1713 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.77500\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3102 - accuracy: 0.9309 - val_loss: 0.9554 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.77500\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.3085 - accuracy: 0.9318 - val_loss: 1.0725 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.77500\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.3079 - accuracy: 0.9317 - val_loss: 0.8834 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.77500\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3081 - accuracy: 0.9316 - val_loss: 0.9828 - val_accuracy: 0.7693\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.77500\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.3099 - accuracy: 0.9306 - val_loss: 1.0524 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.77500\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.3061 - accuracy: 0.9327 - val_loss: 1.1952 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.77500\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.3053 - accuracy: 0.9337 - val_loss: 0.7554 - val_accuracy: 0.7733\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.77500\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 24s 352ms/step - loss: 0.3058 - accuracy: 0.9329 - val_loss: 0.9295 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.77500\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 357ms/step - loss: 0.3067 - accuracy: 0.9323 - val_loss: 1.0658 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.77500\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.3064 - accuracy: 0.9325 - val_loss: 0.8422 - val_accuracy: 0.7774\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00273: val_accuracy improved from 0.77500 to 0.77736, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 358ms/step - loss: 0.3053 - accuracy: 0.9344 - val_loss: 1.0210 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.77736\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.3011 - accuracy: 0.9326 - val_loss: 1.0954 - val_accuracy: 0.7712\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.77736\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.3057 - accuracy: 0.9330 - val_loss: 0.8219 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.77736\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 358ms/step - loss: 0.3045 - accuracy: 0.9330 - val_loss: 0.9251 - val_accuracy: 0.7721\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.77736\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 357ms/step - loss: 0.3026 - accuracy: 0.9349 - val_loss: 0.9933 - val_accuracy: 0.7742\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.77736\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.3065 - accuracy: 0.9340 - val_loss: 1.0241 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.77736\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3057 - accuracy: 0.9335 - val_loss: 1.1303 - val_accuracy: 0.7729\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.77736\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.3020 - accuracy: 0.9312 - val_loss: 1.0113 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.77736\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2984 - accuracy: 0.9353 - val_loss: 0.9307 - val_accuracy: 0.7717\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.77736\n",
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3043 - accuracy: 0.9329 - val_loss: 1.1727 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.77736\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.3054 - accuracy: 0.9324 - val_loss: 1.2357 - val_accuracy: 0.7706\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.77736\n",
      "Epoch 285/2000\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.3022 - accuracy: 0.9340 - val_loss: 1.0766 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.77736\n",
      "Epoch 286/2000\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.3018 - accuracy: 0.9351 - val_loss: 1.1663 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.77736\n",
      "Epoch 287/2000\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.3031 - accuracy: 0.9349 - val_loss: 0.9843 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.77736\n",
      "Epoch 288/2000\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2964 - accuracy: 0.9353 - val_loss: 0.9871 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.77736\n",
      "Epoch 289/2000\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.3012 - accuracy: 0.9348 - val_loss: 0.9849 - val_accuracy: 0.7674\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.77736\n",
      "Epoch 290/2000\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.2975 - accuracy: 0.9350 - val_loss: 1.1185 - val_accuracy: 0.7719\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.77736\n",
      "Epoch 291/2000\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.3016 - accuracy: 0.9340 - val_loss: 1.0583 - val_accuracy: 0.7719\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.77736\n",
      "Epoch 292/2000\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.3031 - accuracy: 0.9326 - val_loss: 1.1110 - val_accuracy: 0.7722\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.77736\n",
      "Epoch 293/2000\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.3020 - accuracy: 0.9355 - val_loss: 1.0941 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.77736\n",
      "Epoch 294/2000\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2978 - accuracy: 0.9350 - val_loss: 1.1687 - val_accuracy: 0.7719\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.77736\n",
      "Epoch 295/2000\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.3042 - accuracy: 0.9343 - val_loss: 1.1833 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.77736\n",
      "Epoch 296/2000\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2975 - accuracy: 0.9360 - val_loss: 1.0006 - val_accuracy: 0.7686\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.77736\n",
      "Epoch 297/2000\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2988 - accuracy: 0.9348 - val_loss: 0.9285 - val_accuracy: 0.7724\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.77736\n",
      "Epoch 298/2000\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2969 - accuracy: 0.9373 - val_loss: 0.9726 - val_accuracy: 0.7719\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.77736\n",
      "Epoch 299/2000\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2951 - accuracy: 0.9361 - val_loss: 1.0469 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.77736\n",
      "Epoch 300/2000\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2968 - accuracy: 0.9361 - val_loss: 0.9093 - val_accuracy: 0.7749\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.77736\n",
      "Epoch 301/2000\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2982 - accuracy: 0.9343 - val_loss: 0.9466 - val_accuracy: 0.7688\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.77736\n",
      "Epoch 302/2000\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2980 - accuracy: 0.9364 - val_loss: 0.9029 - val_accuracy: 0.7707\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.77736\n",
      "Epoch 303/2000\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2970 - accuracy: 0.9352 - val_loss: 1.0908 - val_accuracy: 0.7704\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.77736\n",
      "Epoch 304/2000\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.2982 - accuracy: 0.9361 - val_loss: 0.9241 - val_accuracy: 0.7689\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.77736\n",
      "Epoch 305/2000\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2933 - accuracy: 0.9386 - val_loss: 1.1171 - val_accuracy: 0.7745\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.77736\n",
      "Epoch 306/2000\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2940 - accuracy: 0.9364 - val_loss: 1.1282 - val_accuracy: 0.7717\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.77736\n",
      "Epoch 307/2000\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 350ms/step - loss: 0.2939 - accuracy: 0.9354 - val_loss: 1.0793 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.77736\n",
      "Epoch 308/2000\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.2931 - accuracy: 0.9359 - val_loss: 0.8780 - val_accuracy: 0.7710\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.77736\n",
      "Epoch 309/2000\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.2928 - accuracy: 0.9374 - val_loss: 0.9810 - val_accuracy: 0.7723\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.77736\n",
      "Epoch 310/2000\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.2944 - accuracy: 0.9348 - val_loss: 1.0435 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.77736\n",
      "Epoch 311/2000\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.2918 - accuracy: 0.9372 - val_loss: 0.9421 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.77736\n",
      "Epoch 312/2000\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 357ms/step - loss: 0.2962 - accuracy: 0.9371 - val_loss: 1.0950 - val_accuracy: 0.7699\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.77736\n",
      "Epoch 313/2000\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.2933 - accuracy: 0.9378 - val_loss: 1.0355 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.77736\n",
      "Epoch 314/2000\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 357ms/step - loss: 0.2960 - accuracy: 0.9367 - val_loss: 0.9198 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.77736\n",
      "Epoch 315/2000\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.2929 - accuracy: 0.9356 - val_loss: 0.9999 - val_accuracy: 0.7693\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.77736\n",
      "Epoch 316/2000\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2914 - accuracy: 0.9366 - val_loss: 0.9813 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.77736\n",
      "Epoch 317/2000\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 353ms/step - loss: 0.2896 - accuracy: 0.9367 - val_loss: 1.0330 - val_accuracy: 0.7691\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.77736\n",
      "Epoch 318/2000\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.2896 - accuracy: 0.9379 - val_loss: 1.0222 - val_accuracy: 0.7706\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.77736\n",
      "Epoch 319/2000\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2918 - accuracy: 0.9356 - val_loss: 0.9395 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.77736\n",
      "Epoch 320/2000\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2908 - accuracy: 0.9371 - val_loss: 1.0012 - val_accuracy: 0.7724\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.77736\n",
      "Epoch 321/2000\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.2962 - accuracy: 0.9370 - val_loss: 0.9574 - val_accuracy: 0.7693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00321: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.77736\n",
      "Epoch 322/2000\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 352ms/step - loss: 0.2913 - accuracy: 0.9374 - val_loss: 0.9460 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.77736\n",
      "Epoch 323/2000\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 351ms/step - loss: 0.2898 - accuracy: 0.9351 - val_loss: 0.9685 - val_accuracy: 0.7723\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.77736\n",
      "Epoch 324/2000\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 26s 375ms/step - loss: 0.2899 - accuracy: 0.9391 - val_loss: 1.0796 - val_accuracy: 0.7739\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.77736\n",
      "Epoch 325/2000\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 355ms/step - loss: 0.2903 - accuracy: 0.9378 - val_loss: 0.9891 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.77736\n",
      "Epoch 326/2000\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 356ms/step - loss: 0.2892 - accuracy: 0.9377 - val_loss: 1.0484 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.77736\n",
      "Epoch 327/2000\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 24s 354ms/step - loss: 0.2870 - accuracy: 0.9376 - val_loss: 1.0746 - val_accuracy: 0.7691\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.77736\n",
      "Epoch 328/2000\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 26s 384ms/step - loss: 0.2915 - accuracy: 0.9365 - val_loss: 1.1984 - val_accuracy: 0.7662\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.77736\n",
      "Epoch 329/2000\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 50s 730ms/step - loss: 0.2873 - accuracy: 0.9389 - val_loss: 1.1926 - val_accuracy: 0.7678\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.77736\n",
      "Epoch 330/2000\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 33s 493ms/step - loss: 0.2875 - accuracy: 0.9404 - val_loss: 0.8454 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.77736\n",
      "Epoch 331/2000\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 374ms/step - loss: 0.2856 - accuracy: 0.9402 - val_loss: 0.9478 - val_accuracy: 0.7699\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.77736\n",
      "Epoch 332/2000\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 369ms/step - loss: 0.2862 - accuracy: 0.9373 - val_loss: 1.0858 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.77736\n",
      "Epoch 333/2000\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.2872 - accuracy: 0.9397 - val_loss: 0.9002 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.77736\n",
      "Epoch 334/2000\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.2849 - accuracy: 0.9401 - val_loss: 1.1780 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.77736\n",
      "Epoch 335/2000\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.2865 - accuracy: 0.9381 - val_loss: 0.9722 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.77736\n",
      "Epoch 336/2000\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 369ms/step - loss: 0.2838 - accuracy: 0.9395 - val_loss: 1.0491 - val_accuracy: 0.7714\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.77736\n",
      "Epoch 337/2000\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.2845 - accuracy: 0.9385 - val_loss: 1.1564 - val_accuracy: 0.7680\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.77736\n",
      "Epoch 338/2000\n",
      "\n",
      "Epoch 00338: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 370ms/step - loss: 0.2865 - accuracy: 0.9381 - val_loss: 0.9296 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.77736\n",
      "Epoch 339/2000\n",
      "\n",
      "Epoch 00339: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 26s 378ms/step - loss: 0.2884 - accuracy: 0.9390 - val_loss: 0.9543 - val_accuracy: 0.7738\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.77736\n",
      "Epoch 340/2000\n",
      "\n",
      "Epoch 00340: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 27s 395ms/step - loss: 0.2845 - accuracy: 0.9398 - val_loss: 0.9707 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.77736\n",
      "Epoch 341/2000\n",
      "\n",
      "Epoch 00341: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 369ms/step - loss: 0.2809 - accuracy: 0.9399 - val_loss: 0.9307 - val_accuracy: 0.7739\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.77736\n",
      "Epoch 342/2000\n",
      "\n",
      "Epoch 00342: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 363ms/step - loss: 0.2851 - accuracy: 0.9397 - val_loss: 1.0530 - val_accuracy: 0.7720\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.77736\n",
      "Epoch 343/2000\n",
      "\n",
      "Epoch 00343: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 26s 376ms/step - loss: 0.2873 - accuracy: 0.9391 - val_loss: 0.9852 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.77736\n",
      "Epoch 344/2000\n",
      "\n",
      "Epoch 00344: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.2836 - accuracy: 0.9402 - val_loss: 1.1633 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.77736\n",
      "Epoch 345/2000\n",
      "\n",
      "Epoch 00345: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.2819 - accuracy: 0.9405 - val_loss: 0.9782 - val_accuracy: 0.7690\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.77736\n",
      "Epoch 346/2000\n",
      "\n",
      "Epoch 00346: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.2859 - accuracy: 0.9394 - val_loss: 0.8637 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.77736\n",
      "Epoch 347/2000\n",
      "\n",
      "Epoch 00347: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 25s 362ms/step - loss: 0.2841 - accuracy: 0.9400 - val_loss: 1.0253 - val_accuracy: 0.7694\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.77736\n",
      "Epoch 348/2000\n",
      "\n",
      "Epoch 00348: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.2869 - accuracy: 0.9383 - val_loss: 0.9799 - val_accuracy: 0.7712\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.77736\n",
      "Epoch 349/2000\n",
      "\n",
      "Epoch 00349: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 370ms/step - loss: 0.2876 - accuracy: 0.9402 - val_loss: 1.0780 - val_accuracy: 0.7718\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.77736\n",
      "Epoch 350/2000\n",
      "\n",
      "Epoch 00350: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.2844 - accuracy: 0.9393 - val_loss: 1.1137 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.77736\n",
      "Epoch 351/2000\n",
      "\n",
      "Epoch 00351: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.2807 - accuracy: 0.9401 - val_loss: 1.1255 - val_accuracy: 0.7688\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.77736\n",
      "Epoch 352/2000\n",
      "\n",
      "Epoch 00352: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.2808 - accuracy: 0.9398 - val_loss: 0.9993 - val_accuracy: 0.7706\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.77736\n",
      "Epoch 353/2000\n",
      "\n",
      "Epoch 00353: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 369ms/step - loss: 0.2825 - accuracy: 0.9397 - val_loss: 1.1110 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.77736\n",
      "Epoch 354/2000\n",
      "\n",
      "Epoch 00354: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.2838 - accuracy: 0.9401 - val_loss: 0.9238 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.77736\n",
      "Epoch 355/2000\n",
      "\n",
      "Epoch 00355: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.2797 - accuracy: 0.9416 - val_loss: 1.1647 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.77736\n",
      "Epoch 356/2000\n",
      "\n",
      "Epoch 00356: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.2789 - accuracy: 0.9428 - val_loss: 1.0291 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.77736\n",
      "Epoch 357/2000\n",
      "\n",
      "Epoch 00357: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.2798 - accuracy: 0.9400 - val_loss: 0.9654 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.77736\n",
      "Epoch 358/2000\n",
      "\n",
      "Epoch 00358: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 368ms/step - loss: 0.2820 - accuracy: 0.9407 - val_loss: 1.0503 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.77736\n",
      "Epoch 359/2000\n",
      "\n",
      "Epoch 00359: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 374ms/step - loss: 0.2797 - accuracy: 0.9407 - val_loss: 1.0334 - val_accuracy: 0.7690\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.77736\n",
      "Epoch 360/2000\n",
      "\n",
      "Epoch 00360: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 371ms/step - loss: 0.2824 - accuracy: 0.9395 - val_loss: 0.9818 - val_accuracy: 0.7712\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.77736\n",
      "Epoch 361/2000\n",
      "\n",
      "Epoch 00361: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.2834 - accuracy: 0.9404 - val_loss: 0.9509 - val_accuracy: 0.7682\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.77736\n",
      "Epoch 362/2000\n",
      "\n",
      "Epoch 00362: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.2782 - accuracy: 0.9411 - val_loss: 1.0756 - val_accuracy: 0.7711\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.77736\n",
      "Epoch 363/2000\n",
      "\n",
      "Epoch 00363: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.2764 - accuracy: 0.9418 - val_loss: 0.8351 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.77736\n",
      "Epoch 364/2000\n",
      "\n",
      "Epoch 00364: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 26s 386ms/step - loss: 0.2817 - accuracy: 0.9410 - val_loss: 0.9059 - val_accuracy: 0.7707\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.77736\n",
      "Epoch 365/2000\n",
      "\n",
      "Epoch 00365: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 362ms/step - loss: 0.2833 - accuracy: 0.9403 - val_loss: 1.0443 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.77736\n",
      "Epoch 366/2000\n",
      "\n",
      "Epoch 00366: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 367ms/step - loss: 0.2827 - accuracy: 0.9395 - val_loss: 1.0359 - val_accuracy: 0.7766\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.77736\n",
      "Epoch 367/2000\n",
      "\n",
      "Epoch 00367: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.2815 - accuracy: 0.9412 - val_loss: 0.9236 - val_accuracy: 0.7685\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.77736\n",
      "Epoch 368/2000\n",
      "\n",
      "Epoch 00368: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 361ms/step - loss: 0.2787 - accuracy: 0.9432 - val_loss: 0.8830 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.77736\n",
      "Epoch 369/2000\n",
      "\n",
      "Epoch 00369: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 363ms/step - loss: 0.2755 - accuracy: 0.9414 - val_loss: 0.9981 - val_accuracy: 0.7727\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.77736\n",
      "Epoch 370/2000\n",
      "\n",
      "Epoch 00370: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 364ms/step - loss: 0.2822 - accuracy: 0.9393 - val_loss: 1.2048 - val_accuracy: 0.7698\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.77736\n",
      "Epoch 371/2000\n",
      "\n",
      "Epoch 00371: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.2768 - accuracy: 0.9406 - val_loss: 0.9857 - val_accuracy: 0.7708\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.77736\n",
      "Epoch 372/2000\n",
      "\n",
      "Epoch 00372: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 366ms/step - loss: 0.2773 - accuracy: 0.9424 - val_loss: 1.0548 - val_accuracy: 0.7737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00372: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.77736\n",
      "Epoch 373/2000\n",
      "\n",
      "Epoch 00373: LearningRateScheduler setting learning rate to 0.001.\n",
      "68/68 [==============================] - 25s 365ms/step - loss: 0.2761 - accuracy: 0.9426 - val_loss: 0.8880 - val_accuracy: 0.7731\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.71783\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.77736\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00373: early stopping\n",
      "## Saved in /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.pickle ###\n",
      "\n",
      "\n",
      "Loading maxAccModelName\n",
      "moving maxAccModelName to modelFileNamePath\n",
      "Model for MAX ACCURACY test_acc: 77.736 val_acc: 77.736\n",
      "Model for MIN LOSS test_acc: 77.458 val_acc: 77.458\n",
      "Loading previous results...\n",
      "Dumping results...\n",
      "######## 4/16 - pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05 - Cross_view/ ########\n",
      "touching /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.h5\n",
      "## To be saved in [...]/savedModels/Cross_view/ ###\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_VIEW-dataset.pickle\n",
      "train_set shape: (30336,)\n",
      "train_set zero elements: 4314940/100491930 (4.3%)\n",
      "val_set shape: (7584,)\n",
      "val_set zero elements: 1225598/25026006 (4.9%)\n",
      "test_set shape: (18960,)\n",
      "test_set zero elements: 1832022/62663190 (2.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 30336\n",
      "## NEW LENGHT OF DATSET: 30336\n",
      "## OLD LENGHT OF DATSET: 7584\n",
      "## NEW LENGHT OF DATSET: 7584\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "Adapting the data to the next 3 frame\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (30336, 299, 34, 2)\n",
      "train set zero elements (after padding): 517520120 (83.91%)\n",
      "val set shape: (7584, 299, 34, 2)\n",
      "val set zero elements (after padding): 129477032 (83.97%)\n",
      "test set shape: (18960, 299, 34, 2)\n",
      "test set zero elements (after padding): 323594354 (83.94%)\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_VIEW-dataset.pickle\n",
      "train_set shape: (30336,)\n",
      "train_set zero elements: 4314940/100491930 (4.3%)\n",
      "val_set shape: (7584,)\n",
      "val_set zero elements: 1225598/25026006 (4.9%)\n",
      "test_set shape: (18960,)\n",
      "test_set zero elements: 1832022/62663190 (2.9%)\n",
      "Preproccesing dataset...\n",
      "## OLD LENGHT OF DATSET: 30336\n",
      "## NEW LENGHT OF DATSET: 30336\n",
      "## OLD LENGHT OF DATSET: 7584\n",
      "## NEW LENGHT OF DATSET: 7584\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "classes order: ['1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21' '22'\n",
      " '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35' '36'\n",
      " '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49' '5'\n",
      " '50' '51' '52' '53' '54' '55' '56' '57' '58' '59' '6' '60' '7' '8' '9']\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "removing zeros from dataset\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "normalising EACH VIDEO, considering x and y INDIPENDENTLY\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\n",
      "normalising together train, val and test values BEFORE padding\n",
      "train set shape: (30336, 300, 34, 2)\n",
      "train set zero elements (after padding): 518362470 (83.76%)\n",
      "val set shape: (7584, 300, 34, 2)\n",
      "val set zero elements (after padding): 129687594 (83.82%)\n",
      "test set shape: (18960, 300, 34, 2)\n",
      "test set zero elements (after padding): 324120810 (83.80%)\n",
      "## MERGING TRAIN+VAL ##\n",
      "#### CREATINGS COMBINATION OF BEST STRUCTURES #######\n",
      "### FITTING WITH GENERATORS  ####\n",
      "## VALIDATION len of data 18960 - batch size 600\n",
      "## VALIDATION missing_train = 240\n",
      "## TRAINING len of data 37920 - batch size 600\n",
      "## TRAINING missing_train = 480\n",
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.011.\n",
      "64/64 [==============================] - 40s 624ms/step - loss: 4.1077 - accuracy: 0.0165 - val_loss: 4.1014 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.10141, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.01667, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.010920160000000002.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 4.0972 - accuracy: 0.0152 - val_loss: 4.0963 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.10141 to 4.09634, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.01667\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.010840639999999999.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 4.0960 - accuracy: 0.0160 - val_loss: 4.0932 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.09634 to 4.09322, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.01667\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.01076144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 374ms/step - loss: 4.0957 - accuracy: 0.0157 - val_loss: 4.0939 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.01667\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.01068256.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 4.0957 - accuracy: 0.0147 - val_loss: 4.0950 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.01667\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.010603999999999999.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 4.0956 - accuracy: 0.0155 - val_loss: 4.1073 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.01667\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.010525759999999999.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 4.0957 - accuracy: 0.0152 - val_loss: 4.0939 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.01667\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.01044784.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 4.0957 - accuracy: 0.0151 - val_loss: 4.0952 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.01667\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.01037024.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 4.0953 - accuracy: 0.0153 - val_loss: 4.0965 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.01667 to 0.01677, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.01029296.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 4.0953 - accuracy: 0.0159 - val_loss: 4.0958 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.01677\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.010216.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 4.0954 - accuracy: 0.0158 - val_loss: 4.0941 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.01677\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.01013936.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 4.0953 - accuracy: 0.0146 - val_loss: 4.0947 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.01677\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.010063039999999999.\n",
      "64/64 [==============================] - 24s 368ms/step - loss: 4.0953 - accuracy: 0.0147 - val_loss: 4.0958 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.01677\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.009987039999999999.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 4.0953 - accuracy: 0.0150 - val_loss: 4.0946 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.01677\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.009911360000000001.\n",
      "64/64 [==============================] - 24s 367ms/step - loss: 4.0953 - accuracy: 0.0147 - val_loss: 4.0935 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.01677\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.009836000000000001.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 4.0952 - accuracy: 0.0156 - val_loss: 4.0958 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.01677\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.009760959999999999.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 4.0952 - accuracy: 0.0154 - val_loss: 4.0969 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.01677\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.009686239999999999.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 4.0953 - accuracy: 0.0152 - val_loss: 4.0937 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.01677\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.00961184.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 4.1203 - accuracy: 0.0152 - val_loss: 4.0933 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.01677\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.009537760000000003.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 4.0955 - accuracy: 0.0158 - val_loss: 4.0948 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.09322\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.01677 to 0.01682, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.009464.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 4.0338 - accuracy: 0.0250 - val_loss: 3.9787 - val_accuracy: 0.0279\n",
      "\n",
      "Epoch 00021: val_loss improved from 4.09322 to 3.97870, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.01682 to 0.02790, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.00939056.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 4.0690 - accuracy: 0.0186 - val_loss: 4.0994 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.97870\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.02790\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.00931744.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 4.0964 - accuracy: 0.0169 - val_loss: 4.0930 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.97870\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.02790\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.009244640000000002.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 4.0989 - accuracy: 0.0165 - val_loss: 4.0953 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.97870\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.02790\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.009172160000000002.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 4.0969 - accuracy: 0.0155 - val_loss: 4.0948 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.97870\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.02790\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0091.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 373ms/step - loss: 4.0956 - accuracy: 0.0151 - val_loss: 4.0622 - val_accuracy: 0.0313\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.97870\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.02790 to 0.03133, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.00902816.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 4.0794 - accuracy: 0.0197 - val_loss: 3.8805 - val_accuracy: 0.0437\n",
      "\n",
      "Epoch 00027: val_loss improved from 3.97870 to 3.88048, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.03133 to 0.04372, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.008956640000000002.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 3.7621 - accuracy: 0.0618 - val_loss: 3.5410 - val_accuracy: 0.0986\n",
      "\n",
      "Epoch 00028: val_loss improved from 3.88048 to 3.54102, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.04372 to 0.09858, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.008885440000000001.\n",
      "64/64 [==============================] - 24s 369ms/step - loss: 3.4641 - accuracy: 0.1090 - val_loss: 3.1535 - val_accuracy: 0.1618\n",
      "\n",
      "Epoch 00029: val_loss improved from 3.54102 to 3.15349, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.09858 to 0.16176, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.008814559999999999.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 3.2248 - accuracy: 0.1573 - val_loss: 2.9830 - val_accuracy: 0.1953\n",
      "\n",
      "Epoch 00030: val_loss improved from 3.15349 to 2.98296, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.16176 to 0.19531, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.008744.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 2.9328 - accuracy: 0.2365 - val_loss: 2.6133 - val_accuracy: 0.3156\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.98296 to 2.61333, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.19531 to 0.31561, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.008673759999999999.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 2.6862 - accuracy: 0.3024 - val_loss: 3.1702 - val_accuracy: 0.2057\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.61333\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.31561\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.00860384.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 2.5423 - accuracy: 0.3522 - val_loss: 2.2746 - val_accuracy: 0.3829\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.61333 to 2.27456, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.31561 to 0.38286, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.00853424.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 2.4124 - accuracy: 0.3966 - val_loss: 2.3059 - val_accuracy: 0.4428\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.27456\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.38286 to 0.44277, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.00846496.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 2.2676 - accuracy: 0.4187 - val_loss: 1.8394 - val_accuracy: 0.5097\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.27456 to 1.83941, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.44277 to 0.50970, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.008396.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 2.1367 - accuracy: 0.4503 - val_loss: 1.9856 - val_accuracy: 0.5224\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.83941\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.50970 to 0.52242, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.008327359999999999.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 2.0380 - accuracy: 0.4827 - val_loss: 1.9420 - val_accuracy: 0.5198\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.83941\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.52242\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.00825904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 374ms/step - loss: 2.0161 - accuracy: 0.4977 - val_loss: 2.4012 - val_accuracy: 0.3640\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.83941\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.52242\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.00819104.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 2.0015 - accuracy: 0.4908 - val_loss: 1.6855 - val_accuracy: 0.5925\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.83941 to 1.68548, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.52242 to 0.59251, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.00812336.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 1.8438 - accuracy: 0.5513 - val_loss: 1.6390 - val_accuracy: 0.6338\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.68548 to 1.63901, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.59251 to 0.63381, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.008055999999999999.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 1.7985 - accuracy: 0.5717 - val_loss: 1.5294 - val_accuracy: 0.6403\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.63901 to 1.52943, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.63381 to 0.64035, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.00798896.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 1.7158 - accuracy: 0.5893 - val_loss: 1.5581 - val_accuracy: 0.6524\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.52943\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.64035 to 0.65243, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.00792224.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.6754 - accuracy: 0.6048 - val_loss: 1.4539 - val_accuracy: 0.6375\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.52943 to 1.45391, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.65243\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.007855840000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.6264 - accuracy: 0.6236 - val_loss: 1.4975 - val_accuracy: 0.6623\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.45391\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.65243 to 0.66229, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0077897600000000015.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 1.5980 - accuracy: 0.6321 - val_loss: 1.7734 - val_accuracy: 0.5135\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.45391\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.66229\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.007724000000000001.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 1.5718 - accuracy: 0.6393 - val_loss: 1.3691 - val_accuracy: 0.7013\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.45391 to 1.36914, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.66229 to 0.70132, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.007658560000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.5315 - accuracy: 0.6527 - val_loss: 1.3300 - val_accuracy: 0.6935\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.36914 to 1.32995, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.70132\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.007593440000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.4833 - accuracy: 0.6662 - val_loss: 1.2786 - val_accuracy: 0.6981\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.32995 to 1.27861, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.70132\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.007528640000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.4399 - accuracy: 0.6727 - val_loss: 1.4397 - val_accuracy: 0.7018\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.27861\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.70132 to 0.70185, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.007464160000000001.\n",
      "64/64 [==============================] - 23s 367ms/step - loss: 1.4113 - accuracy: 0.6807 - val_loss: 1.2273 - val_accuracy: 0.7212\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.27861 to 1.22726, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.70185 to 0.72120, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.007400000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 374ms/step - loss: 1.3791 - accuracy: 0.6883 - val_loss: 1.2541 - val_accuracy: 0.7178\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.22726\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.72120\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.00733616.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.3456 - accuracy: 0.6947 - val_loss: 1.2974 - val_accuracy: 0.7194\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.22726\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.72120\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.00727264.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 1.3229 - accuracy: 0.7011 - val_loss: 1.1916 - val_accuracy: 0.7174\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.22726 to 1.19158, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.72120\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.007209440000000001.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 1.2918 - accuracy: 0.7088 - val_loss: 1.2562 - val_accuracy: 0.7270\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.19158\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.72120 to 0.72695, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0071465600000000015.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.2709 - accuracy: 0.7155 - val_loss: 1.1186 - val_accuracy: 0.7394\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.19158 to 1.11861, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.72695 to 0.73940, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.007084000000000001.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 1.2476 - accuracy: 0.7199 - val_loss: 1.1214 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.11861\n",
      "\n",
      "Epoch 00056: val_accuracy improved from 0.73940 to 0.75042, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.007021760000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.2247 - accuracy: 0.7284 - val_loss: 1.3609 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.11861\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.75042\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.006959840000000001.\n",
      "64/64 [==============================] - 24s 369ms/step - loss: 1.2036 - accuracy: 0.7284 - val_loss: 1.1493 - val_accuracy: 0.7514\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.11861\n",
      "\n",
      "Epoch 00058: val_accuracy improved from 0.75042 to 0.75137, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.00689824.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 1.1814 - accuracy: 0.7322 - val_loss: 1.1915 - val_accuracy: 0.7467\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.11861\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.75137\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.00683696.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.1545 - accuracy: 0.7397 - val_loss: 1.0700 - val_accuracy: 0.7576\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.11861 to 1.07002, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.75137 to 0.75765, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.006776.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 1.1284 - accuracy: 0.7448 - val_loss: 0.9211 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.07002 to 0.92110, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.75765 to 0.76023, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.006715360000000001.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 1.1207 - accuracy: 0.7417 - val_loss: 0.9801 - val_accuracy: 0.7523\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.92110\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.76023\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.00665504.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 1.0946 - accuracy: 0.7473 - val_loss: 1.0732 - val_accuracy: 0.7661\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.92110\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.76023 to 0.76614, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.00659504.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 1.0729 - accuracy: 0.7509 - val_loss: 1.0531 - val_accuracy: 0.7706\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.92110\n",
      "\n",
      "Epoch 00064: val_accuracy improved from 0.76614 to 0.77057, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0065353600000000005.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 1.0600 - accuracy: 0.7557 - val_loss: 1.0084 - val_accuracy: 0.7690\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.92110\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.77057\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.006476.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 1.0407 - accuracy: 0.7598 - val_loss: 1.0184 - val_accuracy: 0.7648\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.92110\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.77057\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.006416959999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 372ms/step - loss: 1.0215 - accuracy: 0.7590 - val_loss: 0.9422 - val_accuracy: 0.7766\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.92110\n",
      "\n",
      "Epoch 00067: val_accuracy improved from 0.77057 to 0.77664, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.006358239999999999.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 1.0072 - accuracy: 0.7630 - val_loss: 0.9077 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.92110 to 0.90769, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.77664\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.00629984.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 1.0016 - accuracy: 0.7679 - val_loss: 0.8780 - val_accuracy: 0.7705\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.90769 to 0.87802, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.77664\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.00624176.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.9785 - accuracy: 0.7709 - val_loss: 1.0234 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.87802\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.77664\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.006184.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.9676 - accuracy: 0.7721 - val_loss: 0.9005 - val_accuracy: 0.7763\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.87802\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.77664\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.0061265600000000005.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.9580 - accuracy: 0.7761 - val_loss: 0.9467 - val_accuracy: 0.7799\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.87802\n",
      "\n",
      "Epoch 00072: val_accuracy improved from 0.77664 to 0.77991, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.00606944.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.9463 - accuracy: 0.7754 - val_loss: 0.8854 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.87802\n",
      "\n",
      "Epoch 00073: val_accuracy improved from 0.77991 to 0.78966, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.00601264.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.9315 - accuracy: 0.7817 - val_loss: 0.8327 - val_accuracy: 0.7867\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.87802 to 0.83272, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.78966\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.005956159999999999.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.9118 - accuracy: 0.7854 - val_loss: 0.8252 - val_accuracy: 0.7921\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.83272 to 0.82525, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00075: val_accuracy improved from 0.78966 to 0.79209, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.0059.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.9064 - accuracy: 0.7903 - val_loss: 0.8805 - val_accuracy: 0.7917\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.82525\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.79209\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.005844159999999999.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.9042 - accuracy: 0.7877 - val_loss: 0.8720 - val_accuracy: 0.7868\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.82525\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.79209\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.005788639999999999.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.8893 - accuracy: 0.7907 - val_loss: 0.9021 - val_accuracy: 0.7921\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.82525\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.79209\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.005733439999999999.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.8782 - accuracy: 0.7939 - val_loss: 0.7941 - val_accuracy: 0.7893\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.82525 to 0.79411, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.79209\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.005678559999999999.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.8656 - accuracy: 0.7965 - val_loss: 0.7050 - val_accuracy: 0.7869\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.79411 to 0.70500, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.79209\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.005624.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.8581 - accuracy: 0.7978 - val_loss: 0.9165 - val_accuracy: 0.7953\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00081: val_accuracy improved from 0.79209 to 0.79531, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.005569759999999999.\n",
      "64/64 [==============================] - 24s 368ms/step - loss: 0.8523 - accuracy: 0.8012 - val_loss: 0.8057 - val_accuracy: 0.7928\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.79531\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.005515839999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 371ms/step - loss: 0.8370 - accuracy: 0.8023 - val_loss: 0.9201 - val_accuracy: 0.7938\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.79531\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.005462239999999999.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.8330 - accuracy: 0.8043 - val_loss: 0.7960 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00084: val_accuracy improved from 0.79531 to 0.80364, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.005408959999999999.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.8184 - accuracy: 0.8061 - val_loss: 0.8081 - val_accuracy: 0.7977\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.80364\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.005355999999999999.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.8169 - accuracy: 0.8074 - val_loss: 0.8993 - val_accuracy: 0.7892\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.80364\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.005303360000000001.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.8033 - accuracy: 0.8116 - val_loss: 0.8043 - val_accuracy: 0.7986\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.80364\n",
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.00525104.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.8029 - accuracy: 0.8111 - val_loss: 0.9187 - val_accuracy: 0.7944\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.80364\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.00519904.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.7924 - accuracy: 0.8127 - val_loss: 0.8080 - val_accuracy: 0.7898\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.80364\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.005147360000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.7912 - accuracy: 0.8109 - val_loss: 0.7784 - val_accuracy: 0.8007\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.70500\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.80364\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.005096000000000001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.7782 - accuracy: 0.8164 - val_loss: 0.6615 - val_accuracy: 0.7967\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.70500 to 0.66146, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.80364\n",
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.00504496.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.7721 - accuracy: 0.8147 - val_loss: 0.7189 - val_accuracy: 0.8054\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00092: val_accuracy improved from 0.80364 to 0.80538, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.0049942400000000005.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.7663 - accuracy: 0.8178 - val_loss: 0.8084 - val_accuracy: 0.8023\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.80538\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.0049438400000000006.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.7568 - accuracy: 0.8214 - val_loss: 0.7377 - val_accuracy: 0.8074\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.80538 to 0.80744, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.0048937600000000005.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.7526 - accuracy: 0.8194 - val_loss: 0.7689 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.80744\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.004844.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.7422 - accuracy: 0.8235 - val_loss: 0.7379 - val_accuracy: 0.8033\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.80744\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.00479456.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.7366 - accuracy: 0.8239 - val_loss: 0.7826 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00097: val_accuracy improved from 0.80744 to 0.81039, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.00474544.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.7268 - accuracy: 0.8267 - val_loss: 0.7057 - val_accuracy: 0.8088\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.81039\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.00469664.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.7259 - accuracy: 0.8293 - val_loss: 0.6861 - val_accuracy: 0.8053\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.81039\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.00464816.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.7112 - accuracy: 0.8338 - val_loss: 0.7471 - val_accuracy: 0.8052\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.81039\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.0046.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.7053 - accuracy: 0.8314 - val_loss: 0.7345 - val_accuracy: 0.8139\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.66146\n",
      "\n",
      "Epoch 00101: val_accuracy improved from 0.81039 to 0.81392, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.0045521599999999995.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.7090 - accuracy: 0.8310 - val_loss: 0.6553 - val_accuracy: 0.8114\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.66146 to 0.65526, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.81392\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.004504640000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 370ms/step - loss: 0.6963 - accuracy: 0.8342 - val_loss: 0.7162 - val_accuracy: 0.8055\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.65526\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.81392\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.004457440000000002.\n",
      "64/64 [==============================] - 24s 369ms/step - loss: 0.6967 - accuracy: 0.8363 - val_loss: 0.6941 - val_accuracy: 0.8123\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.65526\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.81392\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.004410560000000001.\n",
      "64/64 [==============================] - 24s 367ms/step - loss: 0.6948 - accuracy: 0.8362 - val_loss: 0.6487 - val_accuracy: 0.8130\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.65526 to 0.64873, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.81392\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.0043640000000000016.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.6756 - accuracy: 0.8425 - val_loss: 0.6743 - val_accuracy: 0.8114\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.64873\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.81392\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.00431776.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.6783 - accuracy: 0.8400 - val_loss: 0.6756 - val_accuracy: 0.8057\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.64873\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.81392\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.004271840000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.6664 - accuracy: 0.8417 - val_loss: 0.8242 - val_accuracy: 0.8053\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.64873\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.81392\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.004226240000000001.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.6606 - accuracy: 0.8430 - val_loss: 0.6792 - val_accuracy: 0.8129\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.64873\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.81392\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.004180960000000001.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.6591 - accuracy: 0.8460 - val_loss: 0.7283 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.64873\n",
      "\n",
      "Epoch 00110: val_accuracy improved from 0.81392 to 0.81872, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.004136000000000001.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.6577 - accuracy: 0.8446 - val_loss: 0.7143 - val_accuracy: 0.8141\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.64873\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.81872\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.0040913600000000005.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.6469 - accuracy: 0.8474 - val_loss: 0.6981 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.64873\n",
      "\n",
      "Epoch 00112: val_accuracy improved from 0.81872 to 0.81930, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.00404704.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.6439 - accuracy: 0.8487 - val_loss: 0.6227 - val_accuracy: 0.8201\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.64873 to 0.62269, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00113: val_accuracy improved from 0.81930 to 0.82009, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.004003040000000001.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.6467 - accuracy: 0.8473 - val_loss: 0.6954 - val_accuracy: 0.8177\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.62269\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.82009\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.00395936.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.6370 - accuracy: 0.8482 - val_loss: 0.7445 - val_accuracy: 0.8099\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.62269\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.82009\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.003916.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.6214 - accuracy: 0.8529 - val_loss: 0.7288 - val_accuracy: 0.8123\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.62269\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.82009\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.0038729600000000004.\n",
      "64/64 [==============================] - 24s 369ms/step - loss: 0.6291 - accuracy: 0.8513 - val_loss: 0.6992 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.62269\n",
      "\n",
      "Epoch 00117: val_accuracy improved from 0.82009 to 0.82110, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.003830240000000001.\n",
      "64/64 [==============================] - 27s 414ms/step - loss: 0.6193 - accuracy: 0.8572 - val_loss: 0.6003 - val_accuracy: 0.8286\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.62269 to 0.60033, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00118: val_accuracy improved from 0.82110 to 0.82864, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.0037878400000000002.\n",
      "64/64 [==============================] - 30s 474ms/step - loss: 0.6154 - accuracy: 0.8571 - val_loss: 0.6679 - val_accuracy: 0.8198\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.82864\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.0037457600000000003.\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6152 - accuracy: 0.8529 - val_loss: 0.6487 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.82864\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.0037040000000000003.\n",
      "64/64 [==============================] - 33s 510ms/step - loss: 0.6054 - accuracy: 0.8581 - val_loss: 0.6175 - val_accuracy: 0.8210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00121: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.82864\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.00366256.\n",
      "64/64 [==============================] - 30s 476ms/step - loss: 0.6004 - accuracy: 0.8598 - val_loss: 0.6829 - val_accuracy: 0.8225\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.82864\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.00362144.\n",
      "64/64 [==============================] - 27s 426ms/step - loss: 0.5986 - accuracy: 0.8578 - val_loss: 0.7048 - val_accuracy: 0.8164\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.82864\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.0035806400000000004.\n",
      "64/64 [==============================] - 27s 427ms/step - loss: 0.5974 - accuracy: 0.8614 - val_loss: 0.6289 - val_accuracy: 0.8262\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.82864\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.00354016.\n",
      "64/64 [==============================] - 27s 419ms/step - loss: 0.5910 - accuracy: 0.8623 - val_loss: 0.7088 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.82864\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.0035.\n",
      "64/64 [==============================] - 27s 427ms/step - loss: 0.5780 - accuracy: 0.8652 - val_loss: 0.6136 - val_accuracy: 0.8284\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.82864\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.00346016.\n",
      "64/64 [==============================] - 27s 427ms/step - loss: 0.5869 - accuracy: 0.8596 - val_loss: 0.7551 - val_accuracy: 0.8242\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.60033\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.82864\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.00342064.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.5806 - accuracy: 0.8645 - val_loss: 0.5350 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.60033 to 0.53504, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.82864\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.00338144.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.5778 - accuracy: 0.8651 - val_loss: 0.6755 - val_accuracy: 0.8219\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.82864\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.00334256.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.5655 - accuracy: 0.8705 - val_loss: 0.6192 - val_accuracy: 0.8264\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.82864\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.003304.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.5703 - accuracy: 0.8666 - val_loss: 0.6408 - val_accuracy: 0.8251\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.82864\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.00326576.\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.5627 - accuracy: 0.8662 - val_loss: 0.6779 - val_accuracy: 0.8302\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00132: val_accuracy improved from 0.82864 to 0.83017, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.00322784.\n",
      "64/64 [==============================] - 23s 361ms/step - loss: 0.5653 - accuracy: 0.8683 - val_loss: 0.6742 - val_accuracy: 0.8306\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00133: val_accuracy improved from 0.83017 to 0.83064, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.0031902399999999996.\n",
      "64/64 [==============================] - 23s 364ms/step - loss: 0.5545 - accuracy: 0.8704 - val_loss: 0.7174 - val_accuracy: 0.8305\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.83064\n",
      "Epoch 135/2000\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.00315296.\n",
      "64/64 [==============================] - 23s 364ms/step - loss: 0.5491 - accuracy: 0.8739 - val_loss: 0.5652 - val_accuracy: 0.8258\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.83064\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.0031159999999999994.\n",
      "64/64 [==============================] - 23s 362ms/step - loss: 0.5505 - accuracy: 0.8729 - val_loss: 0.6059 - val_accuracy: 0.8315\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00136: val_accuracy improved from 0.83064 to 0.83149, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.0030793599999999997.\n",
      "64/64 [==============================] - 23s 363ms/step - loss: 0.5438 - accuracy: 0.8758 - val_loss: 0.7720 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.83149\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.0030430399999999995.\n",
      "64/64 [==============================] - 23s 362ms/step - loss: 0.5381 - accuracy: 0.8772 - val_loss: 0.5723 - val_accuracy: 0.8253\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.83149\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.00300704.\n",
      "64/64 [==============================] - 23s 362ms/step - loss: 0.5313 - accuracy: 0.8773 - val_loss: 0.6206 - val_accuracy: 0.8284\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.83149\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.0029713599999999997.\n",
      "64/64 [==============================] - 23s 362ms/step - loss: 0.5383 - accuracy: 0.8741 - val_loss: 0.6378 - val_accuracy: 0.8278\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.83149\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.002936.\n",
      "64/64 [==============================] - 23s 361ms/step - loss: 0.5297 - accuracy: 0.8765 - val_loss: 0.5781 - val_accuracy: 0.8301\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.83149\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.00290096.\n",
      "64/64 [==============================] - 30s 476ms/step - loss: 0.5303 - accuracy: 0.8796 - val_loss: 0.5871 - val_accuracy: 0.8255\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.83149\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.0028662400000000004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 26s 402ms/step - loss: 0.5231 - accuracy: 0.8791 - val_loss: 0.7196 - val_accuracy: 0.8262\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.83149\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.0028318400000000004.\n",
      "64/64 [==============================] - 23s 361ms/step - loss: 0.5198 - accuracy: 0.8831 - val_loss: 0.6889 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00144: val_accuracy improved from 0.83149 to 0.83201, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.0027977600000000007.\n",
      "64/64 [==============================] - 23s 360ms/step - loss: 0.5185 - accuracy: 0.8815 - val_loss: 0.6094 - val_accuracy: 0.8283\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.83201\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.0027640000000000004.\n",
      "64/64 [==============================] - 23s 364ms/step - loss: 0.5157 - accuracy: 0.8808 - val_loss: 0.7028 - val_accuracy: 0.8288\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.83201\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.002730560000000001.\n",
      "64/64 [==============================] - 23s 361ms/step - loss: 0.5179 - accuracy: 0.8816 - val_loss: 0.5756 - val_accuracy: 0.8338\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.53504\n",
      "\n",
      "Epoch 00147: val_accuracy improved from 0.83201 to 0.83381, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.0026974400000000006.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.5075 - accuracy: 0.8842 - val_loss: 0.5296 - val_accuracy: 0.8307\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.53504 to 0.52961, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.83381\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.0026646400000000002.\n",
      "64/64 [==============================] - 27s 423ms/step - loss: 0.5124 - accuracy: 0.8828 - val_loss: 0.6648 - val_accuracy: 0.8353\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00149: val_accuracy improved from 0.83381 to 0.83534, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.0026321600000000006.\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 0.5061 - accuracy: 0.8866 - val_loss: 0.5841 - val_accuracy: 0.8367\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00150: val_accuracy improved from 0.83534 to 0.83666, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.0026000000000000003.\n",
      "64/64 [==============================] - 23s 364ms/step - loss: 0.5018 - accuracy: 0.8862 - val_loss: 0.7425 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.83666\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.00256816.\n",
      "64/64 [==============================] - 23s 365ms/step - loss: 0.5014 - accuracy: 0.8858 - val_loss: 0.7571 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.83666\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.0025366400000000006.\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.4968 - accuracy: 0.8862 - val_loss: 0.6621 - val_accuracy: 0.8307\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.83666\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.0025054400000000003.\n",
      "64/64 [==============================] - 23s 365ms/step - loss: 0.4928 - accuracy: 0.8875 - val_loss: 0.5635 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.83666\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.0024745599999999998.\n",
      "64/64 [==============================] - 23s 365ms/step - loss: 0.4937 - accuracy: 0.8885 - val_loss: 0.5656 - val_accuracy: 0.8314\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.83666\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.002444.\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.4925 - accuracy: 0.8906 - val_loss: 0.5340 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.52961\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.83666\n",
      "Epoch 157/2000\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.00241376.\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.4847 - accuracy: 0.8891 - val_loss: 0.4806 - val_accuracy: 0.8341\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.52961 to 0.48058, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.83666\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.00238384.\n",
      "64/64 [==============================] - 23s 367ms/step - loss: 0.4870 - accuracy: 0.8913 - val_loss: 0.6436 - val_accuracy: 0.8361\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.83666\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.0023542399999999996.\n",
      "64/64 [==============================] - 23s 364ms/step - loss: 0.4816 - accuracy: 0.8937 - val_loss: 0.5674 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.83666\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.00232496.\n",
      "64/64 [==============================] - 23s 362ms/step - loss: 0.4808 - accuracy: 0.8923 - val_loss: 0.6974 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.83666\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.0022960000000000003.\n",
      "64/64 [==============================] - 23s 365ms/step - loss: 0.4766 - accuracy: 0.8929 - val_loss: 0.6168 - val_accuracy: 0.8370\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00161: val_accuracy improved from 0.83666 to 0.83703, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.00226736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 29s 450ms/step - loss: 0.4750 - accuracy: 0.8949 - val_loss: 0.5901 - val_accuracy: 0.8386\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00162: val_accuracy improved from 0.83703 to 0.83861, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.00223904.\n",
      "64/64 [==============================] - 46s 723ms/step - loss: 0.4683 - accuracy: 0.8957 - val_loss: 0.6714 - val_accuracy: 0.8350\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.83861\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.00221104.\n",
      "64/64 [==============================] - 38s 586ms/step - loss: 0.4705 - accuracy: 0.8942 - val_loss: 0.5857 - val_accuracy: 0.8351\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.83861\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.0021833599999999996.\n",
      "20/64 [========>.....................] - ETA: 2:08 - loss: 0.4613 - accuracy: 0.8986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/keras/utils/data_utils.py:718: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 165s 3s/step - loss: 0.4699 - accuracy: 0.8941 - val_loss: 0.6054 - val_accuracy: 0.8387\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00165: val_accuracy improved from 0.83861 to 0.83871, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.002156.\n",
      "64/64 [==============================] - 24s 383ms/step - loss: 0.4685 - accuracy: 0.8952 - val_loss: 0.5894 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00166: val_accuracy improved from 0.83871 to 0.83966, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.00212896.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.4645 - accuracy: 0.8941 - val_loss: 0.5800 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.83966\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.00210224.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.4555 - accuracy: 0.8969 - val_loss: 0.7237 - val_accuracy: 0.8312\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.83966\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.00207584.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.4599 - accuracy: 0.8986 - val_loss: 0.5738 - val_accuracy: 0.8336\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.83966\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.00204976.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.4564 - accuracy: 0.8993 - val_loss: 0.6323 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.83966\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.0020239999999999998.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.4549 - accuracy: 0.8981 - val_loss: 0.6379 - val_accuracy: 0.8367\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.83966\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.00199856.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.4506 - accuracy: 0.8985 - val_loss: 0.5779 - val_accuracy: 0.8391\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.83966\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.0019734400000000004.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.4490 - accuracy: 0.9008 - val_loss: 0.5486 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.83966\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.0019486400000000004.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.4469 - accuracy: 0.9001 - val_loss: 0.6073 - val_accuracy: 0.8390\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.83966\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.0019241600000000003.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.4487 - accuracy: 0.9023 - val_loss: 0.5892 - val_accuracy: 0.8395\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.83966\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.0019000000000000002.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.4419 - accuracy: 0.9010 - val_loss: 0.5957 - val_accuracy: 0.8377\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.83966\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.0018761600000000004.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.4436 - accuracy: 0.9018 - val_loss: 0.5647 - val_accuracy: 0.8387\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.83966\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.0018526400000000002.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.4455 - accuracy: 0.9010 - val_loss: 0.6604 - val_accuracy: 0.8353\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.83966\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.0018294400000000003.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.4369 - accuracy: 0.9047 - val_loss: 0.5476 - val_accuracy: 0.8345\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.83966\n",
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.0018065600000000002.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.4314 - accuracy: 0.9043 - val_loss: 0.5743 - val_accuracy: 0.8380\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.83966\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.001784.\n",
      "64/64 [==============================] - 25s 392ms/step - loss: 0.4356 - accuracy: 0.9031 - val_loss: 0.6317 - val_accuracy: 0.8398\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00181: val_accuracy improved from 0.83966 to 0.83982, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.0017617600000000002.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.4364 - accuracy: 0.9035 - val_loss: 0.5940 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.83982\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.00173984.\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.4312 - accuracy: 0.9062 - val_loss: 0.6573 - val_accuracy: 0.8352\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.83982\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.0017182400000000002.\n",
      "64/64 [==============================] - 26s 404ms/step - loss: 0.4367 - accuracy: 0.9027 - val_loss: 0.5346 - val_accuracy: 0.8363\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.83982\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.00169696.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.4288 - accuracy: 0.9052 - val_loss: 0.5167 - val_accuracy: 0.8419\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00185: val_accuracy improved from 0.83982 to 0.84193, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.001676.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.4264 - accuracy: 0.9056 - val_loss: 0.5708 - val_accuracy: 0.8379\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.84193\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.00165536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 378ms/step - loss: 0.4271 - accuracy: 0.9068 - val_loss: 0.5647 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.84193\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.00163504.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.4262 - accuracy: 0.9095 - val_loss: 0.6912 - val_accuracy: 0.8377\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.84193\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.0016150399999999999.\n",
      "64/64 [==============================] - 26s 401ms/step - loss: 0.4221 - accuracy: 0.9088 - val_loss: 0.6574 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.84193\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.00159536.\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.4142 - accuracy: 0.9084 - val_loss: 0.5866 - val_accuracy: 0.8367\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.84193\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.0015760000000000001.\n",
      "64/64 [==============================] - 25s 389ms/step - loss: 0.4202 - accuracy: 0.9081 - val_loss: 0.5647 - val_accuracy: 0.8405\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.84193\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.00155696.\n",
      "64/64 [==============================] - 25s 385ms/step - loss: 0.4174 - accuracy: 0.9112 - val_loss: 0.6604 - val_accuracy: 0.8329\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.84193\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.00153824.\n",
      "64/64 [==============================] - 25s 383ms/step - loss: 0.4097 - accuracy: 0.9113 - val_loss: 0.6286 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.84193\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.00151984.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.4204 - accuracy: 0.9076 - val_loss: 0.6786 - val_accuracy: 0.8361\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.84193\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.00150176.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.4105 - accuracy: 0.9106 - val_loss: 0.4848 - val_accuracy: 0.8418\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.84193\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.001484.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.4130 - accuracy: 0.9111 - val_loss: 0.7884 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.84193\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.00146656.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.4093 - accuracy: 0.9109 - val_loss: 0.6150 - val_accuracy: 0.8415\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.84193\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.0014494399999999998.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.4105 - accuracy: 0.9111 - val_loss: 0.5705 - val_accuracy: 0.8418\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.84193\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.0014326399999999998.\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.4070 - accuracy: 0.9122 - val_loss: 0.5675 - val_accuracy: 0.8390\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.84193\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.0014161599999999999.\n",
      "64/64 [==============================] - 26s 402ms/step - loss: 0.4059 - accuracy: 0.9115 - val_loss: 0.5259 - val_accuracy: 0.8441\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00200: val_accuracy improved from 0.84193 to 0.84415, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.0013999999999999998.\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.4070 - accuracy: 0.9100 - val_loss: 0.6313 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.84415\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.0013841599999999997.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.4016 - accuracy: 0.9134 - val_loss: 0.5092 - val_accuracy: 0.8419\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.84415\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.00136864.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.4030 - accuracy: 0.9100 - val_loss: 0.6132 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00203: val_accuracy improved from 0.84415 to 0.84536, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.0013534399999999998.\n",
      "64/64 [==============================] - 25s 389ms/step - loss: 0.4031 - accuracy: 0.9121 - val_loss: 0.5172 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.84536\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.0013385600000000001.\n",
      "64/64 [==============================] - 26s 400ms/step - loss: 0.4006 - accuracy: 0.9124 - val_loss: 0.5723 - val_accuracy: 0.8436\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.84536\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.001324.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.3983 - accuracy: 0.9151 - val_loss: 0.6303 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.84536\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.00130976.\n",
      "64/64 [==============================] - 26s 399ms/step - loss: 0.3982 - accuracy: 0.9150 - val_loss: 0.7186 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.84536\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.0012958400000000001.\n",
      "64/64 [==============================] - 26s 402ms/step - loss: 0.3997 - accuracy: 0.9136 - val_loss: 0.6280 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00208: val_accuracy improved from 0.84536 to 0.84720, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.00128224.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.3927 - accuracy: 0.9150 - val_loss: 0.5558 - val_accuracy: 0.8440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00209: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.84720\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.0012689600000000002.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3944 - accuracy: 0.9160 - val_loss: 0.5607 - val_accuracy: 0.8428\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.84720\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.0012560000000000002.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3959 - accuracy: 0.9142 - val_loss: 0.6113 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.84720\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.0012433600000000002.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3949 - accuracy: 0.9162 - val_loss: 0.6800 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.84720\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.00123104.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3929 - accuracy: 0.9155 - val_loss: 0.5930 - val_accuracy: 0.8451\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.84720\n",
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.00121904.\n",
      "64/64 [==============================] - 24s 383ms/step - loss: 0.3865 - accuracy: 0.9184 - val_loss: 0.5398 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.84720\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.00120736.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3906 - accuracy: 0.9163 - val_loss: 0.6233 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.84720\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.001196.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3868 - accuracy: 0.9184 - val_loss: 0.7255 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.84720\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.00118496.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3860 - accuracy: 0.9183 - val_loss: 0.5140 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.84720\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.00117424.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.3860 - accuracy: 0.9173 - val_loss: 0.5418 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.84720\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.00116384.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3860 - accuracy: 0.9179 - val_loss: 0.5626 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.84720\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.00115376.\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.3853 - accuracy: 0.9160 - val_loss: 0.5757 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.84720\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.001144.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3829 - accuracy: 0.9202 - val_loss: 0.5287 - val_accuracy: 0.8416\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.84720\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.00113456.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3837 - accuracy: 0.9172 - val_loss: 0.7370 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.84720\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.0011254400000000001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3836 - accuracy: 0.9196 - val_loss: 0.6035 - val_accuracy: 0.8428\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.84720\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.00111664.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3769 - accuracy: 0.9218 - val_loss: 0.6430 - val_accuracy: 0.8428\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.84720\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.00110816.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.3801 - accuracy: 0.9186 - val_loss: 0.5930 - val_accuracy: 0.8442\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.84720\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.0011.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.3772 - accuracy: 0.9208 - val_loss: 0.7045 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.84720\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.00109216.\n",
      "64/64 [==============================] - 25s 394ms/step - loss: 0.3824 - accuracy: 0.9191 - val_loss: 0.5542 - val_accuracy: 0.8408\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.84720\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.00108464.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.3790 - accuracy: 0.9191 - val_loss: 0.5953 - val_accuracy: 0.8414\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.84720\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.00107744.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.3746 - accuracy: 0.9203 - val_loss: 0.5394 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.84720\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.00107056.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3766 - accuracy: 0.9187 - val_loss: 0.5619 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.84720\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.0010639999999999998.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3742 - accuracy: 0.9217 - val_loss: 0.5679 - val_accuracy: 0.8414\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.84720\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.00105776.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3730 - accuracy: 0.9212 - val_loss: 0.6237 - val_accuracy: 0.8399\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.84720\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.00105184.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.3758 - accuracy: 0.9209 - val_loss: 0.4972 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.84720\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.00104624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3759 - accuracy: 0.9227 - val_loss: 0.6042 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.84720\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.0010409599999999998.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3735 - accuracy: 0.9221 - val_loss: 0.6659 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.84720\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.001036.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3729 - accuracy: 0.9223 - val_loss: 0.6308 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.84720\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.00103136.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3755 - accuracy: 0.9214 - val_loss: 0.5438 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.84720\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.0010270400000000001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3729 - accuracy: 0.9232 - val_loss: 0.5798 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.84720\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.00102304.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3710 - accuracy: 0.9227 - val_loss: 0.5654 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00239: val_accuracy improved from 0.84720 to 0.84789, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.00101936.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3676 - accuracy: 0.9226 - val_loss: 0.6551 - val_accuracy: 0.8477\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.84789\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.001016.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3681 - accuracy: 0.9238 - val_loss: 0.5792 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.84789\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.00101296.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3672 - accuracy: 0.9258 - val_loss: 0.5961 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.84789\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.0010102400000000001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3684 - accuracy: 0.9233 - val_loss: 0.5210 - val_accuracy: 0.8463\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.84789\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.00100784.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3628 - accuracy: 0.9234 - val_loss: 0.5207 - val_accuracy: 0.8402\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.84789\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.00100576.\n",
      "64/64 [==============================] - 24s 383ms/step - loss: 0.3652 - accuracy: 0.9225 - val_loss: 0.5740 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.84789\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.0010040000000000001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3634 - accuracy: 0.9254 - val_loss: 0.7703 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.84789\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.00100256.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3637 - accuracy: 0.9251 - val_loss: 0.5415 - val_accuracy: 0.8455\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.84789\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.00100144.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.3639 - accuracy: 0.9228 - val_loss: 0.6196 - val_accuracy: 0.8473\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.84789\n",
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.0010006400000000001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3644 - accuracy: 0.9217 - val_loss: 0.6036 - val_accuracy: 0.8475\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.84789\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.00100016.\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.3658 - accuracy: 0.9219 - val_loss: 0.5331 - val_accuracy: 0.8461\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.84789\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3590 - accuracy: 0.9243 - val_loss: 0.5443 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00251: val_accuracy improved from 0.84789 to 0.84926, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3641 - accuracy: 0.9215 - val_loss: 0.5174 - val_accuracy: 0.8427\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.84926\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3585 - accuracy: 0.9265 - val_loss: 0.6913 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.84926\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3650 - accuracy: 0.9218 - val_loss: 0.5972 - val_accuracy: 0.8450\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.84926\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.3525 - accuracy: 0.9264 - val_loss: 0.6370 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.84926\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3624 - accuracy: 0.9236 - val_loss: 0.5481 - val_accuracy: 0.8450\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.84926\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 26s 403ms/step - loss: 0.3571 - accuracy: 0.9237 - val_loss: 0.5466 - val_accuracy: 0.8471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00257: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.84926\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 383ms/step - loss: 0.3514 - accuracy: 0.9263 - val_loss: 0.5644 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.84926\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3574 - accuracy: 0.9257 - val_loss: 0.5831 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.84926\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3585 - accuracy: 0.9253 - val_loss: 0.6198 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.84926\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.3549 - accuracy: 0.9242 - val_loss: 0.6105 - val_accuracy: 0.8463\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.84926\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3575 - accuracy: 0.9254 - val_loss: 0.6764 - val_accuracy: 0.8452\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.84926\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3561 - accuracy: 0.9265 - val_loss: 0.5350 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.84926\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3558 - accuracy: 0.9265 - val_loss: 0.5011 - val_accuracy: 0.8471\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.84926\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3555 - accuracy: 0.9262 - val_loss: 0.6369 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00265: val_accuracy improved from 0.84926 to 0.85042, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3542 - accuracy: 0.9257 - val_loss: 0.5774 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.85042\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 394ms/step - loss: 0.3561 - accuracy: 0.9270 - val_loss: 0.6404 - val_accuracy: 0.8398\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.85042\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3531 - accuracy: 0.9253 - val_loss: 0.6024 - val_accuracy: 0.8412\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.85042\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3548 - accuracy: 0.9275 - val_loss: 0.5246 - val_accuracy: 0.8422\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.85042\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 394ms/step - loss: 0.3541 - accuracy: 0.9262 - val_loss: 0.5745 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.85042\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.3523 - accuracy: 0.9265 - val_loss: 0.6192 - val_accuracy: 0.8495\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.85042\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3535 - accuracy: 0.9257 - val_loss: 0.5828 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.85042\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3526 - accuracy: 0.9263 - val_loss: 0.5466 - val_accuracy: 0.8491\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.85042\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3539 - accuracy: 0.9236 - val_loss: 0.6924 - val_accuracy: 0.8475\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.85042\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3527 - accuracy: 0.9280 - val_loss: 0.5536 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.85042\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3489 - accuracy: 0.9254 - val_loss: 0.6679 - val_accuracy: 0.8473\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.85042\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3463 - accuracy: 0.9287 - val_loss: 0.6284 - val_accuracy: 0.8459\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.85042\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3463 - accuracy: 0.9297 - val_loss: 0.5759 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.85042\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 26s 399ms/step - loss: 0.3480 - accuracy: 0.9271 - val_loss: 0.5975 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.85042\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 388ms/step - loss: 0.3500 - accuracy: 0.9288 - val_loss: 0.6084 - val_accuracy: 0.8503\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.85042\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.3449 - accuracy: 0.9293 - val_loss: 0.7083 - val_accuracy: 0.8473\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.85042\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 25s 385ms/step - loss: 0.3525 - accuracy: 0.9258 - val_loss: 0.6300 - val_accuracy: 0.8436\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.85042\n",
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3496 - accuracy: 0.9274 - val_loss: 0.6252 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.85042\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3437 - accuracy: 0.9299 - val_loss: 0.5730 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.85042\n",
      "Epoch 285/2000\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3457 - accuracy: 0.9287 - val_loss: 0.5348 - val_accuracy: 0.8437\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.85042\n",
      "Epoch 286/2000\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3467 - accuracy: 0.9297 - val_loss: 0.6633 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.85042\n",
      "Epoch 287/2000\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3475 - accuracy: 0.9290 - val_loss: 0.5238 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.85042\n",
      "Epoch 288/2000\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 389ms/step - loss: 0.3484 - accuracy: 0.9286 - val_loss: 0.5401 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.85042\n",
      "Epoch 289/2000\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3436 - accuracy: 0.9282 - val_loss: 0.5580 - val_accuracy: 0.8465\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.85042\n",
      "Epoch 290/2000\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3445 - accuracy: 0.9282 - val_loss: 0.5914 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.85042\n",
      "Epoch 291/2000\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3473 - accuracy: 0.9294 - val_loss: 0.7732 - val_accuracy: 0.8453\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.85042\n",
      "Epoch 292/2000\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3491 - accuracy: 0.9268 - val_loss: 0.5384 - val_accuracy: 0.8449\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.85042\n",
      "Epoch 293/2000\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3476 - accuracy: 0.9271 - val_loss: 0.6649 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.85042\n",
      "Epoch 294/2000\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3419 - accuracy: 0.9273 - val_loss: 0.6030 - val_accuracy: 0.8471\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.85042\n",
      "Epoch 295/2000\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3409 - accuracy: 0.9278 - val_loss: 0.6330 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.85042\n",
      "Epoch 296/2000\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3503 - accuracy: 0.9260 - val_loss: 0.5646 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00296: val_accuracy improved from 0.85042 to 0.85069, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 297/2000\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3441 - accuracy: 0.9280 - val_loss: 0.5371 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.85069\n",
      "Epoch 298/2000\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3391 - accuracy: 0.9283 - val_loss: 0.5671 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.85069\n",
      "Epoch 299/2000\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3417 - accuracy: 0.9297 - val_loss: 0.5383 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.85069\n",
      "Epoch 300/2000\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3410 - accuracy: 0.9290 - val_loss: 0.6013 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.85069\n",
      "Epoch 301/2000\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3438 - accuracy: 0.9269 - val_loss: 0.5788 - val_accuracy: 0.8539\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00301: val_accuracy improved from 0.85069 to 0.85390, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-max_val_acc.hdf5\n",
      "Epoch 302/2000\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3427 - accuracy: 0.9296 - val_loss: 0.6069 - val_accuracy: 0.8461\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.85390\n",
      "Epoch 303/2000\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.3400 - accuracy: 0.9306 - val_loss: 0.6079 - val_accuracy: 0.8467\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.85390\n",
      "Epoch 304/2000\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.3383 - accuracy: 0.9310 - val_loss: 0.7339 - val_accuracy: 0.8480\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.85390\n",
      "Epoch 305/2000\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3417 - accuracy: 0.9285 - val_loss: 0.5301 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.85390\n",
      "Epoch 306/2000\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3379 - accuracy: 0.9292 - val_loss: 0.5327 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.85390\n",
      "Epoch 307/2000\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3411 - accuracy: 0.9277 - val_loss: 0.6242 - val_accuracy: 0.8512\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.85390\n",
      "Epoch 308/2000\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3384 - accuracy: 0.9297 - val_loss: 0.6760 - val_accuracy: 0.8459\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.85390\n",
      "Epoch 309/2000\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3348 - accuracy: 0.9279 - val_loss: 0.6135 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.85390\n",
      "Epoch 310/2000\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3393 - accuracy: 0.9303 - val_loss: 0.5883 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.85390\n",
      "Epoch 311/2000\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3391 - accuracy: 0.9275 - val_loss: 0.5423 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.85390\n",
      "Epoch 312/2000\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.3365 - accuracy: 0.9309 - val_loss: 0.6392 - val_accuracy: 0.8505\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.85390\n",
      "Epoch 313/2000\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 385ms/step - loss: 0.3352 - accuracy: 0.9304 - val_loss: 0.6571 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.85390\n",
      "Epoch 314/2000\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.3372 - accuracy: 0.9305 - val_loss: 0.6956 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.85390\n",
      "Epoch 315/2000\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.3395 - accuracy: 0.9287 - val_loss: 0.6343 - val_accuracy: 0.8495\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.85390\n",
      "Epoch 316/2000\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3335 - accuracy: 0.9317 - val_loss: 0.6199 - val_accuracy: 0.8475\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.85390\n",
      "Epoch 317/2000\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3345 - accuracy: 0.9321 - val_loss: 0.5676 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.85390\n",
      "Epoch 318/2000\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3393 - accuracy: 0.9306 - val_loss: 0.5865 - val_accuracy: 0.8492\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.85390\n",
      "Epoch 319/2000\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.3329 - accuracy: 0.9309 - val_loss: 0.5975 - val_accuracy: 0.8485\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.85390\n",
      "Epoch 320/2000\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.3316 - accuracy: 0.9334 - val_loss: 0.5765 - val_accuracy: 0.8509\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.48058\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.85390\n",
      "Epoch 321/2000\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3279 - accuracy: 0.9326 - val_loss: 0.4545 - val_accuracy: 0.8512\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.48058 to 0.45445, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.85390\n",
      "Epoch 322/2000\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3365 - accuracy: 0.9305 - val_loss: 0.4766 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.85390\n",
      "Epoch 323/2000\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3331 - accuracy: 0.9310 - val_loss: 0.5242 - val_accuracy: 0.8449\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.85390\n",
      "Epoch 324/2000\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.3341 - accuracy: 0.9321 - val_loss: 0.5561 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.85390\n",
      "Epoch 325/2000\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 387ms/step - loss: 0.3305 - accuracy: 0.9327 - val_loss: 0.5282 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.85390\n",
      "Epoch 326/2000\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.3334 - accuracy: 0.9314 - val_loss: 0.4850 - val_accuracy: 0.8437\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.85390\n",
      "Epoch 327/2000\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 26s 400ms/step - loss: 0.3354 - accuracy: 0.9296 - val_loss: 0.7013 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.85390\n",
      "Epoch 328/2000\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 382ms/step - loss: 0.3304 - accuracy: 0.9311 - val_loss: 0.6414 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.85390\n",
      "Epoch 329/2000\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3292 - accuracy: 0.9327 - val_loss: 0.4708 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.85390\n",
      "Epoch 330/2000\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3301 - accuracy: 0.9313 - val_loss: 0.5747 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.85390\n",
      "Epoch 331/2000\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3274 - accuracy: 0.9314 - val_loss: 0.6723 - val_accuracy: 0.8496\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.85390\n",
      "Epoch 332/2000\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3263 - accuracy: 0.9333 - val_loss: 0.5949 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.85390\n",
      "Epoch 333/2000\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 386ms/step - loss: 0.3316 - accuracy: 0.9319 - val_loss: 0.6572 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.85390\n",
      "Epoch 334/2000\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3276 - accuracy: 0.9313 - val_loss: 0.5747 - val_accuracy: 0.8505\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.85390\n",
      "Epoch 335/2000\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 391ms/step - loss: 0.3306 - accuracy: 0.9325 - val_loss: 0.4866 - val_accuracy: 0.8480\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.85390\n",
      "Epoch 336/2000\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 398ms/step - loss: 0.3290 - accuracy: 0.9321 - val_loss: 0.5991 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.85390\n",
      "Epoch 337/2000\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 392ms/step - loss: 0.3307 - accuracy: 0.9313 - val_loss: 0.6258 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.85390\n",
      "Epoch 338/2000\n",
      "\n",
      "Epoch 00338: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 383ms/step - loss: 0.3293 - accuracy: 0.9320 - val_loss: 0.4642 - val_accuracy: 0.8461\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.85390\n",
      "Epoch 339/2000\n",
      "\n",
      "Epoch 00339: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3283 - accuracy: 0.9325 - val_loss: 0.5726 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.85390\n",
      "Epoch 340/2000\n",
      "\n",
      "Epoch 00340: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3291 - accuracy: 0.9320 - val_loss: 0.6722 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.85390\n",
      "Epoch 341/2000\n",
      "\n",
      "Epoch 00341: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3309 - accuracy: 0.9333 - val_loss: 0.6778 - val_accuracy: 0.8452\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.85390\n",
      "Epoch 342/2000\n",
      "\n",
      "Epoch 00342: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3312 - accuracy: 0.9318 - val_loss: 0.6038 - val_accuracy: 0.8506\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.85390\n",
      "Epoch 343/2000\n",
      "\n",
      "Epoch 00343: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 395ms/step - loss: 0.3220 - accuracy: 0.9337 - val_loss: 0.6532 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.85390\n",
      "Epoch 344/2000\n",
      "\n",
      "Epoch 00344: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.3243 - accuracy: 0.9318 - val_loss: 0.5949 - val_accuracy: 0.8476\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.85390\n",
      "Epoch 345/2000\n",
      "\n",
      "Epoch 00345: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 26s 407ms/step - loss: 0.3222 - accuracy: 0.9331 - val_loss: 0.6707 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.85390\n",
      "Epoch 346/2000\n",
      "\n",
      "Epoch 00346: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 385ms/step - loss: 0.3249 - accuracy: 0.9336 - val_loss: 0.4859 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.85390\n",
      "Epoch 347/2000\n",
      "\n",
      "Epoch 00347: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3235 - accuracy: 0.9332 - val_loss: 0.5506 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.85390\n",
      "Epoch 348/2000\n",
      "\n",
      "Epoch 00348: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 396ms/step - loss: 0.3267 - accuracy: 0.9327 - val_loss: 0.6485 - val_accuracy: 0.8481\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.85390\n",
      "Epoch 349/2000\n",
      "\n",
      "Epoch 00349: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3234 - accuracy: 0.9325 - val_loss: 0.5419 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.85390\n",
      "Epoch 350/2000\n",
      "\n",
      "Epoch 00350: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3244 - accuracy: 0.9343 - val_loss: 0.6644 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.85390\n",
      "Epoch 351/2000\n",
      "\n",
      "Epoch 00351: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3226 - accuracy: 0.9343 - val_loss: 0.5393 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.85390\n",
      "Epoch 352/2000\n",
      "\n",
      "Epoch 00352: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 389ms/step - loss: 0.3226 - accuracy: 0.9356 - val_loss: 0.5700 - val_accuracy: 0.8442\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.85390\n",
      "Epoch 353/2000\n",
      "\n",
      "Epoch 00353: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 26s 404ms/step - loss: 0.3272 - accuracy: 0.9324 - val_loss: 0.5935 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.45445\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.85390\n",
      "Epoch 354/2000\n",
      "\n",
      "Epoch 00354: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 389ms/step - loss: 0.3250 - accuracy: 0.9318 - val_loss: 0.4289 - val_accuracy: 0.8506\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.45445 to 0.42892, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.85390\n",
      "Epoch 355/2000\n",
      "\n",
      "Epoch 00355: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3220 - accuracy: 0.9342 - val_loss: 0.6418 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.85390\n",
      "Epoch 356/2000\n",
      "\n",
      "Epoch 00356: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 374ms/step - loss: 0.3245 - accuracy: 0.9351 - val_loss: 0.7318 - val_accuracy: 0.8532\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.85390\n",
      "Epoch 357/2000\n",
      "\n",
      "Epoch 00357: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 387ms/step - loss: 0.3247 - accuracy: 0.9346 - val_loss: 0.5447 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.85390\n",
      "Epoch 358/2000\n",
      "\n",
      "Epoch 00358: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 389ms/step - loss: 0.3224 - accuracy: 0.9348 - val_loss: 0.5573 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.85390\n",
      "Epoch 359/2000\n",
      "\n",
      "Epoch 00359: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3206 - accuracy: 0.9341 - val_loss: 0.6208 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.85390\n",
      "Epoch 360/2000\n",
      "\n",
      "Epoch 00360: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3250 - accuracy: 0.9327 - val_loss: 0.5085 - val_accuracy: 0.8485\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.85390\n",
      "Epoch 361/2000\n",
      "\n",
      "Epoch 00361: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.3248 - accuracy: 0.9346 - val_loss: 0.6329 - val_accuracy: 0.8448\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.85390\n",
      "Epoch 362/2000\n",
      "\n",
      "Epoch 00362: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 391ms/step - loss: 0.3211 - accuracy: 0.9333 - val_loss: 0.6742 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.85390\n",
      "Epoch 363/2000\n",
      "\n",
      "Epoch 00363: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3213 - accuracy: 0.9341 - val_loss: 0.6967 - val_accuracy: 0.8453\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.85390\n",
      "Epoch 364/2000\n",
      "\n",
      "Epoch 00364: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3231 - accuracy: 0.9347 - val_loss: 0.6215 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.85390\n",
      "Epoch 365/2000\n",
      "\n",
      "Epoch 00365: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3203 - accuracy: 0.9348 - val_loss: 0.4788 - val_accuracy: 0.8509\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.85390\n",
      "Epoch 366/2000\n",
      "\n",
      "Epoch 00366: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 383ms/step - loss: 0.3190 - accuracy: 0.9340 - val_loss: 0.7227 - val_accuracy: 0.8506\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.85390\n",
      "Epoch 367/2000\n",
      "\n",
      "Epoch 00367: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 0.3203 - accuracy: 0.9346 - val_loss: 0.5695 - val_accuracy: 0.8534\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.85390\n",
      "Epoch 368/2000\n",
      "\n",
      "Epoch 00368: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3146 - accuracy: 0.9368 - val_loss: 0.5146 - val_accuracy: 0.8475\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.85390\n",
      "Epoch 369/2000\n",
      "\n",
      "Epoch 00369: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.3203 - accuracy: 0.9348 - val_loss: 0.6307 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.85390\n",
      "Epoch 370/2000\n",
      "\n",
      "Epoch 00370: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 377ms/step - loss: 0.3208 - accuracy: 0.9345 - val_loss: 0.5643 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.85390\n",
      "Epoch 371/2000\n",
      "\n",
      "Epoch 00371: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 393ms/step - loss: 0.3139 - accuracy: 0.9377 - val_loss: 0.5461 - val_accuracy: 0.8506\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.85390\n",
      "Epoch 372/2000\n",
      "\n",
      "Epoch 00372: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.3185 - accuracy: 0.9357 - val_loss: 0.5894 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.85390\n",
      "Epoch 373/2000\n",
      "\n",
      "Epoch 00373: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 23s 363ms/step - loss: 0.3200 - accuracy: 0.9334 - val_loss: 0.6918 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.85390\n",
      "Epoch 374/2000\n",
      "\n",
      "Epoch 00374: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.3142 - accuracy: 0.9352 - val_loss: 0.6990 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.85390\n",
      "Epoch 375/2000\n",
      "\n",
      "Epoch 00375: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3187 - accuracy: 0.9346 - val_loss: 0.5630 - val_accuracy: 0.8519\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.85390\n",
      "Epoch 376/2000\n",
      "\n",
      "Epoch 00376: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 373ms/step - loss: 0.3150 - accuracy: 0.9360 - val_loss: 0.5749 - val_accuracy: 0.8496\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.85390\n",
      "Epoch 377/2000\n",
      "\n",
      "Epoch 00377: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 23s 364ms/step - loss: 0.3149 - accuracy: 0.9357 - val_loss: 0.7021 - val_accuracy: 0.8461\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.42892\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.85390\n",
      "Epoch 378/2000\n",
      "\n",
      "Epoch 00378: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3193 - accuracy: 0.9346 - val_loss: 0.4144 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00378: val_loss improved from 0.42892 to 0.41435, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.85390\n",
      "Epoch 379/2000\n",
      "\n",
      "Epoch 00379: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 369ms/step - loss: 0.3152 - accuracy: 0.9362 - val_loss: 0.6102 - val_accuracy: 0.8496\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.85390\n",
      "Epoch 380/2000\n",
      "\n",
      "Epoch 00380: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 369ms/step - loss: 0.3208 - accuracy: 0.9314 - val_loss: 0.5452 - val_accuracy: 0.8515\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.85390\n",
      "Epoch 381/2000\n",
      "\n",
      "Epoch 00381: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 24s 373ms/step - loss: 0.3112 - accuracy: 0.9351 - val_loss: 0.5528 - val_accuracy: 0.8465\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.85390\n",
      "Epoch 382/2000\n",
      "\n",
      "Epoch 00382: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.3181 - accuracy: 0.9342 - val_loss: 0.6841 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.85390\n",
      "Epoch 383/2000\n",
      "\n",
      "Epoch 00383: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3157 - accuracy: 0.9347 - val_loss: 0.7816 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.85390\n",
      "Epoch 384/2000\n",
      "\n",
      "Epoch 00384: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.3169 - accuracy: 0.9349 - val_loss: 0.6024 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.85390\n",
      "Epoch 385/2000\n",
      "\n",
      "Epoch 00385: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.3179 - accuracy: 0.9350 - val_loss: 0.7031 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.85390\n",
      "Epoch 386/2000\n",
      "\n",
      "Epoch 00386: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 0.3148 - accuracy: 0.9373 - val_loss: 0.6077 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.85390\n",
      "Epoch 387/2000\n",
      "\n",
      "Epoch 00387: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 375ms/step - loss: 0.3154 - accuracy: 0.9361 - val_loss: 0.4197 - val_accuracy: 0.8489\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.85390\n",
      "Epoch 388/2000\n",
      "\n",
      "Epoch 00388: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 385ms/step - loss: 0.3153 - accuracy: 0.9363 - val_loss: 0.6833 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.85390\n",
      "Epoch 389/2000\n",
      "\n",
      "Epoch 00389: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.3131 - accuracy: 0.9359 - val_loss: 0.5244 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.85390\n",
      "Epoch 390/2000\n",
      "\n",
      "Epoch 00390: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 398ms/step - loss: 0.3125 - accuracy: 0.9344 - val_loss: 0.4656 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.85390\n",
      "Epoch 391/2000\n",
      "\n",
      "Epoch 00391: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 32s 503ms/step - loss: 0.3112 - accuracy: 0.9368 - val_loss: 0.4844 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.85390\n",
      "Epoch 392/2000\n",
      "\n",
      "Epoch 00392: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 384ms/step - loss: 0.3125 - accuracy: 0.9361 - val_loss: 0.4819 - val_accuracy: 0.8503\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.85390\n",
      "Epoch 393/2000\n",
      "\n",
      "Epoch 00393: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 0.3154 - accuracy: 0.9354 - val_loss: 0.5887 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.85390\n",
      "Epoch 394/2000\n",
      "\n",
      "Epoch 00394: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 390ms/step - loss: 0.3099 - accuracy: 0.9370 - val_loss: 0.5026 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.85390\n",
      "Epoch 395/2000\n",
      "\n",
      "Epoch 00395: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3079 - accuracy: 0.9382 - val_loss: 0.5571 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.85390\n",
      "Epoch 396/2000\n",
      "\n",
      "Epoch 00396: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 380ms/step - loss: 0.3090 - accuracy: 0.9363 - val_loss: 0.6369 - val_accuracy: 0.8510\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.85390\n",
      "Epoch 397/2000\n",
      "\n",
      "Epoch 00397: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3104 - accuracy: 0.9350 - val_loss: 0.6162 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.85390\n",
      "Epoch 398/2000\n",
      "\n",
      "Epoch 00398: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 398ms/step - loss: 0.3087 - accuracy: 0.9376 - val_loss: 0.6719 - val_accuracy: 0.8480\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.85390\n",
      "Epoch 399/2000\n",
      "\n",
      "Epoch 00399: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 24s 379ms/step - loss: 0.3106 - accuracy: 0.9371 - val_loss: 0.5405 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.85390\n",
      "Epoch 400/2000\n",
      "\n",
      "Epoch 00400: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 392ms/step - loss: 0.3079 - accuracy: 0.9372 - val_loss: 0.7097 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.85390\n",
      "Epoch 401/2000\n",
      "\n",
      "Epoch 00401: LearningRateScheduler setting learning rate to 0.001.\n",
      "64/64 [==============================] - 25s 392ms/step - loss: 0.3091 - accuracy: 0.9366 - val_loss: 0.7353 - val_accuracy: 0.8533\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.41435\n",
      "\n",
      "Epoch 00401: val_accuracy did not improve from 0.85390\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00401: early stopping\n",
      "## Saved in /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-normXY-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.pickle ###\n",
      "\n",
      "\n",
      "Loading maxAccModelName\n",
      "moving maxAccModelName to modelFileNamePath\n",
      "Model for MAX ACCURACY test_acc: 85.390 val_acc: 85.390\n",
      "Model for MIN LOSS test_acc: 84.604 val_acc: 84.604\n",
      "Loading previous results...\n",
      "Dumping results...\n",
      "######## 5/16 - pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-MIRR-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05 - Cross_subject/ ########\n",
      "touching /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/pos-4L-cuda-HU_64-LR_0,01-OFF_0,001-POW_2-MIRR-rimoz_0-normXY-NEXT_3-glob_norm1-MERGED-rimoz_0-3BAR_GLOB-glob_norm2-drop-0,15-reg-1e-05.h5\n",
      "## To be saved in [...]/savedModels/Cross_subject/ ###\n",
      "#### Loading dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_SUBJECT-dataset.pickle\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from keras import models  # , layers\n",
    "from keras.layers import LSTM, CuDNNLSTM, Dropout, Dense, Input  # , Concatenate\n",
    "from keras.models import load_model, Model\n",
    "from keras.optimizers import RMSprop  # Adam #, RMSprop, Adadelta\n",
    "from keras.regularizers import l2  # , l1\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from os import scandir\n",
    "from os.path import exists, basename\n",
    "import shutil\n",
    "import math\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K\n",
    "import os\n",
    "\n",
    "# earlyStop = EarlyStopping(monitor='val_acc', ## 4 COLAB\n",
    "earlyStop = EarlyStopping(monitor='val_accuracy',\n",
    "                          min_delta=0,\n",
    "                          patience=PATIENCE,\n",
    "                          verbose=1,\n",
    "                          mode='max',\n",
    "                          baseline=None,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "progressCounter = 0\n",
    "\n",
    "for MODEL_NAME in MODEL_NAME_VALUES:\n",
    "    for LEARNING_RATE in LEARNING_RATE_VALUES:\n",
    "        for MIRRORING in MIRRORING_VALUES:\n",
    "            for STD_JITTERING in STD_JITTERING_VALUES:\n",
    "                for dropOut_idx, dropOut in enumerate(DROPOUT_VALUES):\n",
    "                    for LSTM_LAYERS in LSTM_LAYERS_VALUES:\n",
    "                        for regularizer_idx, regularizer in enumerate(REGULARIZER_VALUES):\n",
    "                            for HIDDEN_UNITS in HIDDEN_UNITS_VALUES:\n",
    "\n",
    "                                DROPOUT = dropOut\n",
    "                                RECURRENT_DROPOUT = dropOut\n",
    "                                #                                 EPOCHS = round(REFERENCE_EPOCHS * (1+DROPOUT))\n",
    "\n",
    "                                for i, (folder_where_to_save, preprocess_functions) in enumerate(\n",
    "                                        PREPROCESS_FUNCTION_TO_TEST):\n",
    "                                    progressCounter += 1\n",
    "                                    folderPathWhereToSave = SAVED_MODEL_FOLDER + folder_where_to_save\n",
    "                                    if folder_where_to_save.endswith(\"_lrScan/\"):\n",
    "                                        EPOCHS = SCAN_EPOCHS\n",
    "\n",
    "                                    alreadyTrainedModel = [f for f in scandir(folderPathWhereToSave) if\n",
    "                                                           f.path.endswith(\".h5\")]\n",
    "\n",
    "                                    ### SET SAVE FILE NAME ###\n",
    "                                    if CONTINUE_TRAINING:\n",
    "                                        saveFileName = CONTINUE_TRAINING\n",
    "                                        saveFileName += \"_THEN\"\n",
    "                                        saveFileName += \"_MIRR\" if MIRRORING else \"\"\n",
    "                                        saveFileName += \"_JIT_\" + str(STD_JITTERING) if STD_JITTERING > 0 else \"\"\n",
    "                                        saveFileName += \"_drop_\" + str(dropOut) if dropOut > 0 else \"\"\n",
    "                                    elif MERGE_TECHNIQUES:\n",
    "                                        prep_fun1 = preprocess_functions[0][0]\n",
    "                                        globNorm1 = preprocess_functions[0][1]\n",
    "                                        prep_fun2 = preprocess_functions[1][0]\n",
    "                                        globNorm2 = preprocess_functions[1][1]\n",
    "                                        saveFileName = getSaveFileName(modelName=MODEL_NAME,\n",
    "                                                                       preprocess_functions=prep_fun1,\n",
    "                                                                       learning_rate=LEARNING_RATE,\n",
    "                                                                       offset=LR_OFFSET,\n",
    "                                                                       power=LR_POWER,\n",
    "                                                                       numberOfLSTMLayers=LSTM_LAYERS,\n",
    "                                                                       useCudaLSTM=USE_CuDNNLSTM,\n",
    "                                                                       hiddenUnits=HIDDEN_UNITS,\n",
    "                                                                       regularizerValue=regularizer,\n",
    "                                                                       dropOut=DROPOUT,\n",
    "                                                                       recurrentDropOut=RECURRENT_DROPOUT,\n",
    "                                                                       std_jittering=STD_JITTERING,\n",
    "                                                                       mirroring=MIRRORING,\n",
    "                                                                       preprocess_functions_2=prep_fun2,\n",
    "                                                                       normalizeGlobally1 = globNorm1,\n",
    "                                                                       normalizeGlobally2 = globNorm2)\n",
    "\n",
    "                                    else:\n",
    "                                        saveFileName = getSaveFileName(modelName=MODEL_NAME,\n",
    "                                                                       preprocess_functions=preprocess_functions,\n",
    "                                                                       learning_rate=LEARNING_RATE,\n",
    "                                                                       offset=LR_OFFSET,\n",
    "                                                                       power=LR_POWER,\n",
    "                                                                       numberOfLSTMLayers=LSTM_LAYERS,\n",
    "                                                                       useCudaLSTM=USE_CuDNNLSTM,\n",
    "                                                                       hiddenUnits=HIDDEN_UNITS,\n",
    "                                                                       regularizerValue=regularizer,\n",
    "                                                                       dropOut=DROPOUT,\n",
    "                                                                       recurrentDropOut=RECURRENT_DROPOUT,\n",
    "                                                                       std_jittering=STD_JITTERING,\n",
    "                                                                       mirroring=MIRRORING)\n",
    "\n",
    "                                    print(\"######## {}/{} - {} - {} ########\".format(progressCounter, numberOfTests,\n",
    "                                                                                     saveFileName,\n",
    "                                                                                     folder_where_to_save))\n",
    "\n",
    "                                    if saveFileName + \".h5\" in [m.name for m in alreadyTrainedModel]:\n",
    "                                        print(\"### already done! ####\")\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        # to avoid that someone else will start the same fitting\n",
    "                                        print(\"touching\", folderPathWhereToSave + saveFileName + \".h5\")\n",
    "                                        modelFileName = saveFileName + \".h5\"\n",
    "\n",
    "                                        #                                         pathToTouch = (folderPathWhereToSave+modelFileName).replace(\" \",\"\\ \") ## 4 COLAB\n",
    "                                        modelFileNamePath = folderPathWhereToSave + modelFileName\n",
    "                                        !touch $modelFileNamePath\n",
    "                                        print(\"## To be saved in [...]{} ###\".format(folderPathWhereToSave[54:]))\n",
    "\n",
    "                                    # RETRIEVE DATASET NAME\n",
    "                                    datasetName = getDatasetName(folderPathWhereToSave, MODEL_NAME)\n",
    "\n",
    "                                    # PREPROCESS DATASET\n",
    "                                    if not MERGE_TECHNIQUES:\n",
    "                                        X_train, y_train, X_val, y_val, X_test, y_test, encodingLabels = getPreprocessedDataset(\n",
    "                                            datasetName,\n",
    "                                            MODEL_NAME,\n",
    "                                            MIRRORING,\n",
    "                                            STD_JITTERING,\n",
    "                                            preprocess_functions)\n",
    "                                    else:\n",
    "                                        X_train1, y_train1, X_val1, y_val1, X_test1, y_test1, encodingLabels1 = getPreprocessedDataset(\n",
    "                                            datasetName,\n",
    "                                            MODEL_NAME,\n",
    "                                            MIRRORING,\n",
    "                                            STD_JITTERING,\n",
    "                                            prep_fun1,\n",
    "                                            globNorm1)\n",
    "                                        X_train2, y_train2, X_val2, y_val2, X_test2, y_test2, encodingLabels2 = getPreprocessedDataset(\n",
    "                                            datasetName,\n",
    "                                            MODEL_NAME,\n",
    "                                            MIRRORING,\n",
    "                                            STD_JITTERING,\n",
    "                                            prep_fun2,\n",
    "                                            globNorm2)\n",
    "                                        assert encodingLabels1 == encodingLabels1\n",
    "                                        encodingLabels = encodingLabels1\n",
    "\n",
    "                                        if MERGING_TRAIN_VAL:\n",
    "                                            print(\"## MERGING TRAIN+VAL ##\")\n",
    "                                            X_train1 = np.concatenate((X_train1, X_val1), axis=0)\n",
    "                                            y_train1 = np.concatenate((y_train1, y_val1), axis=0)\n",
    "                                            X_train2 = np.concatenate((X_train2, X_val2), axis=0)\n",
    "                                            y_train2 = np.concatenate((y_train2, y_val2), axis=0)\n",
    "                                            X_val1, y_val1, X_val2, y_val2 = X_test1, y_test1, X_test2, y_test2\n",
    "\n",
    "                                        ################################  GENERATORS ################################################\n",
    "                                        trainingGenerator = sampleGenerator(X_train1, y_train1, X_train2, y_train2,\n",
    "                                                                            BATCH_SIZE, isTraining=True)\n",
    "                                        validationGenerator = sampleGenerator(X_val1, y_val1, X_val2, y_val2,\n",
    "                                                                              BATCH_SIZE, isTraining=False)\n",
    "                                    ################################################################################################\n",
    "\n",
    "                                    ## callbacks and checkpoints\n",
    "                                    minLossModelName = \"{}-min_val_loss.hdf5\".format(\n",
    "                                        folderPathWhereToSave + saveFileName)\n",
    "                                    checkpointLoss = ModelCheckpoint(minLossModelName, monitor='val_loss',\n",
    "                                                                     verbose=1,\n",
    "                                                                     save_best_only=True, mode='min')\n",
    "\n",
    "                                    maxAccModelName = \"{}-max_val_acc.hdf5\".format(folderPathWhereToSave + saveFileName)\n",
    "\n",
    "                                    checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_accuracy',\n",
    "                                                                    verbose=1,\n",
    "                                                                    save_best_only=True, mode='max')\n",
    "                                    #                     checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_acc', verbose=1, save_best_only=True, mode='max') ## 4 COLAB\n",
    "\n",
    "                                    callbacks_list = [checkpointLoss, checkpointAcc]\n",
    "\n",
    "                                    if USE_SCHEDULER:\n",
    "                                        callbacks_list.append(LearningRateScheduler(scheduler, verbose=1))\n",
    "                                        callbacks_list.append(earlyStop)\n",
    "                                    else:\n",
    "                                        callbacks_list.append(earlyStop)\n",
    "\n",
    "                                    #                                     assert False, \"stop here\"\n",
    "\n",
    "                                    ### DEFINING MODEL ###\n",
    "                                    if not MERGE_TECHNIQUES:\n",
    "                                        # TO SOLVE THE DROPOUT LAYER SHAPE PROBLEM\n",
    "                                        missing_train = (BATCH_SIZE - (X_train.shape[0] % BATCH_SIZE)) % BATCH_SIZE\n",
    "                                        X_train = np.concatenate((X_train, X_train[:missing_train]), axis=0)\n",
    "                                        y_train = np.concatenate((y_train, y_train[:missing_train]), axis=0)\n",
    "\n",
    "                                        inputDim = (X_train.shape[1], X_train.shape[2])\n",
    "                                        outputLen = len(y_train[0])\n",
    "\n",
    "                                        model = models.Sequential()\n",
    "                                        model.add(Dropout(DROPOUT, input_shape=inputDim,\n",
    "                                                          noise_shape=(BATCH_SIZE, 1, inputDim[1])))\n",
    "                                        if USE_LSTM:\n",
    "                                            if LSTM_LAYERS == 1:\n",
    "                                                model.add(LSTM(HIDDEN_UNITS, recurrent_dropout=RECURRENT_DROPOUT))\n",
    "                                            else:\n",
    "                                                model.add(LSTM(HIDDEN_UNITS, recurrent_dropout=RECURRENT_DROPOUT,\n",
    "                                                               return_sequences=True))\n",
    "                                                for layerIdx in range(2, LSTM_LAYERS):\n",
    "                                                    model.add(LSTM(HIDDEN_UNITS, recurrent_dropout=RECURRENT_DROPOUT,\n",
    "                                                                   return_sequences=True))\n",
    "                                                model.add(LSTM(HIDDEN_UNITS, recurrent_dropout=RECURRENT_DROPOUT))\n",
    "\n",
    "                                        elif USE_CuDNNLSTM:\n",
    "                                            print(\"#### REMOVED KERNEL REGULARIZER #######\")\n",
    "                                            reg = l2(regularizer) if regularizer > 0 else None\n",
    "\n",
    "                                            if LSTM_LAYERS == 1:\n",
    "                                                model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg))\n",
    "                                            else:\n",
    "                                                model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg,\n",
    "                                                                    return_sequences=True))\n",
    "                                                for layerIdx in range(2, LSTM_LAYERS):\n",
    "                                                    model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg,\n",
    "                                                                        return_sequences=True))\n",
    "                                                model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg))\n",
    "\n",
    "                                        model.add(Dense(outputLen, activation='softmax'))\n",
    "                                    else:\n",
    "                                        #                                         assert False, \"crea la struttura ad hoc\"\n",
    "                                        print(\"#### CREATINGS COMBINATION OF BEST STRUCTURES #######\")\n",
    "                                        inputDim1 = (X_train1.shape[1], X_train1.shape[2])\n",
    "                                        inputDim2 = (X_train2.shape[1], X_train2.shape[2])\n",
    "                                        outputLen1 = len(y_train1[0])\n",
    "                                        outputLen2 = len(y_train2[0])\n",
    "\n",
    "                                        reg = l2(regularizer) if regularizer > 0 else None\n",
    "                                        input1 = Input(shape=inputDim1)\n",
    "                                        output1 = Dropout(DROPOUT, noise_shape=(BATCH_SIZE, 1, inputDim1[1]))(input1)\n",
    "                                        output1 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg,\n",
    "                                                            return_sequences=True)(output1)\n",
    "                                        output1 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg,\n",
    "                                                            return_sequences=True)(output1)\n",
    "                                        output1 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg)(output1)\n",
    "                                        output1 = Dense(outputLen1, activation='softmax')(output1)\n",
    "\n",
    "                                        input2 = Input(shape=inputDim2)\n",
    "                                        output2 = Dropout(DROPOUT, noise_shape=(BATCH_SIZE, 1, inputDim2[1]))(input2)\n",
    "                                        output2 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg,\n",
    "                                                            return_sequences=True)(output2)\n",
    "                                        output2 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg,\n",
    "                                                            return_sequences=True)(output2)\n",
    "                                        output2 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg)(output2)\n",
    "                                        output2 = Dense(outputLen2, activation='softmax')(output2)\n",
    "\n",
    "                                        output = keras.layers.Average()([output1, output2])\n",
    "\n",
    "                                        model = Model(inputs=[input1, input2], outputs=[output])\n",
    "\n",
    "                                    # opt = Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "                                    # opt = Adadelta(learning_rate=LEARNING_RATE, rho=0.95)\n",
    "                                    opt = RMSprop(lr=LEARNING_RATE, rho=0.9)  ## 4 COLAB\n",
    "                                    #                                     opt = RMSprop(lerning_rate=LEARNING_RATE, rho=0.9)\n",
    "\n",
    "                                    model.compile(\n",
    "                                        #                                         optimizer='rmsprop',\n",
    "                                        optimizer=opt,\n",
    "                                        loss='categorical_crossentropy',\n",
    "                                        metrics=['accuracy'])\n",
    "\n",
    "                                    ## CONTINUE TRAINING\n",
    "                                    if CONTINUE_TRAINING:\n",
    "                                        print(\"Loading from\", CONTINUE_TRAINING)\n",
    "                                        continueTrainingModelName = \"{}.h5\".format(\n",
    "                                            folderPathWhereToSave + CONTINUE_TRAINING)\n",
    "                                        model.load_weights(continueTrainingModelName)\n",
    "                                        previousModelName = continueTrainingModelName\n",
    "\n",
    "                                    ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "                                    if exists(minLossModelName):\n",
    "                                        print(\"#### Loading weights from MIN LOSS model\")\n",
    "                                        model.load_weights(minLossModelName)\n",
    "\n",
    "                                    ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "                                    minLossBackupModelName = \"{}-min_val_loss-BACKUP.hdf5\".format(\n",
    "                                        folderPathWhereToSave + saveFileName)\n",
    "                                    if exists(maxAccModelName):\n",
    "                                        print(\"#### Loading weights from MAX ACCURACY model\")\n",
    "                                        model.load_weights(maxAccModelName)\n",
    "                                        if exists(minLossModelName):\n",
    "                                            print(\"#### BACKUP of weights for previous MIN LOSS model\")\n",
    "                                            shutil.copyfile(minLossModelName, minLossBackupModelName)\n",
    "\n",
    "                                    ## Loading weights from previous model trained with an higher dropout rate\n",
    "                                    loadedFromPreviousModel = False\n",
    "                                    if (DROPOUT > 0 or RECURRENT_DROPOUT > 0) and LOAD_FROM_PREVIOUS_DROPOUT and USE_LSTM:\n",
    "                                        for prev_dropOut in LOAD_FROM_PREVIOUS_DROPOUT:\n",
    "                                            if prev_dropOut <= DROPOUT:\n",
    "                                                continue\n",
    "                                            previousModelName = getSaveFileName(modelName=MODEL_NAME,\n",
    "                                                                                preprocess_functions=preprocess_functions,\n",
    "                                                                                learning_rate=LEARNING_RATE,\n",
    "                                                                                offset=LR_OFFSET,\n",
    "                                                                                power=LR_POWER,\n",
    "                                                                                numberOfLSTMLayers=LSTM_LAYERS,\n",
    "                                                                                useCudaLSTM=USE_CuDNNLSTM,\n",
    "                                                                                hiddenUnits=HIDDEN_UNITS,\n",
    "                                                                                regularizerValue=regularizer,\n",
    "                                                                                dropOut=prev_dropOut,\n",
    "                                                                                recurrentDropOut=prev_dropOut,\n",
    "                                                                                std_jittering=STD_JITTERING,\n",
    "                                                                                mirroring=MIRRORING)\n",
    "                                            if exists(folderPathWhereToSave + previousModelName + \".h5\"):\n",
    "                                                print(\"#### Loading weights from\", previousModelName)\n",
    "                                                model.load_weights(folderPathWhereToSave + previousModelName + \".h5\")\n",
    "                                                loadedFromPreviousModel = True\n",
    "                                                break\n",
    "\n",
    "                                    # FIT ###\n",
    "                                    if not MERGE_TECHNIQUES:\n",
    "                                        print(\"### FITTING NORMALLY  ####\")\n",
    "                                        model_history = model.fit(X_train, y_train,\n",
    "                                                                  epochs=EPOCHS,\n",
    "                                                                  batch_size=BATCH_SIZE,\n",
    "                                                                  callbacks=callbacks_list,\n",
    "                                                                  validation_data=(X_val, y_val)\n",
    "                                                                  )\n",
    "                                    else:\n",
    "                                        print(\"### FITTING WITH GENERATORS  ####\")\n",
    "                                        trainStepPerEpoch = int(len(X_train1) / BATCH_SIZE) + 1\n",
    "                                        valStepPerEpoch = int(len(X_val1) / BATCH_SIZE) + 1\n",
    "\n",
    "                                        model_history = model.fit_generator(trainingGenerator,\n",
    "                                                                            epochs=EPOCHS,\n",
    "                                                                            steps_per_epoch=trainStepPerEpoch,\n",
    "                                                                            callbacks=callbacks_list,\n",
    "                                                                            validation_data=validationGenerator,\n",
    "                                                                            validation_steps=valStepPerEpoch\n",
    "                                                                            )\n",
    "\n",
    "                                    ### SAVE MODEL ###\n",
    "                                    model.save(folderPathWhereToSave + saveFileName + \".h5\")\n",
    "\n",
    "                                    ### SAVE HISTORY AND PREPROCESS FUNCTIONS ###\n",
    "                                    env_functions = [one_hot_encoding,\n",
    "                                                     euclDistance,\n",
    "                                                     paddingTrainValTest,\n",
    "                                                     getClosestNonZeroCoordinate,\n",
    "                                                     removeZerosFromVideo,\n",
    "                                                     getZeroStatsForDataset,\n",
    "                                                     preprocessData,\n",
    "                                                     ]\n",
    "\n",
    "                                    historyToSave = {\n",
    "                                        \"acc\": model_history.history['accuracy'],\n",
    "                                        \"val_acc\": model_history.history['val_accuracy'],\n",
    "                                        \"loss\": model_history.history['loss'],\n",
    "                                        \"val_loss\": model_history.history['val_loss']\n",
    "                                    }\n",
    "\n",
    "                                    info_to_save = {\"history\": historyToSave,\n",
    "                                                    \"env_fun_DILL\": [dill.dumps(x) for x in env_functions],\n",
    "                                                    \"spec_fun_DILL\": [dill.dumps(x) for x in preprocess_functions]}\n",
    "\n",
    "                                    if loadedFromPreviousModel or CONTINUE_TRAINING:\n",
    "                                        info_to_save[\"loaded_from\"] = previousModelName\n",
    "\n",
    "                                    with open(folderPathWhereToSave + saveFileName + \".pickle\", \"wb\") as handle:\n",
    "                                        pickle.dump(info_to_save, handle)\n",
    "                                        print(\"## Saved in {} ###\\n\\n\".format(\n",
    "                                            folderPathWhereToSave + saveFileName + \".pickle\"))\n",
    "\n",
    "                                    ### EVALUATING MODEL ###\n",
    "                                    print(\"Loading maxAccModelName\")\n",
    "                                    model = load_model(maxAccModelName)\n",
    "                                    print(\"moving maxAccModelName to modelFileNamePath\")\n",
    "                                    !mv $maxAccModelName $modelFileNamePath\n",
    "\n",
    "                                    if MERGE_TECHNIQUES:\n",
    "                                        X_val = [X_val1, X_val2]\n",
    "                                        X_test = [X_test1, X_test2]\n",
    "                                        y_val = y_val1\n",
    "                                        y_test = y_test1\n",
    "\n",
    "                                    val_acc, test_acc, y_val_true, y_val_pred, y_test_true, y_test_pred = getValTestAccuracy(\n",
    "                                        model, X_val, y_val, X_test, y_test, encodingLabels)\n",
    "                                    print(\n",
    "                                        \"Model for MAX ACCURACY test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc * 100,\n",
    "                                                                                                         val_acc * 100))\n",
    "\n",
    "                                    if exists(minLossModelName):\n",
    "                                        model_minLoss = load_model(minLossModelName)\n",
    "                                        val_acc_minLoss, test_acc_minLoss, y_val_true, y_val_pred_minLoss, y_test_true, y_test_pred_minLoss = getValTestAccuracy(\n",
    "                                            model_minLoss, X_val, y_val, X_test, y_test, encodingLabels)\n",
    "                                        print(\"Model for MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(\n",
    "                                            test_acc_minLoss * 100, val_acc_minLoss * 100))\n",
    "                                    else:\n",
    "                                        print(\"Model for MIN LOSS NOT SAVED\")\n",
    "                                        val_acc_minLoss = math.inf\n",
    "\n",
    "                                    if exists(minLossBackupModelName):\n",
    "                                        model_minLoss_b = load_model(minLossBackupModelName)\n",
    "                                        print(\"#### Evaluating BACKUP min loss model ####\")\n",
    "                                        val_acc_minLoss_b, test_acc_minLoss_b, y_val_true, y_val_pred_minLoss_b, y_test_true, y_test_pred_minLoss_b = getValTestAccuracy(\n",
    "                                            model_minLoss_b, X_val, y_val, X_test, y_test, encodingLabels)\n",
    "                                        print(\"Model for BACKUP MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(\n",
    "                                            test_acc_minLoss_b * 100, val_acc_minLoss_b * 100))\n",
    "                                        if (val_acc_minLoss_b < val_acc_minLoss):\n",
    "                                            print(\"### keeping BACKUP MIN LOSS model ####\")\n",
    "                                            val_acc_minLoss, test_acc_minLoss, y_val_pred_minLoss, y_test_pred_minLoss = val_acc_minLoss_b, test_acc_minLoss_b, y_val_pred_minLoss_b, y_test_pred_minLoss_b\n",
    "                                            !mv $minLossBackupModelName $minLossModelName\n",
    "                                        else:\n",
    "                                            !rm $minLossBackupModelName\n",
    "\n",
    "                                    ### CLEANING MAX ACC CHECKPOINT\n",
    "                                    ## 4 COLAB\n",
    "                                    #                     patToRemove = maxAccModelName.replace(\" \",\"\\ \")\n",
    "                                    #                         patToRemove = maxAccModelName\n",
    "                                    #                         !rm $patToRemove\n",
    "\n",
    "                                    ### SAVING RESULTS ###\n",
    "                                    if EPOCHS < 10:\n",
    "                                        print(\"## SKIPPING SAVING. EPOCHS < 11\")\n",
    "                                        continue\n",
    "\n",
    "                                    if exists(folderPathWhereToSave + \"summaryResults.pickle\"):\n",
    "                                        print(\"Loading previous results...\")\n",
    "                                        with open(folderPathWhereToSave + \"summaryResults.pickle\", \"rb\") as handle:\n",
    "                                            results = pickle.load(handle)\n",
    "                                    else:\n",
    "                                        results = []\n",
    "\n",
    "                                    results.append({\"val_acc\": val_acc,\n",
    "                                                    \"test_acc\": test_acc,\n",
    "                                                    \"model_name\": saveFileName,\n",
    "                                                    \"y_val_true\": y_val_true,\n",
    "                                                    \"y_val_pred\": y_val_pred,\n",
    "                                                    \"y_test_true\": y_test_true,\n",
    "                                                    \"y_test_pred\": y_test_pred,\n",
    "\n",
    "                                                    \"val_acc_minLoss\": val_acc_minLoss,\n",
    "                                                    \"test_acc_minLoss\": test_acc_minLoss,\n",
    "                                                    \"y_val_pred_minLoss\": y_val_pred_minLoss,\n",
    "                                                    \"y_test_pred_minLoss\": y_test_pred_minLoss\n",
    "                                                    })\n",
    "\n",
    "                                    print(\"Dumping results...\")\n",
    "                                    with open(folderPathWhereToSave + \"summaryResults.pickle\", \"wb\") as handle:\n",
    "                                        pickle.dump(results, handle)\n",
    "\n",
    "print(\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56880, 57024)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train1)+len(X_test1),len(X_train2)+len(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 828, 828)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validationGenerator = sampleGenerator(X_val1, y_val1, X_val2, y_val2, len(X_val1), name=\"validation\")\n",
    "# len(X_train1),len(X_val1),len(X_test1)\n",
    "totale = 2844\n",
    "test1 = 948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for MAX ACCURACY test_acc: 33.544 val_acc: 33.544\n",
      "Model for MIN LOSS test_acc: 33.439 val_acc: 33.439\n",
      "Loading previous results...\n",
      "Dumping results...\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# #                                     model = load_model(maxAccModelName)\n",
    "# #                                     !mv $maxAccModelName $modelFileNamePath\n",
    "                                    \n",
    "#                                     if MERGE_TECHNIQUES:\n",
    "#                                         X_val = [X_val1, X_val2]\n",
    "#                                         X_test = [X_test1, X_test2]\n",
    "#                                         y_val = y_val1\n",
    "#                                         y_test = y_test1\n",
    "#                                     val_acc, test_acc, y_val_true, y_val_pred, y_test_true, y_test_pred = getValTestAccuracy(\n",
    "#                                             model, X_val, y_val, X_test, y_test, encodingLabels)\n",
    "#                                     print(\n",
    "#                                         \"Model for MAX ACCURACY test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc * 100,\n",
    "#                                                                                                          val_acc * 100))\n",
    "\n",
    "#                                     if exists(minLossModelName):\n",
    "#                                         model_minLoss = load_model(minLossModelName)\n",
    "#                                         val_acc_minLoss, test_acc_minLoss, y_val_true, y_val_pred_minLoss, y_test_true, y_test_pred_minLoss = getValTestAccuracy(\n",
    "#                                             model_minLoss, X_val, y_val, X_test, y_test, encodingLabels)\n",
    "#                                         print(\"Model for MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(\n",
    "#                                             test_acc_minLoss * 100, val_acc_minLoss * 100))\n",
    "#                                     else:\n",
    "#                                         print(\"Model for MIN LOSS NOT SAVED\")\n",
    "#                                         val_acc_minLoss = math.inf\n",
    "\n",
    "#                                     if exists(minLossBackupModelName):\n",
    "#                                         model_minLoss_b = load_model(minLossBackupModelName)\n",
    "#                                         print(\"#### Evaluating BACKUP min loss model ####\")\n",
    "#                                         val_acc_minLoss_b, test_acc_minLoss_b, y_val_true, y_val_pred_minLoss_b, y_test_true, y_test_pred_minLoss_b = getValTestAccuracy(\n",
    "#                                             model_minLoss_b, X_val, y_val, X_test, y_test, encodingLabels)\n",
    "#                                         print(\"Model for BACKUP MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(\n",
    "#                                             test_acc_minLoss_b * 100, val_acc_minLoss_b * 100))\n",
    "#                                         if (val_acc_minLoss_b < val_acc_minLoss):\n",
    "#                                             print(\"### keeping BACKUP MIN LOSS model ####\")\n",
    "#                                             val_acc_minLoss, test_acc_minLoss, y_val_pred_minLoss, y_test_pred_minLoss = val_acc_minLoss_b, test_acc_minLoss_b, y_val_pred_minLoss_b, y_test_pred_minLoss_b\n",
    "#                                             !mv $minLossBackupModelName $minLossModelName\n",
    "#                                         else:\n",
    "#                                             !rm $minLossBackupModelName\n",
    "\n",
    "#                                     ### CLEANING MAX ACC CHECKPOINT\n",
    "#                                     ## 4 COLAB\n",
    "#                                     #                     patToRemove = maxAccModelName.replace(\" \",\"\\ \")\n",
    "#                                     #                         patToRemove = maxAccModelName\n",
    "#                                     #                         !rm $patToRemove\n",
    "\n",
    "#                                     ### SAVING RESULTS ###\n",
    "#                                     if EPOCHS < 10:\n",
    "#                                         print(\"## SKIPPING SAVING. EPOCHS < 11\")\n",
    "# #                                         continue\n",
    "\n",
    "#                                     if exists(folderPathWhereToSave + \"summaryResults.pickle\"):\n",
    "#                                         print(\"Loading previous results...\")\n",
    "#                                         with open(folderPathWhereToSave + \"summaryResults.pickle\", \"rb\") as handle:\n",
    "#                                             results = pickle.load(handle)\n",
    "#                                     else:\n",
    "#                                         results = []\n",
    "\n",
    "#                                     results.append({\"val_acc\": val_acc,\n",
    "#                                                     \"test_acc\": test_acc,\n",
    "#                                                     \"model_name\": saveFileName,\n",
    "#                                                     \"y_val_true\": y_val_true,\n",
    "#                                                     \"y_val_pred\": y_val_pred,\n",
    "#                                                     \"y_test_true\": y_test_true,\n",
    "#                                                     \"y_test_pred\": y_test_pred,\n",
    "\n",
    "#                                                     \"val_acc_minLoss\": val_acc_minLoss,\n",
    "#                                                     \"test_acc_minLoss\": test_acc_minLoss,\n",
    "#                                                     \"y_val_pred_minLoss\": y_val_pred_minLoss,\n",
    "#                                                     \"y_test_pred_minLoss\": y_test_pred_minLoss\n",
    "#                                                     })\n",
    "\n",
    "#                                     print(\"Dumping results...\")\n",
    "#                                     with open(folderPathWhereToSave + \"summaryResults.pickle\", \"wb\") as handle:\n",
    "#                                         pickle.dump(results, handle)\n",
    "\n",
    "#                                     print(\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valStepPerEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### CREATINGS COMBINATION OF BEST STRUCTURES #######\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "print(\"#### CREATINGS COMBINATION OF BEST STRUCTURES #######\")\n",
    "inputDim1 = (X_train1.shape[1], X_train1.shape[2])\n",
    "inputDim2 = (X_train2.shape[1], X_train2.shape[2])\n",
    "outputLen1 = len(y_train1[0])\n",
    "outputLen2 = len(y_train2[0])\n",
    "\n",
    "reg = l2(regularizer) if regularizer > 0 else None\n",
    "input1 = Input(shape=inputDim1)\n",
    "output1 = Dropout(DROPOUT, noise_shape=(BATCH_SIZE, 1, inputDim1[1]))(input1)\n",
    "output1 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg, return_sequences=True)(output1)\n",
    "output1 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg, return_sequences=True)(output1)\n",
    "output1 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg)(output1)\n",
    "output1 = Dense(outputLen1, activation='softmax')(output1)\n",
    "\n",
    "input2 = Input(shape=inputDim2)\n",
    "output2 = Dropout(DROPOUT, noise_shape=(BATCH_SIZE, 1, inputDim2[1]))(input2)\n",
    "output2 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg, return_sequences=True)(output2)\n",
    "output2 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg, return_sequences=True)(output2)\n",
    "output2 = CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg)(output2)\n",
    "output2 = Dense(outputLen2, activation='softmax')(output2)\n",
    "\n",
    "output = keras.layers.Average()([output1, output2])\n",
    "\n",
    "model = Model(inputs=[input1,input2], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_view_test/keypoint_rcnn_X_101_32x8d_FPN_3x-4L-CuDNNLSTM-HU_64-LR_0.01-OFF_0.001-POW_2-MIRR-STD_JIT_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-MERGED-relativeTo3GlobalBaricentersOfVideo-normalizeVideos-drop-0.15-reg-0.0001.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on MERGED models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "# from keras import models #, layers\n",
    "# from keras.layers import LSTM, CuDNNLSTM, Dropout, Dense #, Concatenate \n",
    "from keras.models import load_model #, Model\n",
    "# from keras.optimizers import RMSprop #Adam #, RMSprop, Adadelta\n",
    "# from keras.regularizers import l2 #, l1\n",
    "# from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "# from os import scandir\n",
    "# from os.path import exists, basename\n",
    "# import shutil \n",
    "# import math\n",
    "# from numpy.random import seed\n",
    "# from tensorflow import set_random_seed \n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import random as rn\n",
    "# from keras import backend as K\n",
    "# import os\n",
    "\n",
    "# SAVED_MODEL_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/\"\n",
    "SAVED_MODEL_FOLDER = \"/Users/andrea/Documents/universita/tesi/savedModels/\"\n",
    "# DATASET_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/\"\n",
    "      \n",
    "model_folder = \"Cross_subject/\"\n",
    "# model_folder = \"Cross_view/\" \n",
    "\n",
    "MODEL_NAME_VALUES = [\n",
    "    \"keypoint_rcnn_X_101_32x8d_FPN_3x\"\n",
    "#     \"PoseNet-101\"\n",
    "    ]\n",
    "\n",
    "modelName1 = \"keypoint_rcnn_X_101_32x8d_FPN_3x-3L-HU_64-LR_0.01-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-THEN_drop_0.05.h5\"\n",
    "modelName2 = \"keypoint_rcnn_X_101_32x8d_FPN_3x-3L-removeZerosFromDataset-relativeToUpperMiddleBottomCentersOfVideo-normalizeVideos-drop-0.05-rec_drop-0.05.h5\"\n",
    "\n",
    "model1 = load_model(SAVED_MODEL_FOLDER+model_folder+modelName1)\n",
    "model2 = load_model(SAVED_MODEL_FOLDER+model_folder+modelName2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/\"\n",
    "DATASET_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/\"\n",
    "\n",
    "modelFolder = \"Cross_subject/\"\n",
    "modelName1 = \"keypoint_rcnn_X_101_32x8d_FPN_3x-3L-HU_64-LR_0.01-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-THEN_drop_0.05.h5\"\n",
    "modelName2 = \"keypoint_rcnn_X_101_32x8d_FPN_3x-4L-CuDNNLSTM-HU_64-LR_0.01-OFF_0.001-POW_2-MIRR-STD_JIT_2-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.15-reg-0.h5\"      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/envs/gpuEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /data/students_home/amoscatelli/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "assert modelName1.split(\"-\")[0] == modelName2.split(\"-\")[0]\n",
    "\n",
    "model1 = load_model(SAVED_MODEL_FOLDER+modelFolder+modelName1)\n",
    "model2 = load_model(SAVED_MODEL_FOLDER+modelFolder+modelName1)\n",
    "# mergedLayer = keras.layers.Average()([model1, model2])\n",
    "# mergedLayer = keras.layers.Maximum()([model1, model2])\n",
    "\n",
    "# mergedModel = keras.models.Model(inputs=[model1, model2], outputs=mergedLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dropout_6_input:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.input.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(SAVED_MODEL_FOLDER+modelFolder+modelName1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dropout_6_input_1:0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.input.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.name = 'model_1' # \"model_1 : rename as you like\"\n",
    "model2.name = 'model_2' # \"model_1 : rename as you like\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model1.layers:\n",
    "    layer.name = 'model1_' + layer.name\n",
    "    \n",
    "for layer in model2.layers:\n",
    "    layer.name = 'model2_' + layer.name\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9bee99c42aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model1.input.layer.name = 'model1_' + model1.input.name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model2.input.layer.name = 'model2_' + model2.input.name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "# model1.input.layer.name = 'model1_' + model1.input.name \n",
    "# model2.input.layer.name = 'model2_' + model2.input.name \n",
    "# model1.input.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dropout_6', 'lstm_5', 'lstm_6', 'dense_3'],\n",
       " ['dropout_6', 'lstm_5', 'lstm_6', 'dense_3'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.name for l in model1.layers],[l.name for l in model2.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "A1 = Input(shape=(30,),name='A1')\n",
    "A2 = Dense(8, activation='relu',name='A2')(A1)\n",
    "A3 = Dense(30, activation='relu',name='A3')(A2)\n",
    "\n",
    "B2 = Dense(40, activation='relu',name='B2')(A2)\n",
    "B3 = Dense(30, activation='relu',name='B3')(B2)\n",
    "\n",
    "merged = Model(inputs=[A1],outputs=[A3,B3])\n",
    "plot_model(merged,to_file='demo.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "\n",
    "# input1 = keras.layers.Input(shape=(16,))\n",
    "# x1 = keras.layers.Dense(8, activation='relu')(input1)\n",
    "# input2 = keras.layers.Input(shape=(32,))\n",
    "# x2 = keras.layers.Dense(8, activation='relu')(input2)\n",
    "# # equivalent to added = keras.layers.add([x1, x2])\n",
    "# added = keras.layers.Add()([x1, x2])\n",
    "\n",
    "# out = keras.layers.Dense(4)(added)\n",
    "# model = keras.models.Model(inputs=[input1, input2], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1 = [layer.output for layer in model1.layers]          # all layer outputs 1\n",
    "outputs2 = [layer.output for layer in model2.layers]          # all layer outputs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"dropout_6_input\" is used 2 times in the model. All layer names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ddb2230b1539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmergedLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmergedModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmergedLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 241\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1521\u001b[0m             raise ValueError('The name \"' + name + '\" is used ' +\n\u001b[1;32m   1522\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m                              \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m                              'All layer names should be unique.')\n\u001b[1;32m   1525\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnetwork_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"dropout_6_input\" is used 2 times in the model. All layer names should be unique."
     ]
    }
   ],
   "source": [
    "mergedLayer = keras.layers.Average()([outputs1[-1], outputs2[-1]])\n",
    "mergedModel = keras.models.Model(inputs=[model1.input, model2.input], outputs=mergedLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'getLayers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3684b6b44ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'getLayers'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# Testing\n",
    "test = np.random.random(input_shape)[np.newaxis,...]\n",
    "layer_outs = [func([test, 1.]) for func in functors]\n",
    "print layer_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relativeTo3BaricentersOfVideo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bba53db41977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"keypoint_rcnn_X_101_32x8d_FPN_3x\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodelToContinueTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-3L-CuDNNLSTM-HU_64-LR_0.017-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.15-reg-0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreprocess_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremoveZerosFromDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelativeTo3BaricentersOfVideo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalizeVideos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfolderToTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cross_subject/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'relativeTo3BaricentersOfVideo' is not defined"
     ]
    }
   ],
   "source": [
    "# # \"det-3L-cuda-HU_64-LR_0,017-OFF_0,001-POW_1,5-rimoz_0-3BAR-norm-drop-0,15\"\n",
    "# MODEL_NAME = \"keypoint_rcnn_X_101_32x8d_FPN_3x\"\n",
    "# modelToContinueTrain = MODEL_NAME+\"-3L-CuDNNLSTM-HU_64-LR_0.017-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.15-reg-0\"\n",
    "# preprocess_functions = [removeZerosFromDataset,relativeTo3BaricentersOfVideo,normalizeVideos]\n",
    "\n",
    "# folderToTrain = \"Cross_subject/\"\n",
    "# CONFIGURATION_TO_CONTINUE_TRAIN = [(folderToTrain, modelToContinueTrain)]\n",
    "\n",
    "# PATIENCE = 100\n",
    "# EPOCHS = 50000\n",
    "# BATCH_SIZE = 600\n",
    "        \n",
    "# LEARNING_RATE = 0.005\n",
    "# USE_SCHEDULER = False\n",
    "# ###### POLYNOMIAL SCHEDULER #############\n",
    "# LR_OFFSET = 0.000\n",
    "# LR_POWER = 1\n",
    "# def polynomialScheduler(epoch, lr):\n",
    "#     decay = (1 - (epoch / float(EPOCHS)))  ** LR_POWER\n",
    "#     alpha = LEARNING_RATE * decay\n",
    "#     return float(alpha) + LR_OFFSET\n",
    "# scheduler = polynomialScheduler\n",
    "# ##########################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "# from keras import models #, layers\n",
    "# from keras.layers import LSTM, CuDNNLSTM, Dropout, Dense #, Concatenate \n",
    "# from keras.models import load_model #, Model\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras.regularizers import l2 #, l1\n",
    "# from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "# from os import scandir\n",
    "# from os.path import exists, basename\n",
    "# import shutil \n",
    "# import math\n",
    "# from numpy.random import seed\n",
    "# from tensorflow import set_random_seed \n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import random as rn\n",
    "# from keras import backend as K\n",
    "# import os\n",
    "\n",
    "\n",
    "# # earlyStop = EarlyStopping(monitor='val_acc', ## 4 COLAB \n",
    "# earlyStop = EarlyStopping(monitor='val_accuracy', \n",
    "#                           min_delta=0, \n",
    "#                           patience=PATIENCE, \n",
    "#                           verbose=1, \n",
    "#                           mode='max', \n",
    "#                           baseline=None, \n",
    "#                           restore_best_weights=True)\n",
    "\n",
    "# for idx_configuration, (folderToTrain,modelToTrain) in enumerate(CONFIGURATION_TO_CONTINUE_TRAIN):\n",
    "#     print(\"######## {}/{} - {} - {} ########\".format(idx_configuration, len(CONFIGURATION_TO_CONTINUE_TRAIN),cleanForExcel(modelToTrain),folderToTrain))\n",
    "\n",
    "#     folderPathWhereToSave = SAVED_MODEL_FOLDER+folderToTrain\n",
    "#     if not exists(folderPathWhereToSave+modelToTrain+\".h5\"):\n",
    "#         print(\"model {} not existend in folder {}\".format(modelToTrain,folderToTrain))\n",
    "#         continue\n",
    "          \n",
    "#     alreadyTrainedModel = [f for f in scandir(folderPathWhereToSave) if f.path.endswith(\".h5\")]\n",
    "    \n",
    "#     saveFileName = modelToTrain+\"-THEN_LR_\"+str(LEARNING_RATE)\n",
    "          \n",
    "#     if saveFileName+\".h5\" in [m.name for m in alreadyTrainedModel]:\n",
    "#         print(\"### already done! ####\")\n",
    "#         continue\n",
    "#     else:\n",
    "#         #to avoid that someone else will start the same fitting\n",
    "#         print(\"touching\",folderPathWhereToSave+saveFileName+\".h5\")\n",
    "#         modelFileName = saveFileName+\".h5\"\n",
    "\n",
    "# #       pathToTouch = (folderPathWhereToSave+modelFileName).replace(\" \",\"\\ \") ## 4 COLAB \n",
    "#         modelFileNamePath = folderPathWhereToSave+modelFileName\n",
    "#         !touch $modelFileNamePath\n",
    "#         print(\"## To be saved in [...]{} ###\".format(folderPathWhereToSave[54:]))\n",
    "\n",
    "#     ### LOADING DATASET ###\n",
    "#     if folderPathWhereToSave.endswith(\"Senesi/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT-SENESI-dataset.pickle\"\n",
    "#     elif folderPathWhereToSave.endswith(\"top-models/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT-dataset.pickle\"      \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_subject_test/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TEST-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_view_test/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TEST-dataset.pickle\"     \n",
    "\n",
    "#     elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_subject/\",\"Cross_subject_lrScan/\"]]):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT-dataset.pickle\"       \n",
    "#     elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_view/\",\"Cross_view_lrScan/\"]]):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW-dataset.pickle\"  \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_view_tough/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TOUGH-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_subject_tough/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TOUGH-dataset.pickle\" \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_view_mini/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_MINI-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_subject_mini/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_MINI-dataset.pickle\"    \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_view/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TOP+SENESI-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_subject/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TOP+SENESI-dataset.pickle\" \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset)/\") and MODEL_NAME == \"PoseNet-101\":\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset.pickle\"\n",
    "#     else:\n",
    "#         raise Exception(\"result folder not correct\")\n",
    "\n",
    "#     ### CHECK IF ALREADY PREPROCESSED DATASET EXISTS\n",
    "#     preprocessed_datasetName = basename(datasetName).replace(\"-dataset.pickle\",\"\")\n",
    "#     for f in preprocess_functions:\n",
    "#         preprocessed_datasetName += \"-\"+f.__name__\n",
    "#     preprocessed_datasetName += \"-dataset.pickle\"\n",
    "\n",
    "#     preprocessed_datasetPath = DATASET_FOLDER+preprocessed_datasetName\n",
    "\n",
    "#     if exists(preprocessed_datasetPath):\n",
    "#         print(\"#### Loading preprocessed dataset: \", preprocessed_datasetPath)\n",
    "#         with open(preprocessed_datasetPath,'rb') as file_in:\n",
    "#             prepDict = pickle.load(file_in)\n",
    "#             X_train = prepDict[\"X_train\"]\n",
    "#             y_train = prepDict[\"y_train\"]\n",
    "#             X_val = prepDict[\"X_val\"]\n",
    "#             y_val = prepDict[\"y_val\"]\n",
    "#             X_test = prepDict[\"X_test\"]\n",
    "#             y_test = prepDict[\"y_test\"]\n",
    "#             encodingLabels = prepDict[\"encodingLabels\"]\n",
    "#     else:\n",
    "#         print(\"#### Loading dataset: \", datasetName)\n",
    "#         train_set, val_set, test_set = getData(datasetName)\n",
    "#         print(\"Preproccesing dataset...\")\n",
    "#         X_train, y_train, X_val, y_val, X_test, y_test, encodingLabels = preprocessData(train_set, \n",
    "#                                                                                        val_set, \n",
    "#                                                                                        test_set,  \n",
    "#                                                                                        preprocess_functions)\n",
    "\n",
    "#     # TO SOLVE THE DROPOUT LAYER SHAPE PROBLEM\n",
    "#     missing_train = (BATCH_SIZE-(X_train.shape[0]%BATCH_SIZE))%BATCH_SIZE\n",
    "#     X_train = np.concatenate((X_train,X_train[:missing_train]),axis=0)\n",
    "#     y_train = np.concatenate((y_train,y_train[:missing_train]),axis=0)\n",
    "\n",
    "#     ### DEFINING MODEL ###\n",
    "#     inputDim = (X_train.shape[1], X_train.shape[2])\n",
    "#     outputLen = len(y_train[0])\n",
    "\n",
    "#     ## callbacks and checkpoints\n",
    "#     minLossModelName = \"{}-min_val_loss.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "#     checkpointLoss = ModelCheckpoint(minLossModelName, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#     maxAccModelName = \"{}-max_val_acc.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "\n",
    "#     checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') \n",
    "# #   checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_acc', verbose=1, save_best_only=True, mode='max') ## 4 COLAB \n",
    "\n",
    "\n",
    "#     callbacks_list = [checkpointLoss, checkpointAcc]\n",
    "\n",
    "#     if USE_SCHEDULER:\n",
    "#         callbacks_list.append(LearningRateScheduler(scheduler, verbose=1))\n",
    "#     else:\n",
    "#         callbacks_list.append(earlyStop)\n",
    "\n",
    "            \n",
    "#     model = load_model(folderPathWhereToSave+modelToTrain+\".h5\")\n",
    "\n",
    "#     rmpsprop = RMSprop(lr=LEARNING_RATE, rho=0.9) \n",
    "\n",
    "#     model.compile(\n",
    "# #               optimizer='rmsprop',\n",
    "#                 optimizer=rmpsprop,\n",
    "#                 loss='categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#     ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "#     if exists(minLossModelName):\n",
    "#         print(\"#### Loading weights from MIN LOSS model\")\n",
    "#         model.load_weights(minLossModelName)\n",
    "\n",
    "#     ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "#     minLossBackupModelName = \"{}-min_val_loss-BACKUP.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "#     if exists(maxAccModelName):\n",
    "#         print(\"#### Loading weights from MAX ACCURACY model\")\n",
    "#         model.load_weights(minLossModelName)\n",
    "#         if exists(minLossModelName):\n",
    "#             print(\"#### BACKUP of weights for previous MIN LOSS model\")\n",
    "#             shutil.copyfile(minLossModelName,minLossBackupModelName)\n",
    "\n",
    "\n",
    "#     ## FIT ###    \n",
    "#     model_history = model.fit(X_train, y_train,\n",
    "#                         epochs=EPOCHS,\n",
    "#                         batch_size=BATCH_SIZE,\n",
    "#                         callbacks=callbacks_list,\n",
    "#                         validation_data=(X_val, y_val)\n",
    "#                        )\n",
    "\n",
    "#     ### SAVE MODEL ###\n",
    "#     model.save(folderPathWhereToSave+saveFileName+\".h5\")\n",
    "\n",
    "#     ### SAVE HISTORY AND PREPROCESS FUNCTIONS ###\n",
    "#     env_functions = [one_hot_encoding, \n",
    "#                       euclDistance,\n",
    "#                       paddingTrainValTest, \n",
    "#                       getClosestNonZeroCoordinate,\n",
    "#                       removeZerosFromVideo,\n",
    "#                       getZeroStatsForDataset,\n",
    "#                       preprocessData,\n",
    "#                      ]\n",
    "\n",
    "#     historyToSave = {\n",
    "#         \"acc\" : model_history.history['accuracy'],\n",
    "#         \"val_acc\" : model_history.history['val_accuracy'],\n",
    "#         \"loss\" : model_history.history['loss'],\n",
    "#         \"val_loss\" : model_history.history['val_loss']\n",
    "#     }\n",
    "\n",
    "\n",
    "#     info_to_save = {\"history\": historyToSave,\n",
    "#                     \"env_fun_DILL\":[dill.dumps(x) for x in env_functions],\n",
    "#                     \"spec_fun_DILL\":[dill.dumps(x) for x in preprocess_functions]}\n",
    "\n",
    "#     info_to_save[\"loaded_from\"] = folderPathWhereToSave+modelToTrain\n",
    "\n",
    "#     with open(folderPathWhereToSave+saveFileName+\".pickle\",\"wb\") as handle:\n",
    "#         pickle.dump(info_to_save, handle) \n",
    "#         print(\"## Saved in {} ###\\n\\n\".format(folderPathWhereToSave+saveFileName+\".pickle\"))\n",
    "\n",
    "\n",
    "#     ### EVALUATING MODEL ### \n",
    "#     model = load_model(maxAccModelName)\n",
    "#     !mv $maxAccModelName $modelFileNamePath\n",
    "#     val_acc, test_acc, y_val_true, y_val_pred, y_test_true, y_test_pred = getValTestAccuracy(model,X_val,y_val,X_test,y_test, encodingLabels)\n",
    "#     print(\"Model for MAX ACCURACY test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc*100,val_acc*100))\n",
    "\n",
    "#     if exists(minLossModelName):\n",
    "#         model_minLoss = load_model(minLossModelName)\n",
    "#         val_acc_minLoss, test_acc_minLoss, y_val_true, y_val_pred_minLoss, y_test_true, y_test_pred_minLoss = getValTestAccuracy(model_minLoss,X_val,y_val,X_test,y_test,encodingLabels)\n",
    "#         print(\"Model for MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc_minLoss*100,val_acc_minLoss*100))\n",
    "#     else:\n",
    "#         print(\"Model for MIN LOSS NOT SAVED\")\n",
    "#         val_acc_minLoss = math.inf\n",
    "\n",
    "#     if exists(minLossBackupModelName):\n",
    "#         model_minLoss_b = load_model(minLossBackupModelName)\n",
    "#         print(\"#### Evaluating BACKUP min loss model ####\")\n",
    "#         val_acc_minLoss_b, test_acc_minLoss_b, y_val_true, y_val_pred_minLoss_b, y_test_true, y_test_pred_minLoss_b = getValTestAccuracy(model_minLoss_b,X_val,y_val,X_test,y_test,encodingLabels)\n",
    "#         print(\"Model for BACKUP MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc_minLoss_b*100,val_acc_minLoss_b*100))\n",
    "#         if (val_acc_minLoss_b < val_acc_minLoss):\n",
    "#             print(\"### keeping BACKUP MIN LOSS model ####\")\n",
    "#             val_acc_minLoss, test_acc_minLoss, y_val_pred_minLoss, y_test_pred_minLoss = val_acc_minLoss_b, test_acc_minLoss_b, y_val_pred_minLoss_b, y_test_pred_minLoss_b\n",
    "#             !mv $minLossBackupModelName $minLossModelName\n",
    "#         else:\n",
    "#             !rm $minLossBackupModelName\n",
    "\n",
    "\n",
    "#     ### SAVING RESULTS ###\n",
    "#     if EPOCHS < 10:\n",
    "#         print(\"## SKIPPING SAVING. EPOCHS < 11\")\n",
    "#         continue\n",
    "\n",
    "#     if exists(folderPathWhereToSave+\"summaryResults.pickle\"):\n",
    "#         print(\"Loading previous results...\")\n",
    "#         with open(folderPathWhereToSave+\"summaryResults.pickle\",\"rb\") as handle:\n",
    "#                 results = pickle.load(handle)\n",
    "#     else:\n",
    "#         results = []\n",
    "\n",
    "#     results.append({\"val_acc\": val_acc, \n",
    "#                     \"test_acc\": test_acc, \n",
    "#                     \"model_name\": saveFileName, \n",
    "#                     \"y_val_true\": y_val_true,\n",
    "#                     \"y_val_pred\": y_val_pred,\n",
    "#                     \"y_test_true\": y_test_true,\n",
    "#                     \"y_test_pred\": y_test_pred,\n",
    "\n",
    "#                     \"val_acc_minLoss\": val_acc_minLoss, \n",
    "#                     \"test_acc_minLoss\": test_acc_minLoss, \n",
    "#                     \"y_val_pred_minLoss\": y_val_pred_minLoss,\n",
    "#                     \"y_test_pred_minLoss\": y_test_pred_minLoss\n",
    "#                    })\n",
    "\n",
    "#     print(\"Dumping results...\")\n",
    "#     with open(folderPathWhereToSave+\"summaryResults.pickle\",\"wb\") as handle:\n",
    "#         pickle.dump(results, handle)\n",
    "\n",
    "# print(\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping results on  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/keypoint_rcnn_X_101_32x8d_FPN_3x-CROSS_SUBJECT-removeZerosFromDataset-relativeTo5BaricentersNTURGBofVideo-normalizeVideos-dataset.pickle\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# from os.path import exists, basename\n",
    "# newDatasetName = basename(datasetName).replace(\"-dataset.pickle\",\"\")\n",
    "# for f in preprocess_functions:\n",
    "#     newDatasetName += \"-\"+f.__name__\n",
    "# newDatasetName += \"-dataset.pickle\"\n",
    "\n",
    "# newDatasetPath = DATASET_FOLDER+newDatasetName\n",
    "# newDatasetPath\n",
    "# print(\"Dumping results on \",newDatasetPath)\n",
    "# with open(newDatasetPath,\"wb\") as handle:\n",
    "#     pickle.dump({\"X_train\": X_train,\n",
    "#                  \"y_train\": y_train,\n",
    "#                  \"X_val\": X_val,\n",
    "#                  \"y_val\": y_val, \n",
    "#                  \"X_test\": X_test,\n",
    "#                  \"y_test\": y_test, \n",
    "#                  \"encodingLabels\": encodingLabels}, handle)\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.delete();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript \n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_6 (Dropout)          (None, 251, 68)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 64)                34304     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 34,824\n",
      "Trainable params: 34,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from keras import models #, layers\n",
    "from keras.layers import LSTM, CuDNNLSTM, Dropout, Dense #, Concatenate \n",
    "from keras.models import load_model #, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l2 #, l1\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "# import random\n",
    "from os import scandir\n",
    "from os.path import exists\n",
    "import shutil \n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed \n",
    "\n",
    "# setting SEED in order to initialize the networks always in the same way\n",
    "seed(2)\n",
    "set_random_seed(2)\n",
    "\n",
    "USE_LSTM = False\n",
    "USE_CuDNNLSTM = not USE_LSTM\n",
    "LSTM_LAYERS = 1\n",
    "HIDDEN_UNITS = 64\n",
    "### inputDim (251, 68)\n",
    "# 122 4L -> 335k\n",
    "# 155 3L -> 334k\n",
    "# 256 2L -> 336k\n",
    "\n",
    "### inputDim (251, 17*16)\n",
    "# 122 4L -> 434k\n",
    "# 155 3L -> 461k\n",
    "# 256 2L -> 545k\n",
    "\n",
    "DROPOUT = 0\n",
    "RECURRENT_DROPOUT = 0\n",
    "regularizer = 0\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 80\n",
    "inputDim = (251, 68) # Mini\n",
    "outputLen = 8\n",
    "\n",
    "# inputDim = (300, 68) # 60 azioni\n",
    "# outputLen = 60\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Dropout(DROPOUT, input_shape=inputDim, noise_shape=(BATCH_SIZE, 1, inputDim[1])))\n",
    "\n",
    "if USE_LSTM:\n",
    "    if LSTM_LAYERS == 1:\n",
    "        model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT))\n",
    "    else:       \n",
    "        model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT, return_sequences=True))\n",
    "        for layerIdx in range(2, LSTM_LAYERS):\n",
    "            model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT, return_sequences=True))\n",
    "        model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT))    \n",
    "\n",
    "elif USE_CuDNNLSTM:\n",
    "    reg=l2(regularizer) if regularizer > 0 else None\n",
    "\n",
    "    if LSTM_LAYERS == 1:\n",
    "        model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer = reg))\n",
    "    else:\n",
    "        model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer = reg, return_sequences=True))\n",
    "        for layerIdx in range(2, LSTM_LAYERS):\n",
    "            model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer = reg, return_sequences=True))                  \n",
    "        model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer=reg))\n",
    "\n",
    "\n",
    "model.add(Dense(outputLen, activation='softmax'))\n",
    "\n",
    "rmpsprop = RMSprop(learning_rate=LEARNING_RATE, rho=0.9)\n",
    "\n",
    "model.compile(\n",
    "#                                 optimizer='rmsprop',\n",
    "            optimizer=rmpsprop,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight1 = model.get_weights()\n",
    "weight2 = model.get_weights()\n",
    "# for layer in model.layers:\n",
    "#     weights = layer.get_weights() # list of numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing accessories file for low results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os.path import isfile, isdir, join, exists,getsize,basename\n",
    "# from os import scandir\n",
    "# import pickle\n",
    "\n",
    "# NUMBER_OF_BEST_MODEL_TO_SAVE = 20\n",
    "\n",
    "# SAVED_MODEL_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/\"\n",
    "# # SAVED_MODEL_FOLDER += \"Senesi/\"\n",
    "# # SAVED_MODEL_FOLDER += \"top-models/\"\n",
    "# SAVED_MODEL_FOLDER += \"Cross_view_mini/\"\n",
    "# # SAVED_MODEL_FOLDER += \"Cross_subject_mini/\"\n",
    "\n",
    "\n",
    "# accessoryFileList = [f.path for f in scandir(SAVED_MODEL_FOLDER) \n",
    "#                        if f.path.endswith(\".pickle\") \n",
    "#                        and \"summaryResult\" not in basename(f)]\n",
    "\n",
    "# with open(SAVED_MODEL_FOLDER+\"summaryResults.pickle\",\"rb\") as handle:\n",
    "#         loadedResults = pickle.load(handle)\n",
    "        \n",
    "# loadedResults.sort(key=lambda x : x[\"test_acc\"], reverse=True)\n",
    "# assert NUMBER_OF_BEST_MODEL_TO_SAVE > 10\n",
    "# bestModels = [r['model_name'] for r in loadedResults[:NUMBER_OF_BEST_MODEL_TO_SAVE]]\n",
    "\n",
    "# for accessoryFile in accessoryFileList:\n",
    "#     modelNameToCheck = basename(accessoryFile).replace(\".pickle\",\"\")\n",
    "#     if modelNameToCheck not in bestModels:\n",
    "#         print(\"Removing\",accessoryFile)\n",
    "#         !rm $accessoryFile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
