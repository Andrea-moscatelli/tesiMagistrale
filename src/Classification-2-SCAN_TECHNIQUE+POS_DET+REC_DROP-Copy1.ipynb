{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/students_home/amoscatelli/.local/bin:/data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/bin:/data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/local/cuda/bin:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# PROJECT_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis\"\n",
    "# os.environ['PATH'] = \"/sbin:/bin:/usr/bin:/usr/local/bin:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin\"\n",
    "# os.environ['PATH'] = PROJECT_FOLDER+\"/miniconda3/bin:\" + os.environ['PATH'] \n",
    "os.environ['PATH'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# with tf.device(\"/GPU:0\"):\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Almost) Reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/students_home/amoscatelli/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/fchollet/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=32, inter_op_parallelism_threads=32)\n",
    "# session_conf = tf.ConfigProto()\n",
    "session_conf.gpu_options.allow_growth = True\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# import tensorflow as tf\n",
    "# # import os\n",
    "# # with tf.device(\"/GPU:0\"):\n",
    "# # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.python.client import device_lib\n",
    "# # gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# # tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# # config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "#                                     # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and count zero's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "def getData(datasetName):\n",
    "    with open(datasetName,'rb') as file_in:\n",
    "#         features, labels, setups, cameras, performers, replications = pickle.load(file_in)\n",
    "        train_set, val_set, test_set = pickle.load(file_in)\n",
    "    \n",
    "    #### stats ################################\n",
    "    labels = [\"train_set\", \"val_set\", \"test_set\"]\n",
    "    for i,dataset in enumerate([train_set, val_set, test_set]):\n",
    "        totalsize, zero_elements =  getZeroStatsForDataset(dataset[0])\n",
    "        print(\"{} shape: {}\".format(labels[i], dataset[0].shape))\n",
    "        print(\"{} zero elements: {}/{} ({:.2}%)\".format(labels[i],zero_elements,totalsize,zero_elements*100/totalsize))\n",
    "        \n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def getZeroStatsForDataset(X):\n",
    "    totalsize = sum([len(x)*len(x[0])*2 for x in X])\n",
    "    non_zero_elements = sum([np.count_nonzero(x) for x in X])\n",
    "    zero_elements = totalsize - non_zero_elements\n",
    "    return totalsize, zero_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it removes the zeros from the dataset features taking for each video the closest non-zero value \n",
    "def removeZerosFromDataset(X):\n",
    "    print(\"removing zeros from dataset\")\n",
    "    for i,video in enumerate(X):\n",
    "        if sum([np.count_nonzero(frame==0) for frame in video])>0:\n",
    "#             print(\"removing zeros from video\", i)\n",
    "            removeZerosFromVideo(video)\n",
    "    return X\n",
    "    \n",
    "# return the closest non zero point for the passed point\n",
    "def getClosestNonZeroCoordinate(frameIdx, point, features):\n",
    "    for hop in range(1,len(features)):\n",
    "        previousIdx = max(0, frameIdx-hop)\n",
    "        nextIdx = min(len(features)-1, frameIdx+hop)\n",
    "        if all(features[previousIdx][point] != 0):\n",
    "            return features[previousIdx][point]\n",
    "        if all(features[nextIdx][point] != 0):\n",
    "            return features[nextIdx][point]\n",
    "    return [0.0,0.0] #in case that point is never found in the video\n",
    "        \n",
    "# it removes the zeros from the video features taking the closest non-zero values for each point\n",
    "def removeZerosFromVideo(videoFeatures):\n",
    "    # retrieving the index of the points which contain 0 values for each frame \n",
    "    zeroPoints = [list(set(np.where(frame == 0.)[0])) for frame in videoFeatures] \n",
    "    \n",
    "    # concatenating the previous result with the frame index (discarding correct frames)\n",
    "    zeroPointsCoordinates = [(i,p) for i,p in enumerate(zeroPoints) if len(p)>0]\n",
    "    \n",
    "    oldVideo = np.copy(videoFeatures)\n",
    "    notFoundPoints = set()\n",
    "    for frameIdx, pointCoordinates in zeroPointsCoordinates:\n",
    "        for pointIdx in pointCoordinates:\n",
    "            if pointIdx in notFoundPoints:\n",
    "                videoFeatures[frameIdx][pointIdx] = [0.0,0.0]\n",
    "            else:\n",
    "                videoFeatures[frameIdx][pointIdx] = getClosestNonZeroCoordinate(frameIdx, pointIdx,oldVideo)\n",
    "            \n",
    "            if np.count_nonzero(videoFeatures[frameIdx][pointIdx]) == 0:\n",
    "                notFoundPoints.add(pointIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def one_hot_encoding(labels):\n",
    "    encoder = LabelBinarizer()\n",
    "    label_strings = [str(i) for i in labels]\n",
    "    oneHotLabels = encoder.fit_transform(label_strings)\n",
    "    print('classes order:', encoder.classes_) \n",
    "    return oneHotLabels, encoder.classes_\n",
    "    \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def paddingTrainValTest(X_train, X_val, X_test, maxLength=None):\n",
    "    if maxLength is None:\n",
    "         maxLength = max([len(s) for s in np.concatenate((X_train, X_val, X_test), axis=0)])\n",
    "    \n",
    "    # 17 if there is always only 1 person, 34 if there are videos with 2 people\n",
    "    maxVideoHeigth = max([len(s[0]) for s in np.concatenate((X_train, X_val, X_test), axis=0)])\n",
    "    \n",
    "    for dataset in [X_train, X_val, X_test]:\n",
    "        for i in range(len(dataset)):\n",
    "            if dataset[i].shape[1] < maxVideoHeigth:\n",
    "                videoShape = dataset[i].shape\n",
    "                missingPart = (videoShape[0], maxVideoHeigth-videoShape[1], videoShape[2])\n",
    "#                 dataset[i] = np.concatenate((dataset[i],np.zeros(dataset[i].shape)),axis=1)\n",
    "                dataset[i] = np.concatenate((dataset[i], np.zeros(missingPart)), axis=1)\n",
    "    \n",
    "    \n",
    "    X_train = pad_sequences(X_train, maxlen=maxLength, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "    X_val = pad_sequences(X_val, maxlen=maxLength, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "    X_test = pad_sequences(X_test, maxlen=maxLength, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "    \n",
    "    ### stats ######################################\n",
    "    labels = [\"train set\", \"val set\", \"test set\"]\n",
    "    for i, dataset in enumerate([X_train, X_val, X_test]):\n",
    "        totalsize, zero_elements =  getZeroStatsForDataset(dataset)\n",
    "        print(\"{} shape: {}\".format(labels[i], dataset.shape))\n",
    "        print(\"{} zero elements (after padding): {} ({:.2f}%)\".format(labels[i],zero_elements,zero_elements*100/totalsize))\n",
    "    \n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normaliseBeforePadding(X_train, X_val, X_test):\n",
    "#     print(\"!!!! That's not correct. It normalize the datasets all in one. You should normalize each video indipendently.\")\n",
    "#     trainAndVal = np.concatenate((X_train, X_val), axis=0)\n",
    "#     print(\"normalising train, val and test values BEFORE padding\")\n",
    "#     trainMean = np.vstack(trainAndVal).mean() # the mean and std must be calculated only on the training data\n",
    "#     trainStd = np.vstack(trainAndVal).std()\n",
    "#     normalized_X_train = np.array([(x - trainMean)/trainStd for x in X_train])\n",
    "#     normalized_X_val = np.array([(x - trainMean)/trainStd for x in X_val])\n",
    "#     normalized_X_test = np.array([(x - trainMean)/trainStd for x in X_test])\n",
    "\n",
    "#     return normalized_X_train, normalized_X_val, normalized_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeVideosXYInpid(dataset):\n",
    "    print(\"normalising EACH VIDEO, considering x and y INDIPENDENTLY\")\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        xAndYVideoMean = np.mean(np.vstack(dataset[i]),axis=0)\n",
    "        xAndYVideoStd = np.std(np.vstack(dataset[i]),axis=0)\n",
    "        dataset[i] = (dataset[i]-xAndYVideoMean)/xAndYVideoStd\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeVideos(dataset):\n",
    "    print(\"normalising EACH VIDEO, considering x and y TOGETHER\")\n",
    "    for i in range(len(dataset)):\n",
    "        videoMean = np.mean(np.vstack(dataset[i]))\n",
    "        videoStd = np.std(np.vstack(dataset[i]))\n",
    "        dataset[i] = (dataset[i]-videoMean)/videoStd\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posenet predicts:\n",
    "# 1 - nose             18\n",
    "# 2 - leftEye          19\n",
    "# 3 - rightEye         20\n",
    "# 4 - leftEar          21\n",
    "# 5 - rightEar         22\n",
    "\n",
    "# 6 - leftShoulder     23\n",
    "# 7 - rightShoulder    24\n",
    "# 8 - leftElbow        25\n",
    "# 9 - rightElbow       26\n",
    "# 10 - leftWrist       27\n",
    "# 11 - rightWrist      28\n",
    "\n",
    "# 12 - leftHip         29\n",
    "# 13 - rightHip        30\n",
    "# 14 - leftKnee        31\n",
    "# 15 - rightKnee       32\n",
    "# 16 - leftAnkle       33\n",
    "# 17 - rightAnkle      34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeToVideoCenter(X):\n",
    "    print(\"Adapting the data to the CENTER of each VIDEO\")\n",
    "    for i,frames in enumerate(X):\n",
    "        # calculating the center of the whole video\n",
    "        videoMean = np.mean([np.mean(features,axis=0) for features in frames], axis = 0) \n",
    "        X[i] = [frame-videoMean for frame in frames]\n",
    "\n",
    "    return X\n",
    "\n",
    "def relativeToPersonVideoCenter(X):\n",
    "    print(\"Adapting the data to the video PERSON CENTER of each VIDEO\")\n",
    "    for i,frames in enumerate(X):\n",
    "        # calculating the center of the frames points relative to the whole video\n",
    "        videoMean = np.mean([np.mean(features[:17],axis=0) for features in frames], axis = 0) \n",
    "\n",
    "        if len(frames[0]) == 34:\n",
    "            videoMean2 = np.mean([np.mean(features[17:],axis=0) for features in frames], axis = 0) \n",
    "            videoMean = np.vstack((videoMean, videoMean2)) \n",
    "            videoMean = np.repeat(videoMean, [17, 17], axis=0)\n",
    "        \n",
    "        X[i] = [frame-videoMean for frame in frames]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeToFrameCenter(X):\n",
    "    print(\"Adapting the data to the CENTER of each FRAME\")\n",
    "    for i_video, video in enumerate(X):\n",
    "        for i_frame, frame in enumerate(video):\n",
    "            frame_mean = np.mean(frame,axis=0)\n",
    "            X[i_video][i_frame] = frame - frame_mean\n",
    "\n",
    "    return X\n",
    "\n",
    "def relativeToPersonFrameCenter(X):\n",
    "    print(\"Adapting the data to the PERSON CENTER of each FRAME\")\n",
    "    for i_video, video in enumerate(X):\n",
    "        for i_frame, frame in enumerate(video):\n",
    "            frame_mean = np.mean(frame[:17],axis=0)\n",
    "            if len(frame) == 34:\n",
    "                frame_mean2 = np.mean(frame[17:],axis=0)\n",
    "                frame_mean = np.vstack((frame_mean, frame_mean2)) \n",
    "                frame_mean = np.repeat(frame_mean, [17, 17], axis=0)\n",
    "            X[i_video][i_frame] = frame - frame_mean\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[[p[0]+i, p[1]+i]for i,p in enumerate(f)] for f in X_to_test1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER PERSON BARICENTERS\n",
    "def relativeTo5PersonalBaricentersNTURGBofVideo(X):\n",
    "    print(\"Adapting the data to the 5 body PERSONAL BARICENTERS of each video as in NTU-RGB+D\")\n",
    "    for i_video,frames in enumerate(X): \n",
    "        troncoPoints = [0,1,2,3,4,5,6,11,12]\n",
    "        rightArmPoints = [8,10]\n",
    "        leftArmPoints = [7,9]\n",
    "        rightLegPoints = [14,16]\n",
    "        leftLegPoints = [13,15] \n",
    "        videoCenterFrame = np.zeros(frames[0].shape)\n",
    "        for person_offset in range(0,len(frames[0]),17):\n",
    "            troncoPoints = [i+person_offset for i in troncoPoints]\n",
    "            rightArmPoints = [i+person_offset for i in rightArmPoints]\n",
    "            leftArmPoints = [i+person_offset for i in leftArmPoints]\n",
    "            rightLegPoints = [i+person_offset for i in rightLegPoints]\n",
    "            leftLegPoints = [i+person_offset for i in leftLegPoints]\n",
    "            troncoCenter = np.mean(np.mean(np.array(frames)[:,troncoPoints], axis=1),axis=0)\n",
    "            rightArmCenter = np.mean(np.mean(np.array(frames)[:,rightArmPoints], axis=1),axis=0)\n",
    "            leftArmCenter = np.mean(np.mean(np.array(frames)[:,leftArmPoints], axis=1),axis=0)\n",
    "            rightLegCenter = np.mean(np.mean(np.array(frames)[:,rightLegPoints], axis=1),axis=0)\n",
    "            leftLegCenter = np.mean(np.mean(np.array(frames)[:,leftLegPoints], axis=1),axis=0)\n",
    "\n",
    "            videoCenterFrame[troncoPoints] = troncoCenter \n",
    "            videoCenterFrame[rightArmPoints] = rightArmCenter \n",
    "            videoCenterFrame[leftArmPoints] = leftArmCenter \n",
    "            videoCenterFrame[rightLegPoints] = rightLegCenter \n",
    "            videoCenterFrame[leftLegPoints] = leftLegCenter \n",
    "\n",
    "        X[i_video] = frames - videoCenterFrame\n",
    "    return X\n",
    "\n",
    "\n",
    "# GLOBAL BARICENTERS\n",
    "def relativeTo5GlobalBaricentersNTURGBofVideo(X):\n",
    "    print(\"Adapting the data to the 5 body GLOBAL BARICENTERS of each video as in NTU-RGB+D\")\n",
    "    for i_video,frames in enumerate(X): \n",
    "        troncoPoints = [0,1,2,3,4,5,6,11,12]\n",
    "        rightArmPoints = [8,10]\n",
    "        leftArmPoints = [7,9]\n",
    "        rightLegPoints = [14,16]\n",
    "        leftLegPoints = [13,15] \n",
    "        videoCenterFrame = np.zeros(frames[0].shape)\n",
    "        if len(frames[0]) == 34:\n",
    "            person_offset = 17\n",
    "            troncoPoints += [i+person_offset for i in troncoPoints]\n",
    "            rightArmPoints += [i+person_offset for i in rightArmPoints]\n",
    "            leftArmPoints += [i+person_offset for i in leftArmPoints]\n",
    "            rightLegPoints += [i+person_offset for i in rightLegPoints]\n",
    "            leftLegPoints += [i+person_offset for i in leftLegPoints]\n",
    "        troncoCenter = np.mean(np.mean(np.array(frames)[:,troncoPoints], axis=1),axis=0)\n",
    "        rightArmCenter = np.mean(np.mean(np.array(frames)[:,rightArmPoints], axis=1),axis=0)\n",
    "        leftArmCenter = np.mean(np.mean(np.array(frames)[:,leftArmPoints], axis=1),axis=0)\n",
    "        rightLegCenter = np.mean(np.mean(np.array(frames)[:,rightLegPoints], axis=1),axis=0)\n",
    "        leftLegCenter = np.mean(np.mean(np.array(frames)[:,leftLegPoints], axis=1),axis=0)\n",
    "\n",
    "        videoCenterFrame[troncoPoints] = troncoCenter \n",
    "        videoCenterFrame[rightArmPoints] = rightArmCenter \n",
    "        videoCenterFrame[leftArmPoints] = leftArmCenter \n",
    "        videoCenterFrame[rightLegPoints] = rightLegCenter \n",
    "        videoCenterFrame[leftLegPoints] = leftLegCenter \n",
    "\n",
    "        X[i_video] = frames - videoCenterFrame\n",
    "    return X\n",
    "\n",
    "def relativeTo5GlobalBaricentersNTURGBofVideoAbs(X):\n",
    "    print(\"ABSOLUTE VALUES of 5 GLOBAL BARICENTERS\")\n",
    "    return abs(relativeTo5GlobalBaricentersNTURGBofVideo(X))\n",
    "\n",
    "def relativeTo5PersonalBaricentersNTURGBofVideoAbs(X):\n",
    "    print(\"ABSOLUTE VALUES of 5 PERSONAL BARICENTERS\")\n",
    "    return abs(relativeTo5PersonalBaricentersNTURGBofVideo(X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_name = \"keypoint_rcnn_X_101_32x8d_FPN_3x\"\n",
    "# model_name = \"PoseNet-101\"\n",
    "# datasetName = DATASET_FOLDER+model_name+\"-CROSS_SUBJECT_TEST-dataset.pickle\"\n",
    "\n",
    "# train_set, val_set, test_set = getData(datasetName)\n",
    "\n",
    "# train_set[0] = removeZerosFromDataset(train_set[0])\n",
    "# val_set[0] = removeZerosFromDataset(val_set[0])\n",
    "# test_set[0] = removeZerosFromDataset(test_set[0])\n",
    "\n",
    "# labels = [\"train_set\", \"val_set\", \"test_set\"]\n",
    "# for i,dataset in enumerate([train_set, val_set, test_set]):\n",
    "#     totalsize, zero_elements =  getZeroStatsForDataset(dataset[0])\n",
    "#     print(\"{} shape: {}\".format(labels[i], dataset[0].shape))\n",
    "#     print(\"{} zero elements: {}/{} ({:.2}%)\".format(labels[i],zero_elements,totalsize,zero_elements*100/totalsize))\n",
    "\n",
    "    \n",
    "# X_to_test = train_set[0][0]\n",
    "# X_to_test = X_to_test[:2]\n",
    "# X_to_test = np.expand_dims(X_to_test, axis=0)\n",
    "# print(\"X_to_test shape\", X_to_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relativeTo3BaricentersOfFrame(X):\n",
    "#     assert False, \"Va testato\"\n",
    "#     print(\"Adapting the data to the TOP-MIDDLE-BOTTOM center of each frame\")\n",
    "#     for i_video, video in enumerate(X):\n",
    "#         for i_frame, frame in enumerate(video):\n",
    "#             X[i_video][i_frame][:5] = frame[:5] - np.mean(frame[:5], axis=0)\n",
    "#             X[i_video][i_frame][5:11] = frame[5:11] - np.mean(frame[5:11], axis=0)\n",
    "#             X[i_video][i_frame][11:17] = frame[11:17] - np.mean(frame[11:17], axis=0)\n",
    "#             if len(frame) == 34:\n",
    "#                 X[i_video][i_frame][17:22] = frame[17:22] - np.mean(frame[17:22], axis=0)\n",
    "#                 X[i_video][i_frame][22:28] = frame[22:28] - np.mean(frame[22:28], axis=0)\n",
    "#                 X[i_video][i_frame][28:34] = frame[28:34] - np.mean(frame[28:34], axis=0)\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ARTIFICIAL \n",
    "# X_to_test1 = np.ones(2*17*2).reshape((2,17,2)) # 1 person\n",
    "# X_to_test1 = np.asarray([np.asarray([np.asarray([p[0]+i, p[1]+i]) for i,p in enumerate(f)]) for f in X_to_test1])\n",
    "\n",
    "# X_to_test2 = np.ones(3*34*2).reshape((3,34,2)) # 2 people\n",
    "# X_to_test2 = np.asarray([np.asarray([np.asarray([p[0]+i+100, p[1]+i+100]) for i,p in enumerate(f)]) for f in X_to_test2])\n",
    "\n",
    "# # X_to_test3 = np.ones(3*17*2).reshape((3,17,2)) # 1 person\n",
    "# # X_to_test3 = np.asarray([np.asarray([np.asarray([p[0]+i+200, p[1]+i+200]) for i,p in enumerate(f)]) for f in X_to_test3])\n",
    "\n",
    "# # X_to_test = np.asarray([X_to_test1, X_to_test2, X_to_test3])\n",
    "# X_to_test = np.asarray([X_to_test1, X_to_test2])\n",
    "\n",
    "# print(X_to_test)\n",
    "# print(relativeTo3GlobalBaricentersOfVideo(X_to_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeTo3PersonalBaricentersOfVideo(X):\n",
    "    print(\"Adapting the data wrt to the 3 PERSONAL BARICENTERS of each VIDEO\")\n",
    "    \n",
    "    for i_video,frames in enumerate(X):        \n",
    "        videoUpperMeanP1 = np.mean([np.mean(features[:5], axis=0) for features in frames], axis = 0) \n",
    "        videoMiddleMeanP1 = np.mean([np.mean(features[5:11], axis=0) for features in frames], axis = 0) \n",
    "        videoBottomMeanP1 = np.mean([np.mean(features[11:17], axis=0) for features in frames], axis = 0) \n",
    "        if len(frames[0]) == 34:\n",
    "            videoUpperMeanP2 = np.mean([np.mean(features[17:22], axis=0) for features in frames], axis = 0) \n",
    "            videoMiddleMeanP2 = np.mean([np.mean(features[22:28], axis=0) for features in frames], axis = 0) \n",
    "            videoBottomMeanP2 = np.mean([np.mean(features[28:34], axis=0) for features in frames], axis = 0) \n",
    "        \n",
    "        for i_frame, frame in enumerate(frames):\n",
    "            X[i_video][i_frame][:5] = frame[:5] - videoUpperMeanP1\n",
    "            X[i_video][i_frame][5:11] = frame[5:11] - videoMiddleMeanP1\n",
    "            X[i_video][i_frame][11:17] = frame[11:17] - videoBottomMeanP1\n",
    "            if len(frame) == 34:\n",
    "                X[i_video][i_frame][17:22] = frame[17:22] - videoUpperMeanP2\n",
    "                X[i_video][i_frame][22:28] = frame[22:28] - videoMiddleMeanP2\n",
    "                X[i_video][i_frame][28:34] = frame[28:34] - videoBottomMeanP2\n",
    "                \n",
    "    return X\n",
    "\n",
    "def relativeTo3GlobalBaricentersOfVideo(X):\n",
    "    print(\"Adapting the data wrt to the 3 GLOBAL BARICENTERS of each VIDEO\")\n",
    "    \n",
    "    for i_video,frames in enumerate(X):        \n",
    "        upperMean = np.mean([np.mean(features[:5], axis=0) for features in frames], axis = 0) \n",
    "        middleMean = np.mean([np.mean(features[5:11], axis=0) for features in frames], axis = 0) \n",
    "        bottomMean = np.mean([np.mean(features[11:17], axis=0) for features in frames], axis = 0) \n",
    "        if len(frames[0]) == 34:\n",
    "            upperMeanP2 = np.mean([np.mean(features[17:22], axis=0) for features in frames], axis = 0) \n",
    "            middleMeanP2 = np.mean([np.mean(features[22:28], axis=0) for features in frames], axis = 0) \n",
    "            bottomMeanP2 = np.mean([np.mean(features[28:34], axis=0) for features in frames], axis = 0) \n",
    "            upperMean = (upperMean + upperMeanP2)/2.\n",
    "            middleMean = (middleMean+middleMeanP2)/2.\n",
    "            bottomMean = (bottomMean+bottomMeanP2)/2.\n",
    "        \n",
    "        for i_frame, frame in enumerate(frames):\n",
    "            X[i_video][i_frame][:5] = frame[:5] - upperMean\n",
    "            X[i_video][i_frame][5:11] = frame[5:11] - middleMean\n",
    "            X[i_video][i_frame][11:17] = frame[11:17] - bottomMean\n",
    "            if len(frame) == 34:\n",
    "                X[i_video][i_frame][17:22] = frame[17:22] - upperMean\n",
    "                X[i_video][i_frame][22:28] = frame[22:28] - middleMean\n",
    "                X[i_video][i_frame][28:34] = frame[28:34] - bottomMean\n",
    "                \n",
    "    return X\n",
    "\n",
    "def relativeTo3PersonalBaricentersOfVideoAbs(X):\n",
    "    print(\"Adapting the data as the ABSOLUTE values wrt the 3 PERSONAL BARICENTERS of each VIDEO \")\n",
    "    return abs(relativeTo3PersonalBaricentersOfVideo(X))\n",
    "\n",
    "def relativeTo3GlobalBaricentersOfVideoAbs(X):\n",
    "    print(\"Adapting the data as the ABSOLUTE values wrt the 3 GLOBAL BARICENTERS of each VIDEO \")\n",
    "    return abs(relativeTo3GlobalBaricentersOfVideo(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relativeTo17BaricentersOfVideo(X):\n",
    "    print(\"Adapting the data as the difference to the center of EACH KEYPOINT in the VIDEO\")   \n",
    "    for i_video,frames in enumerate(X): \n",
    "        video_mean_by_points = np.mean(X[i_video],axis=0)\n",
    "        X[i_video] = X[i_video] - video_mean_by_points\n",
    "    return X\n",
    "\n",
    "def relativeTo17BaricentersOfVideoAbs(X):\n",
    "    return abs(relativeTo17BaricentersOfVideo(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relativeToNextFrameOLD(X):\n",
    "#     print(\"Adapting the data to the next frame\")\n",
    "#     newX = []\n",
    "#     for frames in X:\n",
    "#         motions = []\n",
    "#         for i in range(len(frames)-1):\n",
    "#             motions.append(np.array(frames[i+1])-np.array(frames[i]))\n",
    "#         newX.append(motions)\n",
    "#     return np.array(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builder function which return a function to calculate the difference each N frames\n",
    "def relativeToNextFrameBuilder(step):\n",
    "    step = step\n",
    "    \n",
    "    # it smooths the dataset following the Savitzky-Golay algorithm\n",
    "    def relativeToNextFrame(X):\n",
    "        print(\"Adapting the data to the next\",step,\"frame\")\n",
    "        newX = []\n",
    "        for frames in X:\n",
    "            # repeat the last frame of the video as much as the number of steps\n",
    "            frames = np.concatenate((frames,np.repeat(np.expand_dims(frames[-1],axis=0),step,axis=0)))\n",
    "            motions = np.array([frames[i+step]-frames[i] for i in range(len(frames)-step-1)])\n",
    "            newX.append(motions)\n",
    "        return np.array(newX)\n",
    "    \n",
    "    if step>1:\n",
    "        relativeToNextFrame.__name__ = \"relativeToNextFrame_\"+str(step)\n",
    "    return relativeToNextFrame\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulativeDifferences(X):\n",
    "        print(\"Adapting the data as the CUMULATIVE DIFFERENCES of consecutive frames\")\n",
    "        newX = []\n",
    "        for frames in X:\n",
    "            motions = frames - frames[0]\n",
    "            newX.append(motions)\n",
    "        return np.array(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euclDistance(point1,point2):\n",
    "    return math.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)\n",
    "\n",
    "def relativeToPointDistances(X):\n",
    "    print(\"Adapting the data to the DISTANCES between points of each person in each FRAME\")\n",
    "    newX = []\n",
    "    for videoIdx,video in enumerate(X):\n",
    "        if videoIdx % 100 == 0:\n",
    "            print(\"{}/{} video done\".format(videoIdx,len(X)))\n",
    "        \n",
    "        videoDistances = np.zeros((len(video),len(video[0]),17))\n",
    "        \n",
    "        for fIdx, frame in enumerate(video):\n",
    "            distances = [[euclDistance(frame[i],frame[j]) for j in range(17)] for i in range(17)]\n",
    "            if len(frame) == 34:\n",
    "                distancesP2 = [[euclDistance(frame[i],frame[j]) for j in range(17,34)] for i in range(17,34)]\n",
    "                distances = np.concatenate((distances,distancesP2),axis = 0)\n",
    "            videoDistances[fIdx] = distances\n",
    "        \n",
    "        newX.append(videoDistances)\n",
    "    return np.array(newX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(train_set, val_set, test_set, preprocess_functions = None):\n",
    "    X_train, X_val, X_test = train_set[0], val_set[0], test_set[0]\n",
    "    # one hot encoding\n",
    "    y_train, encoding_train = one_hot_encoding(train_set[1])\n",
    "    y_val, encoding_val = one_hot_encoding(val_set[1])\n",
    "    y_test, encoding_test = one_hot_encoding(test_set[1])\n",
    "    \n",
    "    assert all(encoding_train == encoding_val)\n",
    "    assert all(encoding_val == encoding_test)\n",
    "\n",
    "    # preprocess\n",
    "    if preprocess_functions is not None:\n",
    "        for preprocess_function in preprocess_functions:\n",
    "            X_train = preprocess_function(X_train)\n",
    "            X_val = preprocess_function(X_val)\n",
    "            X_test = preprocess_function(X_test)\n",
    "\n",
    "    #padding\n",
    "    X_train, X_val, X_test = paddingTrainValTest(X_train, X_val, X_test)\n",
    "\n",
    "    \n",
    "    ## reshaping after padding ###\n",
    "    X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2] * X_train.shape[3])\n",
    "    X_val = X_val.reshape(X_val.shape[0],X_val.shape[1],X_val.shape[2] * X_val.shape[3])\n",
    "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2] * X_test.shape[3])\n",
    "    \n",
    "#     ## reshaping without padding ###\n",
    "#     for dataset in [X_train, X_val, X_test]:\n",
    "#         for i in range(len(dataset)):\n",
    "#             dataset[i] = dataset[i].reshape(dataset[i].shape[0], \n",
    "#                                             dataset[i].shape[1] * dataset[i].shape[2])\n",
    "\n",
    "    encoding_train = [int(i) for i in encoding_train]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, encoding_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "# builder function which returs a Savitzky-Golay smoother function with the passed arguments\n",
    "def smoothingPoints(window, order):\n",
    "    movingWindow = window\n",
    "    polynomialOrder = order\n",
    "    \n",
    "    # it smooths the dataset following the Savitzky-Golay algorithm\n",
    "    def smooth(X):\n",
    "        for vidIdx, video in enumerate(X):\n",
    "            if vidIdx % 500 == 0:\n",
    "                print(\"smooting video {}/{}\".format(vidIdx,len(X)))\n",
    "            for p in range(len(X[0][0])): # X[0][0] == 17 or 34 -> the number of points\n",
    "                x, y = zip(*[(f[p][0], f[p][1]) for f in video])\n",
    "                \n",
    "                #     Savitzky-Golay\n",
    "                smooth_x = signal.savgol_filter(x, movingWindow, polynomialOrder)\n",
    "                smooth_y = signal.savgol_filter(y, movingWindow, polynomialOrder)\n",
    "                \n",
    "                # placing the smoothed series\n",
    "                for i,frame in enumerate(video):\n",
    "                    frame[p] = [smooth_x[i], smooth_y[i]]\n",
    "        return X\n",
    "    \n",
    "    smooth.__name__ = \"smooth_\"+str(window)+\"_\"+str(order)\n",
    "        \n",
    "    return smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from random import gauss\n",
    "\n",
    "def augmentData(dataset, xAxis = None, mirroring = False, std_jittering = 0):\n",
    "    X = dataset[0]\n",
    "    y = dataset[1]\n",
    "    print(\"## OLD LENGHT OF DATSET:\",len(X))\n",
    "    \n",
    "    # check that the X and labels have the same length\n",
    "    assert len(X) == len(y)\n",
    "    \n",
    "    # MIRRORING\n",
    "    if mirroring:\n",
    "        print(\"## Applying MIRRORING to dataset...\")\n",
    "        if xAxis == 0:\n",
    "            mirrX = np.asarray([ np.asarray([ np.asarray([ np.asarray([-p[0],p[1]],dtype=np.float32) for p in f]) for f in v]) for v in X])\n",
    "        elif xAxis == 1:\n",
    "            mirrX = np.asarray([ np.asarray([ np.asarray([ np.asarray([p[0],-p[1]],dtype=np.float32) for p in f]) for f in v]) for v in X])\n",
    "        else:\n",
    "            raise Exception(\"xAxis can be only 0 or 1\")\n",
    "\n",
    "        X = np.concatenate((X,mirrX))\n",
    "        y = np.concatenate((y,y))\n",
    "    \n",
    "    \n",
    "    # JITTERING\n",
    "    if std_jittering > 0:\n",
    "        print(\"## Applying JITTERING to dataset...\")\n",
    "        jitterX = np.asarray([np.asarray([ np.asarray([ \n",
    "                                np.asarray([p[0]+gauss(0,std_jittering), p[1]+gauss(0,std_jittering)], dtype=np.float32) for p in f]) \n",
    "                              for f in v]) for v in X])\n",
    "        \n",
    "        X = np.concatenate((X,jitterX))\n",
    "        y = np.concatenate((y,y))\n",
    "    \n",
    "    print(\"## NEW LENGHT OF DATSET:\",len(X))\n",
    "    return [X,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# a =[1,2,3,4,5,6,7,8,9]\n",
    "# b =[11,12,13,14,15,16,17,18,19]\n",
    "# data = list(zip(a,b))\n",
    "# random.shuffle(data)\n",
    "# [i[0] for i in data[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MIRRORING_VALUES: [False]\n",
      "1 STD_JITTERING_VALUES: [0]\n",
      "NORMAL LSTM\n",
      "2 MODEL_NAME_VALUES: ['keypoint_rcnn_X_101_32x8d_FPN_3x', 'PoseNet-101']\n",
      "2 LSTM_LAYERS_VALUES LAYERS: [3, 2]\n",
      "1 HIDDEN UNITS [64]\n",
      "1 REGULARIZER_VALUES [0]\n",
      "4 DROPOUT_VALUES [0.15, 0.1, 0.2, 0.5]\n",
      "4 PREPROCESS_FUNCTION_TO_TEST\n",
      "\n",
      "!! MERGING TRAIN+VAL !!\n",
      "\n",
      "EPOCHS: 2000\n",
      "REFERENCE_EPOCHS: 300\n",
      "PATIENCE: 100\n",
      "\n",
      "1 LEARNING_RATE_VALUES [0.01]\n",
      "polynomialScheduler\n",
      "LR_OFFSET: 0.001\n",
      "LR_POWER: 2\n",
      "BATCH_SIZE: 2372\n",
      "CONTINUE_TRAINING: None\n",
      "\n",
      "Number of tests: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/',\n",
       " 'Cross_subject/',\n",
       " 'Cross_view/')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVED_MODEL_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/\"\n",
    "DATASET_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/\"\n",
    "\n",
    "# DATASET_FOLDER = \"/content/gdrive/My Drive/actionAnalysis/datasets/\"\n",
    "# SAVED_MODEL_FOLDER = \"/content/gdrive/My Drive/actionAnalysis/savedModels/\"\n",
    "      \n",
    "folder_where_save1 = \"Cross_subject/\"\n",
    "folder_where_save2 = \"Cross_view/\"        \n",
    "\n",
    "# folder_where_save1 = \"Cross_view_lrScan/\"        \n",
    "# folder_where_save1 = \"Cross_subject_lrScan/\"     \n",
    "# folder_where_save2 = \"Cross_subject_lrScan/\"\n",
    "# SCAN_EPOCHS = 10\n",
    "\n",
    "# folder_where_save1 = \"Cross_view_tough/\" \n",
    "# folder_where_save2 = \"Cross_view_tough/\" \n",
    "\n",
    "# folder_where_save1 = \"Cross_subject_tough/\"\n",
    "# folder_where_save2 = \"Cross_view_tough/\"\n",
    "\n",
    "# folder_where_save1 = \"Cross_view_test/\" \n",
    "# folder_where_save2 = \"Cross_subject_test/\"\n",
    "\n",
    "# folder_where_save1 = \"Cross_view_mini/\"     \n",
    "# folder_where_save2 = \"Cross_subject_mini/\"  \n",
    "\n",
    "# folder_where_save1 = \"Senesi/\"\n",
    "# folder_where_save2 = \"Cross_subject/\"\n",
    "\n",
    "# folder_where_save1 = \"Cross_view/\"\n",
    "# folder_where_save2 = \"top-models/\"\n",
    "\n",
    "\n",
    "MODEL_NAME_VALUES = [\n",
    "    \"keypoint_rcnn_X_101_32x8d_FPN_3x\",\n",
    "    \"PoseNet-101\"\n",
    "    ]\n",
    "\n",
    "MERGING_TRAIN_VAL = True\n",
    "\n",
    "CONTINUE_TRAINING = None\n",
    "# CONTINUE_TRAINING = \"keypoint_rcnn_X_101_32x8d_FPN_3x-3L-HU_64-LR_0.01-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-THEN_drop_0.05\"\n",
    "\n",
    "PATIENCE = 100\n",
    "HIDDEN_UNITS_VALUES = [64]\n",
    "\n",
    "#                         [0.04,0.039,0.038,0.037,0.036,0.035,0.034,0.033,0.032,0.031,\n",
    "#                         0.03,0.029,0.028,0.027,0.026,0.025,0.024,0.023,0.022,0.021,\n",
    "#                         0.02,0.019,0.018,0.017,0.016,0.015,0.014,0.013,0.012,0.011,\n",
    "#                         0.01,0.009,0.008,0.007,0.006,0.005,0.004,0.003,0.002,0.001]\n",
    "BATCH_SIZE = 2372\n",
    "REFERENCE_EPOCHS = 300 #the earlystop will eventually stop the training\n",
    "EPOCHS = 2000\n",
    "\n",
    "MIRRORING_VALUES = [False]\n",
    "STD_JITTERING_VALUES = [0]\n",
    "\n",
    "\n",
    "USE_SCHEDULER = True\n",
    "LEARNING_RATE_VALUES = [0.01]\n",
    "\n",
    "###### POLYNOMIAL SCHEDULER #############\n",
    "LR_OFFSET = 0.001\n",
    "LR_POWER = 2\n",
    "def polynomialScheduler(epoch, lr):\n",
    "    if epoch < REFERENCE_EPOCHS:\n",
    "        decay = (1 - (epoch / float(REFERENCE_EPOCHS)))  ** LR_POWER\n",
    "        alpha = LEARNING_RATE * decay\n",
    "        return float(alpha)+LR_OFFSET\n",
    "    else:\n",
    "        return LR_OFFSET\n",
    "scheduler = polynomialScheduler\n",
    "##########################################\n",
    "\n",
    "USE_LSTM = True\n",
    "USE_CuDNNLSTM = not USE_LSTM\n",
    "\n",
    "REGULARIZER_VALUES = [0]  \n",
    "\n",
    "DROPOUT_VALUES = [0.15,0.1,0.2,0.5] # [] == don't load\n",
    "\n",
    "LOAD_FROM_PREVIOUS_DROPOUT = [] # [] == don't load\n",
    "\n",
    "LSTM_LAYERS_VALUES = [3,2]\n",
    "PREPROCESS_FUNCTION_TO_TEST = [\n",
    "     \n",
    "     (folder_where_save1,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideo,normalizeVideos])\n",
    "     ,(folder_where_save2,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideo,normalizeVideos])\n",
    "    \n",
    "     ,(folder_where_save1,[removeZerosFromDataset,relativeTo3GlobalBaricentersOfVideo,normalizeVideos])\n",
    "     ,(folder_where_save2,[removeZerosFromDataset,relativeTo3GlobalBaricentersOfVideo,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo5GlobalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo5GlobalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideo,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToFrameCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToFrameCenter,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToVideoCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToVideoCenter,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToPersonVideoCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToPersonVideoCenter,normalizeVideos])\n",
    "    \n",
    "    \n",
    "#      (folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(1),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(1),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(3),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(3),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(7),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(7),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToNextFrameBuilder(15),normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToNextFrameBuilder(15),normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToPersonFrameCenter,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToPersonFrameCenter,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,cumulativeDifferences,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,cumulativeDifferences,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideoAbs,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo5PersonalBaricentersNTURGBofVideoAbs,normalizeVideos])\n",
    "    \n",
    "    \n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideoAbs,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo3PersonalBaricentersOfVideoAbs,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo17BaricentersOfVideo,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo17BaricentersOfVideo,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeTo17BaricentersOfVideoAbs,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeTo17BaricentersOfVideoAbs,normalizeVideos])\n",
    "    \n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,relativeToPointDistances,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,relativeToPointDistances,normalizeVideos])\n",
    "    \n",
    "    \n",
    "    \n",
    "#      ,(folder_where_save1,[])\n",
    "#      ,(folder_where_save2,[])\n",
    "#      ,(folder_where_save1,[normalizeVideos])\n",
    "#      ,(folder_where_save2,[normalizeVideos])\n",
    "#      ,(folder_where_save1,[normalizeVideosXYInpid])\n",
    "#      ,(folder_where_save2,[normalizeVideosXYInpid])\n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,normalizeVideos])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,normalizeVideos])\n",
    "#      ,(folder_where_save1,[removeZerosFromDataset,normalizeVideosXYInpid])\n",
    "#      ,(folder_where_save2,[removeZerosFromDataset,normalizeVideosXYInpid])\n",
    "    \n",
    "     \n",
    "    # TECNIQUES\n",
    "\n",
    "# relativeToVideoCenter\n",
    "# relativeToPersonVideoCenter\n",
    "# relativeToFrameCenter\n",
    "# relativeToPersonFrameCenter\n",
    "# relativeTo5BaricentersNTURGBofVideo\n",
    "# relativeTo5BaricentersNTURGBofVideoAbs\n",
    "# relativeTo3BaricentersOfVideo\n",
    "# relativeTo3BaricentersOfVideoAbs\n",
    "# relativeTo17BaricentersOfVideo\n",
    "# relativeTo17BaricentersOfVideoAbs\n",
    "# relativeToNextFrameBuilder(1)\n",
    "# relativeToNextFrameBuilder(3)\n",
    "# relativeToNextFrameBuilder(7)\n",
    "# relativeToNextFrameBuilder(15)\n",
    "# cumulativeDifferences\n",
    "# relativeToPointDistances\n",
    "]\n",
    "\n",
    "if USE_LSTM:\n",
    "    REGULARIZER_VALUES = [0]\n",
    "if not USE_SCHEDULER:\n",
    "    LR_OFFSET = 0\n",
    "    LR_POWER = 0\n",
    " \n",
    "    \n",
    "\n",
    "print(len(MIRRORING_VALUES),\"MIRRORING_VALUES:\", MIRRORING_VALUES)\n",
    "print(len(STD_JITTERING_VALUES),\"STD_JITTERING_VALUES:\", STD_JITTERING_VALUES)\n",
    "print(\"NORMAL LSTM\" if USE_LSTM else \"CuDNNLSTM\")\n",
    "print(len(MODEL_NAME_VALUES),\"MODEL_NAME_VALUES:\", MODEL_NAME_VALUES)\n",
    "print(len(LSTM_LAYERS_VALUES),\"LSTM_LAYERS_VALUES LAYERS:\", LSTM_LAYERS_VALUES)\n",
    "print(len(HIDDEN_UNITS_VALUES), \"HIDDEN UNITS\",HIDDEN_UNITS_VALUES)\n",
    "print(len(REGULARIZER_VALUES),\"REGULARIZER_VALUES\",REGULARIZER_VALUES)\n",
    "print(len(DROPOUT_VALUES),\"DROPOUT_VALUES\",DROPOUT_VALUES)\n",
    "print(len(PREPROCESS_FUNCTION_TO_TEST),\"PREPROCESS_FUNCTION_TO_TEST\")\n",
    "\n",
    "\n",
    "numberOfTests = len(MIRRORING_VALUES) * len(STD_JITTERING_VALUES) * len(MODEL_NAME_VALUES)* len(LEARNING_RATE_VALUES)*len(HIDDEN_UNITS_VALUES) * len(PREPROCESS_FUNCTION_TO_TEST)*len(DROPOUT_VALUES)*len(REGULARIZER_VALUES)*len(LSTM_LAYERS_VALUES)\n",
    "print()\n",
    "if MERGING_TRAIN_VAL:\n",
    "    print(\"!! MERGING TRAIN+VAL !!\\n\")\n",
    "    \n",
    "    \n",
    "print(\"EPOCHS:\", EPOCHS)\n",
    "print(\"REFERENCE_EPOCHS:\", REFERENCE_EPOCHS)\n",
    "print(\"PATIENCE:\", PATIENCE)\n",
    "print()\n",
    "    \n",
    "print(len(LEARNING_RATE_VALUES),\"LEARNING_RATE_VALUES\",LEARNING_RATE_VALUES)\n",
    "if USE_SCHEDULER:\n",
    "#     print(\"\\nUSE_SCHEDULER\\n\\tDECAY_RATE:\", DECAY_RATE, \"\\n\\tDECAY_STEP:\", DECAY_STEP)\n",
    "    print(scheduler.__name__)\n",
    "    print(\"LR_OFFSET:\",LR_OFFSET)\n",
    "    print(\"LR_POWER:\",LR_POWER)\n",
    "print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "print(\"CONTINUE_TRAINING:\",CONTINUE_TRAINING)\n",
    "print(\"\\nNumber of tests:\", numberOfTests)\n",
    "SAVED_MODEL_FOLDER, folder_where_save1, folder_where_save2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequential trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSaveFileName(modelName,preprocess_functions,learning_rate, offset, power, numberOfLSTMLayers, useCudaLSTM, hiddenUnits, regularizerValue, dropOut, recurrentDropOut, std_jittering, mirroring):\n",
    "                                                                   \n",
    "    saveFileName = modelName+\"-{}L\".format(numberOfLSTMLayers+1)\n",
    "    saveFileName += \"-CuDNNLSTM\" if useCudaLSTM else \"\"\n",
    "    saveFileName += \"-HU_\"+str(hiddenUnits)\n",
    "    saveFileName += \"-LR_\"+str(learning_rate)\n",
    "    saveFileName += \"-OFF_\"+str(offset)\n",
    "    saveFileName += \"-POW_\"+str(power)\n",
    "    saveFileName += \"-MIRR\" if mirroring else \"\"\n",
    "    saveFileName += \"-STD_JIT_\"+str(std_jittering) if std_jittering>0 else \"\" \n",
    "    \n",
    "    if preprocess_functions is not None:\n",
    "        for function in preprocess_functions:\n",
    "            saveFileName += \"-{}\".format(function.__name__) \n",
    "                \n",
    "    saveFileName += \"-drop-\"+str(dropOut)\n",
    "    \n",
    "    if useCudaLSTM:\n",
    "        saveFileName += \"-reg-\"+str(regularizerValue)\n",
    "    else:\n",
    "        saveFileName += \"-rec_drop-\"+str(recurrentDropOut)\n",
    "    \n",
    "    return saveFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def getValTestAccuracy(model,x_val,y_val,x_test,y_test, label_order = None):\n",
    "    if label_order is None:\n",
    "        raise Exception(\"define label order for val test accuracy evaluation\")\n",
    "    y_val_pred = [label_order[i] for i in model.predict_classes(x_val)]\n",
    "    y_val_true = [label_order[np.argmax(i)] for i in y_val]\n",
    "    y_test_pred = [label_order[i] for i in model.predict_classes(x_test)]\n",
    "    y_test_true = [label_order[np.argmax(i)] for i in y_test]\n",
    "    val_acc = accuracy_score(y_pred=y_val_pred,y_true=y_val_true)\n",
    "    test_acc = accuracy_score(y_pred=y_test_pred,y_true=y_test_true)\n",
    "    return val_acc, test_acc, y_val_true, y_val_pred, y_test_true, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanForExcel(text):\n",
    "    replacements = (\n",
    "        (\"relativeToVideoCenter\",\"VIDEO\"),\n",
    "        (\"relativeToPersonVideoCenter\",\"VIDEO_PERS\"),        \n",
    "        (\"relativeToFrameCenter\",\"FRAME\"),        \n",
    "        (\"relativeToPersonFrameCenter\",\"FRAME_PERS\"),  \n",
    "        (\"relativeTo3BaricentersOfVideo\",\"3BAR\"),\n",
    "        (\"relativeToUpperMiddleBottomCentersOfVideo\",\"3BAR\"),        \n",
    "        (\"relativeTo5BaricentersNTURGBofVideo\",\"5BAR\"),\n",
    "        (\"relativeTo17BaricentersOfVideo\",\"17BAR\"),\n",
    "        (\"relativeToPointDistances\",\"DIST_REL\"),\n",
    "        (\"relativeToNextFrame\",\"NEXT\"),\n",
    "        (\"cumulativeDifferences\",\"DIST_CUM\"),\n",
    "        (\"removeZerosFromDataset\",\"rimoz_0\"), \n",
    "        (\"normalizeVideosXYInpid\",\"normXY\"),\n",
    "        (\"normalizeVideos\",\"norm\"),     \n",
    "        (\"Abs\",\"_ASS\"),    \n",
    "        (\"CuDNNLSTM\",\"cuda\"),\n",
    "        (\".pickle\",\"\"),\n",
    "        (\".h5\",\"\"),\n",
    "        (\".\",\",\"),\n",
    "        (\"PoseNet-101\",\"pos\"),\n",
    "        (\"keypoint_rcnn_X_101_32x8d_FPN_3x\",\"det\"),\n",
    "        (\"-drop-0-\",\"-\"),\n",
    "        (\"-rec_drop-0-\",\"-\"),\n",
    "        (\"-reg-0#\",\"\"),\n",
    "        (\"-reg-0-\",\"-\"),\n",
    "        (\"#\",\"\")\n",
    "    )\n",
    "    text = text+\"#\"\n",
    "    for r in replacements:\n",
    "        text = text.replace(*r)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## 1/64 - keypoint_rcnn_X_101_32x8d_FPN_3x-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_subject/ ########\n",
      "### already done! ####\n",
      "######## 2/64 - PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_subject/ ########\n",
      "### already done! ####\n",
      "######## 3/64 - keypoint_rcnn_X_101_32x8d_FPN_3x-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_view/ ########\n",
      "### already done! ####\n",
      "######## 4/64 - PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_view/ ########\n",
      "### already done! ####\n",
      "######## 5/64 - keypoint_rcnn_X_101_32x8d_FPN_3x-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3GlobalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_subject/ ########\n",
      "### already done! ####\n",
      "######## 6/64 - PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3GlobalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_subject/ ########\n",
      "### already done! ####\n",
      "######## 7/64 - keypoint_rcnn_X_101_32x8d_FPN_3x-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3GlobalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_view/ ########\n",
      "### already done! ####\n",
      "######## 8/64 - PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3GlobalBaricentersOfVideo-normalizeVideos-drop-0.15-rec_drop-0.15 - Cross_view/ ########\n",
      "### already done! ####\n",
      "######## 9/64 - keypoint_rcnn_X_101_32x8d_FPN_3x-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1 - Cross_subject/ ########\n",
      "### already done! ####\n",
      "######## 10/64 - PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1 - Cross_subject/ ########\n",
      "touching /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1.h5\n",
      "## To be saved in [...]/savedModels/Cross_subject/ ###\n",
      "#### Loading preprocessed dataset:  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/PoseNet-101-CROSS_SUBJECT-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-dataset.pickle\n",
      "## MERGING TRAIN+VAL ##\n",
      "WARNING:tensorflow:From /data/students_home/amoscatelli/Desktop/actionAnalysis/miniconda3/envs/gpuEnv/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /data/students_home/amoscatelli/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 40324 samples, validate on 16560 samples\n",
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.011.\n",
      "40324/40324 [==============================] - 25s 621us/step - loss: 4.1031 - accuracy: 0.0170 - val_loss: 4.0951 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.09512, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.01685, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-max_val_acc.hdf5\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.010933444444444444.\n",
      "40324/40324 [==============================] - 23s 566us/step - loss: 4.1835 - accuracy: 0.0165 - val_loss: 4.0942 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.09512 to 4.09422, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.01685\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.010867111111111109.\n",
      "40324/40324 [==============================] - 22s 549us/step - loss: 4.1022 - accuracy: 0.0170 - val_loss: 4.0958 - val_accuracy: 0.0168\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.09422\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.01685\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.010801000000000002.\n",
      "40324/40324 [==============================] - 22s 545us/step - loss: 4.0561 - accuracy: 0.0255 - val_loss: 3.7122 - val_accuracy: 0.0332\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.09422 to 3.71219, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.01685 to 0.03321, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-max_val_acc.hdf5\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.010735111111111112.\n",
      "40324/40324 [==============================] - 22s 555us/step - loss: 3.6564 - accuracy: 0.0374 - val_loss: 3.5066 - val_accuracy: 0.0465\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.71219 to 3.50658, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-min_val_loss.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.03321 to 0.04650, saving model to /data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/Cross_subject/PoseNet-101-4L-HU_64-LR_0.01-OFF_0.001-POW_2-removeZerosFromDataset-relativeTo3PersonalBaricentersOfVideo-normalizeVideos-drop-0.1-rec_drop-0.1-max_val_acc.hdf5\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.010669444444444443.\n",
      "21348/40324 [==============>...............] - ETA: 8s - loss: 3.5166 - accuracy: 0.0472"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d7b4f86c2586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    301\u001b[0m                                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                                                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                                                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m                                                        )    \n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/actionAnalysis/miniconda3/envs/gpuEnv/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/Desktop/actionAnalysis/miniconda3/envs/gpuEnv/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from keras import models #, layers\n",
    "from keras.layers import LSTM, CuDNNLSTM, Dropout, Dense #, Concatenate \n",
    "from keras.models import load_model #, Model\n",
    "from keras.optimizers import RMSprop #Adam #, RMSprop, Adadelta\n",
    "from keras.regularizers import l2 #, l1\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "from os import scandir\n",
    "from os.path import exists, basename\n",
    "import shutil \n",
    "import math\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from keras import backend as K\n",
    "import os\n",
    "\n",
    "# earlyStop = EarlyStopping(monitor='val_acc', ## 4 COLAB \n",
    "earlyStop = EarlyStopping(monitor='val_accuracy', \n",
    "                          min_delta=0, \n",
    "                          patience=PATIENCE, \n",
    "                          verbose=1, \n",
    "                          mode='max', \n",
    "                          baseline=None, \n",
    "                          restore_best_weights=True)\n",
    "\n",
    "progressCounter = 0\n",
    "\n",
    "for LEARNING_RATE in LEARNING_RATE_VALUES:\n",
    "    for MIRRORING in MIRRORING_VALUES:\n",
    "        for STD_JITTERING in STD_JITTERING_VALUES:\n",
    "            for LSTM_LAYERS in LSTM_LAYERS_VALUES:\n",
    "                for dropOut_idx, dropOut in enumerate(DROPOUT_VALUES):\n",
    "                    for regularizer_idx, regularizer in enumerate(REGULARIZER_VALUES):\n",
    "                        for HIDDEN_UNITS in HIDDEN_UNITS_VALUES:\n",
    "                            for i, (folder_where_to_save, preprocess_functions) in enumerate(PREPROCESS_FUNCTION_TO_TEST):\n",
    "                                for MODEL_NAME in MODEL_NAME_VALUES:\n",
    "                                    DROPOUT = dropOut\n",
    "                                    RECURRENT_DROPOUT = dropOut\n",
    "            #                         EPOCHS = round(REFERENCE_EPOCHS * (1+DROPOUT))\n",
    "\n",
    "\n",
    "                                    progressCounter += 1\n",
    "                                    folderPathWhereToSave = SAVED_MODEL_FOLDER+folder_where_to_save\n",
    "                                    if folder_where_to_save.endswith(\"_lrScan/\"):\n",
    "                                        EPOCHS = SCAN_EPOCHS\n",
    "\n",
    "                                    alreadyTrainedModel = [f for f in scandir(folderPathWhereToSave) if f.path.endswith(\".h5\")]\n",
    "\n",
    "                                    ### SET SAVE FILE NAME ###\n",
    "                                    if CONTINUE_TRAINING:\n",
    "                                        saveFileName = CONTINUE_TRAINING\n",
    "                                        saveFileName += \"_THEN\"\n",
    "                                        saveFileName += \"_MIRR\" if MIRRORING else \"\"\n",
    "                                        saveFileName += \"_JIT_\"+ str(STD_JITTERING) if STD_JITTERING>0 else \"\" \n",
    "                                        saveFileName += \"_drop_\"+ str(dropOut) if dropOut>0 else \"\"\n",
    "                                    else:                                            \n",
    "                                        saveFileName = getSaveFileName(modelName = MODEL_NAME,\n",
    "                                                                       preprocess_functions = preprocess_functions,\n",
    "                                                                       learning_rate= LEARNING_RATE,\n",
    "                                                                       offset = LR_OFFSET,\n",
    "                                                                       power = LR_POWER,\n",
    "                                                                       numberOfLSTMLayers = LSTM_LAYERS,\n",
    "                                                                       useCudaLSTM = USE_CuDNNLSTM,\n",
    "                                                                       hiddenUnits = HIDDEN_UNITS,\n",
    "                                                                       regularizerValue = regularizer,\n",
    "                                                                       dropOut = DROPOUT, \n",
    "                                                                       recurrentDropOut = RECURRENT_DROPOUT,\n",
    "                                                                       std_jittering = STD_JITTERING,\n",
    "                                                                       mirroring = MIRRORING)\n",
    "\n",
    "                                    print(\"######## {}/{} - {} - {} ########\".format(progressCounter, numberOfTests, saveFileName, folder_where_to_save))\n",
    "\n",
    "                                    if saveFileName+\".h5\" in [m.name for m in alreadyTrainedModel]:\n",
    "                                        print(\"### already done! ####\")\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        #to avoid that someone else will start the same fitting\n",
    "                                        print(\"touching\",folderPathWhereToSave+saveFileName+\".h5\")\n",
    "                                        modelFileName = saveFileName+\".h5\"\n",
    "\n",
    "                #                         pathToTouch = (folderPathWhereToSave+modelFileName).replace(\" \",\"\\ \") ## 4 COLAB \n",
    "                                        modelFileNamePath = folderPathWhereToSave+modelFileName\n",
    "                                        !touch $modelFileNamePath\n",
    "                                        print(\"## To be saved in [...]{} ###\".format(folderPathWhereToSave[54:]))\n",
    "\n",
    "                                    ### LOADING DATASET ###\n",
    "                                    if folderPathWhereToSave.endswith(\"Senesi/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT-SENESI-dataset.pickle\"\n",
    "                                    elif folderPathWhereToSave.endswith(\"top-models/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT-dataset.pickle\"      \n",
    "\n",
    "                                    elif folderPathWhereToSave.endswith(\"Cross_subject_test/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TEST-dataset.pickle\"            \n",
    "                                    elif folderPathWhereToSave.endswith(\"Cross_view_test/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TEST-dataset.pickle\"     \n",
    "\n",
    "                                    elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_subject/\",\"Cross_subject_lrScan/\"]]):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT-dataset.pickle\"       \n",
    "                                    elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_view/\",\"Cross_view_lrScan/\"]]):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW-dataset.pickle\"  \n",
    "\n",
    "                                    elif folderPathWhereToSave.endswith(\"Cross_view_tough/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TOUGH-dataset.pickle\"            \n",
    "                                    elif folderPathWhereToSave.endswith(\"Cross_subject_tough/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TOUGH-dataset.pickle\" \n",
    "\n",
    "                                    elif folderPathWhereToSave.endswith(\"Cross_view_mini/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_MINI-dataset.pickle\"            \n",
    "                                    elif folderPathWhereToSave.endswith(\"Cross_subject_mini/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_MINI-dataset.pickle\"    \n",
    "\n",
    "                                    elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_view/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TOP+SENESI-dataset.pickle\"            \n",
    "                                    elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_subject/\"):\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TOP+SENESI-dataset.pickle\" \n",
    "\n",
    "                                    elif folderPathWhereToSave.endswith(\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset)/\") and MODEL_NAME == \"PoseNet-101\":\n",
    "                                        datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset.pickle\"\n",
    "                                    else:\n",
    "                                        raise Exception(\"result folder not correct\")\n",
    "\n",
    "                                    ### CHECK IF ALREADY PREPROCESSED DATASET EXISTS\n",
    "                                    preprocessed_datasetName = basename(datasetName).replace(\"-dataset.pickle\",\"\")\n",
    "                                    preprocessed_datasetName += \"-MIRR\" if MIRRORING else \"\"\n",
    "                                    preprocessed_datasetName += \"-STD_JIT_\"+str(STD_JITTERING) if STD_JITTERING>0 else \"\" \n",
    "                                    for f in preprocess_functions:\n",
    "                                        preprocessed_datasetName += \"-\"+f.__name__\n",
    "                                    preprocessed_datasetName += \"-dataset.pickle\"\n",
    "\n",
    "                                    preprocessed_datasetPath = DATASET_FOLDER+preprocessed_datasetName\n",
    "\n",
    "    #                                     print(\"###### NOT CHECKING IF THERE IS A PREPROCCED DATASET ######\")\n",
    "    #                                     if False:\n",
    "                                    if exists(preprocessed_datasetPath):\n",
    "                                        print(\"#### Loading preprocessed dataset: \", preprocessed_datasetPath)\n",
    "                                        with open(preprocessed_datasetPath,'rb') as file_in:\n",
    "                                            prepDict = pickle.load(file_in)\n",
    "                                            X_train = prepDict[\"X_train\"]\n",
    "                                            y_train = prepDict[\"y_train\"]\n",
    "                                            X_val = prepDict[\"X_val\"]\n",
    "                                            y_val = prepDict[\"y_val\"]\n",
    "                                            X_test = prepDict[\"X_test\"]\n",
    "                                            y_test = prepDict[\"y_test\"]\n",
    "                                            encodingLabels = prepDict[\"encodingLabels\"]\n",
    "                                    else:\n",
    "                                        print(\"#### Loading dataset: \", datasetName)\n",
    "                                        train_set, val_set, test_set = getData(datasetName)\n",
    "                                        print(\"Preproccesing dataset...\")\n",
    "\n",
    "                                        ##### DATA AUGMENTATION #####\n",
    "                                        X_AXIS = 1 if MODEL_NAME == \"PoseNet-101\" else 0\n",
    "                                        train_set = augmentData(train_set, xAxis = X_AXIS, mirroring = MIRRORING, std_jittering = STD_JITTERING)\n",
    "                                        val_set = augmentData(val_set, xAxis = X_AXIS, mirroring = MIRRORING, std_jittering = STD_JITTERING)\n",
    "\n",
    "                                        X_train, y_train, X_val, y_val, X_test, y_test, encodingLabels = preprocessData(train_set, \n",
    "                                                                                                                       val_set, \n",
    "                                                                                                                       test_set,  \n",
    "                                                                                                                       preprocess_functions)\n",
    "\n",
    "\n",
    "    #                                     ###### CREATING GENERATORS #######\n",
    "    #                                     trainingGenerator = sampleGenerator(X_train, y_train, BATCH_SIZE, xAxis = 1 if MODEL_NAME == \"PoseNet-101\" else 0)\n",
    "    #                                     validationGenerator = sampleGenerator(X_val, y_val, BATCH_SIZE, xAxis = 1 if MODEL_NAME == \"PoseNet-101\" else 0)\n",
    "\n",
    "    #                                     assert False, \"stop here\"\n",
    "\n",
    "                                    # MERGING TRAINNG AND VALIDATION\n",
    "                                    if MERGING_TRAIN_VAL:\n",
    "                                        print(\"## MERGING TRAIN+VAL ##\")\n",
    "                                        X_train = np.concatenate((X_train,X_val),axis=0)\n",
    "                                        y_train = np.concatenate((y_train,y_val),axis=0)\n",
    "                                        X_val,y_val = X_test,y_test\n",
    "\n",
    "                                    # TO SOLVE THE DROPOUT LAYER SHAPE PROBLEM\n",
    "                                    missing_train = (BATCH_SIZE-(X_train.shape[0]%BATCH_SIZE))%BATCH_SIZE\n",
    "                                    X_train = np.concatenate((X_train,X_train[:missing_train]),axis=0)\n",
    "                                    y_train = np.concatenate((y_train,y_train[:missing_train]),axis=0)\n",
    "\n",
    "                                    ### DEFINING MODEL ###\n",
    "                                    inputDim = (X_train.shape[1], X_train.shape[2])\n",
    "                                    outputLen = len(y_train[0])\n",
    "\n",
    "                                    ## callbacks and checkpoints\n",
    "                                    minLossModelName = \"{}-min_val_loss.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "                                    checkpointLoss = ModelCheckpoint(minLossModelName, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "                                    maxAccModelName = \"{}-max_val_acc.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "\n",
    "                                    checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') \n",
    "                #                     checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_acc', verbose=1, save_best_only=True, mode='max') ## 4 COLAB \n",
    "\n",
    "\n",
    "                                    callbacks_list = [checkpointLoss, checkpointAcc]\n",
    "\n",
    "                                    if USE_SCHEDULER:\n",
    "                                        callbacks_list.append(LearningRateScheduler(scheduler, verbose=1))\n",
    "                                        callbacks_list.append(earlyStop)\n",
    "                                    else:\n",
    "                                        callbacks_list.append(earlyStop)\n",
    "\n",
    "\n",
    "                                    model = models.Sequential()\n",
    "                                    model.add(Dropout(DROPOUT, input_shape=inputDim, noise_shape=(BATCH_SIZE, 1, inputDim[1])))\n",
    "\n",
    "                                    if USE_LSTM:\n",
    "                                        if LSTM_LAYERS == 1:\n",
    "                                            model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT))\n",
    "                                        else:       \n",
    "                                            model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT, return_sequences=True))\n",
    "                                            for layerIdx in range(2, LSTM_LAYERS):\n",
    "                                                model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT, return_sequences=True))\n",
    "                                            model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT))    \n",
    "\n",
    "                                    elif USE_CuDNNLSTM:\n",
    "                                        print(\"#### REMOVED KERNEL REGULARIZER #######\")\n",
    "                                        reg=l2(regularizer) if regularizer > 0 else None\n",
    "\n",
    "                                        if LSTM_LAYERS == 1:\n",
    "                                            model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer = reg))\n",
    "                                        else:\n",
    "                                            model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer = reg, return_sequences=True))\n",
    "                                            for layerIdx in range(2, LSTM_LAYERS):\n",
    "                                                model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer = reg, return_sequences=True))                  \n",
    "                                            model.add(CuDNNLSTM(HIDDEN_UNITS, recurrent_regularizer=reg))\n",
    "\n",
    "\n",
    "                                    model.add(Dense(outputLen, activation='softmax'))\n",
    "\n",
    "        #                             opt = Adam(learning_rate=LEARNING_RATE, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        #                             opt = Adadelta(learning_rate=LEARNING_RATE, rho=0.95)\n",
    "                                    opt = RMSprop(lr=LEARNING_RATE, rho=0.9) ## 4 COLAB \n",
    "                #                     opt = RMSprop(lerning_rate=LEARNING_RATE, rho=0.9)\n",
    "\n",
    "                                    model.compile(\n",
    "                #                                 optimizer='rmsprop',\n",
    "                                                optimizer=opt,\n",
    "                                                loss='categorical_crossentropy',\n",
    "                                                metrics=['accuracy'])\n",
    "\n",
    "                                    ## CONTINUE TRAINING\n",
    "                                    if CONTINUE_TRAINING:\n",
    "                                        print(\"Loading from\",CONTINUE_TRAINING)\n",
    "                                        continueTrainingModelName = \"{}.h5\".format(folderPathWhereToSave+CONTINUE_TRAINING)\n",
    "                                        model.load_weights(continueTrainingModelName)\n",
    "                                        previousModelName = continueTrainingModelName\n",
    "\n",
    "                                    ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "                                    if exists(minLossModelName):\n",
    "                                        print(\"#### Loading weights from MIN LOSS model\")\n",
    "                                        model.load_weights(minLossModelName)\n",
    "\n",
    "                                    ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "                                    minLossBackupModelName = \"{}-min_val_loss-BACKUP.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "                                    if exists(maxAccModelName):\n",
    "                                        print(\"#### Loading weights from MAX ACCURACY model\")\n",
    "                                        model.load_weights(minLossModelName)\n",
    "                                        if exists(minLossModelName):\n",
    "                                            print(\"#### BACKUP of weights for previous MIN LOSS model\")\n",
    "                                            shutil.copyfile(minLossModelName,minLossBackupModelName)\n",
    "\n",
    "                                    ## Loading weights from previous model trained with an higher dropout rate\n",
    "                                    loadedFromPreviousModel = False\n",
    "                                    if (DROPOUT > 0 or RECURRENT_DROPOUT > 0) and LOAD_FROM_PREVIOUS_DROPOUT and USE_LSTM:\n",
    "                                        for prev_dropOut in LOAD_FROM_PREVIOUS_DROPOUT:\n",
    "                                            if prev_dropOut <= DROPOUT:\n",
    "                                                continue\n",
    "                                            previousModelName = getSaveFileName(modelName = MODEL_NAME, \n",
    "                                                                                preprocess_functions = preprocess_functions, \n",
    "                                                                                learning_rate= LEARNING_RATE,\n",
    "                                                                                offset = LR_OFFSET,\n",
    "                                                                                power = LR_POWER,\n",
    "                                                                                numberOfLSTMLayers = LSTM_LAYERS, \n",
    "                                                                                useCudaLSTM = USE_CuDNNLSTM,\n",
    "                                                                                hiddenUnits = HIDDEN_UNITS,\n",
    "                                                                                regularizerValue = regularizer,\n",
    "                                                                                dropOut = prev_dropOut, \n",
    "                                                                                recurrentDropOut = prev_dropOut,\n",
    "                                                                                std_jittering = STD_JITTERING,\n",
    "                                                                                mirroring = MIRRORING)\n",
    "                                            if exists(folderPathWhereToSave+previousModelName+\".h5\"):\n",
    "                                                print(\"#### Loading weights from\",previousModelName)\n",
    "                                                model.load_weights(folderPathWhereToSave+previousModelName+\".h5\")\n",
    "                                                loadedFromPreviousModel = True\n",
    "                                                break\n",
    "\n",
    "\n",
    "                                    # FIT ###\n",
    "    #                                     if MERGING_TRAIN_VAL:\n",
    "    #                                         model_history = model.fit(X_train, y_train,\n",
    "    #                                                         epochs=EPOCHS,\n",
    "    #                                                         batch_size=BATCH_SIZE,\n",
    "    #                                                         callbacks=callbacks_list,\n",
    "    #                                                         validation_data=(X_test, y_test)\n",
    "    #                                                        )\n",
    "    #                                     else:\n",
    "                                    model_history = model.fit(X_train, y_train,\n",
    "                                                        epochs=EPOCHS,\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                        callbacks=callbacks_list,\n",
    "                                                        validation_data=(X_val, y_val)\n",
    "                                                       )    \n",
    "\n",
    "    #                                     print(\"### FITTING WITH GENERATORS  ####\")\n",
    "    #                                     trainStepPerEpoch = int(len(X_train)/BATCH_SIZE)+1\n",
    "    #                                     valStepPerEpoch = int(len(X_val)/BATCH_SIZE)+1\n",
    "\n",
    "    #                                     history = model.fit_generator(trainingGenerator,\n",
    "    #                                                                   epochs=EPOCHS,\n",
    "    #                                                                   steps_per_epoch= trainStepPerEpoch,\n",
    "    #                                                                   callbacks=callbacks_list,\n",
    "    #                                                                   validation_data=validationGenerator,\n",
    "    #                                                                   validation_steps=valStepPerEpoch\n",
    "    #                                                                   )\n",
    "\n",
    "\n",
    "                                    ### SAVE MODEL ###\n",
    "                                    model.save(folderPathWhereToSave+saveFileName+\".h5\")\n",
    "\n",
    "                                    ### SAVE HISTORY AND PREPROCESS FUNCTIONS ###\n",
    "                                    env_functions = [one_hot_encoding, \n",
    "                                                      euclDistance,\n",
    "                                                      paddingTrainValTest, \n",
    "                                                      getClosestNonZeroCoordinate,\n",
    "                                                      removeZerosFromVideo,\n",
    "                                                      getZeroStatsForDataset,\n",
    "                                                      preprocessData,\n",
    "                                                     ]\n",
    "\n",
    "                                    historyToSave = {\n",
    "                                        \"acc\" : model_history.history['accuracy'],\n",
    "                                        \"val_acc\" : model_history.history['val_accuracy'],\n",
    "                                        \"loss\" : model_history.history['loss'],\n",
    "                                        \"val_loss\" : model_history.history['val_loss']\n",
    "                                    }\n",
    "\n",
    "\n",
    "                                    info_to_save = {\"history\": historyToSave,\n",
    "                                                    \"env_fun_DILL\":[dill.dumps(x) for x in env_functions],\n",
    "                                                    \"spec_fun_DILL\":[dill.dumps(x) for x in preprocess_functions]}\n",
    "\n",
    "\n",
    "                                    if loadedFromPreviousModel or CONTINUE_TRAINING:\n",
    "                                        info_to_save[\"loaded_from\"] = previousModelName\n",
    "\n",
    "                                    with open(folderPathWhereToSave+saveFileName+\".pickle\",\"wb\") as handle:\n",
    "                                        pickle.dump(info_to_save, handle) \n",
    "                                        print(\"## Saved in {} ###\\n\\n\".format(folderPathWhereToSave+saveFileName+\".pickle\"))\n",
    "\n",
    "\n",
    "                                    ### EVALUATING MODEL ### \n",
    "                                    model = load_model(maxAccModelName)\n",
    "                                    !mv $maxAccModelName $modelFileNamePath\n",
    "                                    val_acc, test_acc, y_val_true, y_val_pred, y_test_true, y_test_pred = getValTestAccuracy(model,X_val,y_val,X_test,y_test, encodingLabels)\n",
    "                                    print(\"Model for MAX ACCURACY test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc*100,val_acc*100))\n",
    "\n",
    "                                    if exists(minLossModelName):\n",
    "                                        model_minLoss = load_model(minLossModelName)\n",
    "                                        val_acc_minLoss, test_acc_minLoss, y_val_true, y_val_pred_minLoss, y_test_true, y_test_pred_minLoss = getValTestAccuracy(model_minLoss,X_val,y_val,X_test,y_test,encodingLabels)\n",
    "                                        print(\"Model for MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc_minLoss*100,val_acc_minLoss*100))\n",
    "                                    else:\n",
    "                                        print(\"Model for MIN LOSS NOT SAVED\")\n",
    "                                        val_acc_minLoss = math.inf\n",
    "\n",
    "                                    if exists(minLossBackupModelName):\n",
    "                                        model_minLoss_b = load_model(minLossBackupModelName)\n",
    "                                        print(\"#### Evaluating BACKUP min loss model ####\")\n",
    "                                        val_acc_minLoss_b, test_acc_minLoss_b, y_val_true, y_val_pred_minLoss_b, y_test_true, y_test_pred_minLoss_b = getValTestAccuracy(model_minLoss_b,X_val,y_val,X_test,y_test,encodingLabels)\n",
    "                                        print(\"Model for BACKUP MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc_minLoss_b*100,val_acc_minLoss_b*100))\n",
    "                                        if (val_acc_minLoss_b < val_acc_minLoss):\n",
    "                                            print(\"### keeping BACKUP MIN LOSS model ####\")\n",
    "                                            val_acc_minLoss, test_acc_minLoss, y_val_pred_minLoss, y_test_pred_minLoss = val_acc_minLoss_b, test_acc_minLoss_b, y_val_pred_minLoss_b, y_test_pred_minLoss_b\n",
    "                                            !mv $minLossBackupModelName $minLossModelName\n",
    "                                        else:\n",
    "                                            !rm $minLossBackupModelName\n",
    "\n",
    "                                    ### CLEANING MAX ACC CHECKPOINT \n",
    "                                    ## 4 COLAB \n",
    "                #                     patToRemove = maxAccModelName.replace(\" \",\"\\ \")\n",
    "            #                         patToRemove = maxAccModelName\n",
    "            #                         !rm $patToRemove\n",
    "\n",
    "                                    ### SAVING RESULTS ###\n",
    "                                    if EPOCHS < 10:\n",
    "                                        print(\"## SKIPPING SAVING. EPOCHS < 11\")\n",
    "                                        continue\n",
    "\n",
    "                                    if exists(folderPathWhereToSave+\"summaryResults.pickle\"):\n",
    "                                        print(\"Loading previous results...\")\n",
    "                                        with open(folderPathWhereToSave+\"summaryResults.pickle\",\"rb\") as handle:\n",
    "                                                results = pickle.load(handle)\n",
    "                                    else:\n",
    "                                        results = []\n",
    "\n",
    "                                    results.append({\"val_acc\": val_acc, \n",
    "                                                    \"test_acc\": test_acc, \n",
    "                                                    \"model_name\": saveFileName, \n",
    "                                                    \"y_val_true\": y_val_true,\n",
    "                                                    \"y_val_pred\": y_val_pred,\n",
    "                                                    \"y_test_true\": y_test_true,\n",
    "                                                    \"y_test_pred\": y_test_pred,\n",
    "\n",
    "                                                    \"val_acc_minLoss\": val_acc_minLoss, \n",
    "                                                    \"test_acc_minLoss\": test_acc_minLoss, \n",
    "                                                    \"y_val_pred_minLoss\": y_val_pred_minLoss,\n",
    "                                                    \"y_test_pred_minLoss\": y_test_pred_minLoss\n",
    "                                                   })\n",
    "\n",
    "                                    print(\"Dumping results...\")\n",
    "                                    with open(folderPathWhereToSave+\"summaryResults.pickle\",\"wb\") as handle:\n",
    "                                        pickle.dump(results, handle)\n",
    "\n",
    "print(\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### CHECK IF ALREADY PREPROCESSED DATASET EXISTS\n",
    "preprocessed_datasetName = basename(datasetName).replace(\"-dataset.pickle\",\"\")\n",
    "preprocessed_datasetName += \"-MIRR\" if mirroring else \"\"\n",
    "preprocessed_datasetName += \"-STD_JIT_\"+str(std_jittering) if std_jittering>0 else \"\" \n",
    "for f in preprocess_functions:\n",
    "    preprocessed_datasetName += \"-\"+f.__name__\n",
    "    \n",
    "preprocessed_datasetName += \"-dataset.pickle\"\n",
    "\n",
    "\n",
    "preprocessed_datasetPath = DATASET_FOLDER+preprocessed_datasetName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relativeTo3BaricentersOfVideo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bba53db41977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"keypoint_rcnn_X_101_32x8d_FPN_3x\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodelToContinueTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-3L-CuDNNLSTM-HU_64-LR_0.017-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.15-reg-0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpreprocess_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mremoveZerosFromDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelativeTo3BaricentersOfVideo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalizeVideos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfolderToTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cross_subject/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'relativeTo3BaricentersOfVideo' is not defined"
     ]
    }
   ],
   "source": [
    "# # \"det-3L-cuda-HU_64-LR_0,017-OFF_0,001-POW_1,5-rimoz_0-3BAR-norm-drop-0,15\"\n",
    "# MODEL_NAME = \"keypoint_rcnn_X_101_32x8d_FPN_3x\"\n",
    "# modelToContinueTrain = MODEL_NAME+\"-3L-CuDNNLSTM-HU_64-LR_0.017-OFF_0.001-POW_1.5-removeZerosFromDataset-relativeTo3BaricentersOfVideo-normalizeVideos-drop-0.15-reg-0\"\n",
    "# preprocess_functions = [removeZerosFromDataset,relativeTo3BaricentersOfVideo,normalizeVideos]\n",
    "\n",
    "# folderToTrain = \"Cross_subject/\"\n",
    "# CONFIGURATION_TO_CONTINUE_TRAIN = [(folderToTrain, modelToContinueTrain)]\n",
    "\n",
    "# PATIENCE = 100\n",
    "# EPOCHS = 50000\n",
    "# BATCH_SIZE = 600\n",
    "        \n",
    "# LEARNING_RATE = 0.005\n",
    "# USE_SCHEDULER = False\n",
    "# ###### POLYNOMIAL SCHEDULER #############\n",
    "# LR_OFFSET = 0.000\n",
    "# LR_POWER = 1\n",
    "# def polynomialScheduler(epoch, lr):\n",
    "#     decay = (1 - (epoch / float(EPOCHS)))  ** LR_POWER\n",
    "#     alpha = LEARNING_RATE * decay\n",
    "#     return float(alpha) + LR_OFFSET\n",
    "# scheduler = polynomialScheduler\n",
    "# ##########################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "# from keras import models #, layers\n",
    "# from keras.layers import LSTM, CuDNNLSTM, Dropout, Dense #, Concatenate \n",
    "# from keras.models import load_model #, Model\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras.regularizers import l2 #, l1\n",
    "# from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "# from os import scandir\n",
    "# from os.path import exists, basename\n",
    "# import shutil \n",
    "# import math\n",
    "# from numpy.random import seed\n",
    "# from tensorflow import set_random_seed \n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import random as rn\n",
    "# from keras import backend as K\n",
    "# import os\n",
    "\n",
    "\n",
    "# # earlyStop = EarlyStopping(monitor='val_acc', ## 4 COLAB \n",
    "# earlyStop = EarlyStopping(monitor='val_accuracy', \n",
    "#                           min_delta=0, \n",
    "#                           patience=PATIENCE, \n",
    "#                           verbose=1, \n",
    "#                           mode='max', \n",
    "#                           baseline=None, \n",
    "#                           restore_best_weights=True)\n",
    "\n",
    "# for idx_configuration, (folderToTrain,modelToTrain) in enumerate(CONFIGURATION_TO_CONTINUE_TRAIN):\n",
    "#     print(\"######## {}/{} - {} - {} ########\".format(idx_configuration, len(CONFIGURATION_TO_CONTINUE_TRAIN),cleanForExcel(modelToTrain),folderToTrain))\n",
    "\n",
    "#     folderPathWhereToSave = SAVED_MODEL_FOLDER+folderToTrain\n",
    "#     if not exists(folderPathWhereToSave+modelToTrain+\".h5\"):\n",
    "#         print(\"model {} not existend in folder {}\".format(modelToTrain,folderToTrain))\n",
    "#         continue\n",
    "          \n",
    "#     alreadyTrainedModel = [f for f in scandir(folderPathWhereToSave) if f.path.endswith(\".h5\")]\n",
    "    \n",
    "#     saveFileName = modelToTrain+\"-THEN_LR_\"+str(LEARNING_RATE)\n",
    "          \n",
    "#     if saveFileName+\".h5\" in [m.name for m in alreadyTrainedModel]:\n",
    "#         print(\"### already done! ####\")\n",
    "#         continue\n",
    "#     else:\n",
    "#         #to avoid that someone else will start the same fitting\n",
    "#         print(\"touching\",folderPathWhereToSave+saveFileName+\".h5\")\n",
    "#         modelFileName = saveFileName+\".h5\"\n",
    "\n",
    "# #       pathToTouch = (folderPathWhereToSave+modelFileName).replace(\" \",\"\\ \") ## 4 COLAB \n",
    "#         modelFileNamePath = folderPathWhereToSave+modelFileName\n",
    "#         !touch $modelFileNamePath\n",
    "#         print(\"## To be saved in [...]{} ###\".format(folderPathWhereToSave[54:]))\n",
    "\n",
    "#     ### LOADING DATASET ###\n",
    "#     if folderPathWhereToSave.endswith(\"Senesi/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT-SENESI-dataset.pickle\"\n",
    "#     elif folderPathWhereToSave.endswith(\"top-models/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT-dataset.pickle\"      \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_subject_test/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TEST-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_view_test/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TEST-dataset.pickle\"     \n",
    "\n",
    "#     elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_subject/\",\"Cross_subject_lrScan/\"]]):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT-dataset.pickle\"       \n",
    "#     elif any([folderPathWhereToSave.endswith(s) for s in [\"Cross_view/\",\"Cross_view_lrScan/\"]]):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW-dataset.pickle\"  \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_view_tough/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TOUGH-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_subject_tough/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TOUGH-dataset.pickle\" \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_view_mini/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_MINI-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"Cross_subject_mini/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_MINI-dataset.pickle\"    \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_view/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_VIEW_TOP+SENESI-dataset.pickle\"            \n",
    "#     elif folderPathWhereToSave.endswith(\"top+Senesi_Cross_subject/\"):\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-CROSS_SUBJECT_TOP+SENESI-dataset.pickle\" \n",
    "\n",
    "#     elif folderPathWhereToSave.endswith(\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset)/\") and MODEL_NAME == \"PoseNet-101\":\n",
    "#         datasetName = DATASET_FOLDER+MODEL_NAME+\"-SPLIT_DIFFERENT_FROM_DETECTRON-dataset.pickle\"\n",
    "#     else:\n",
    "#         raise Exception(\"result folder not correct\")\n",
    "\n",
    "#     ### CHECK IF ALREADY PREPROCESSED DATASET EXISTS\n",
    "#     preprocessed_datasetName = basename(datasetName).replace(\"-dataset.pickle\",\"\")\n",
    "#     for f in preprocess_functions:\n",
    "#         preprocessed_datasetName += \"-\"+f.__name__\n",
    "#     preprocessed_datasetName += \"-dataset.pickle\"\n",
    "\n",
    "#     preprocessed_datasetPath = DATASET_FOLDER+preprocessed_datasetName\n",
    "\n",
    "#     if exists(preprocessed_datasetPath):\n",
    "#         print(\"#### Loading preprocessed dataset: \", preprocessed_datasetPath)\n",
    "#         with open(preprocessed_datasetPath,'rb') as file_in:\n",
    "#             prepDict = pickle.load(file_in)\n",
    "#             X_train = prepDict[\"X_train\"]\n",
    "#             y_train = prepDict[\"y_train\"]\n",
    "#             X_val = prepDict[\"X_val\"]\n",
    "#             y_val = prepDict[\"y_val\"]\n",
    "#             X_test = prepDict[\"X_test\"]\n",
    "#             y_test = prepDict[\"y_test\"]\n",
    "#             encodingLabels = prepDict[\"encodingLabels\"]\n",
    "#     else:\n",
    "#         print(\"#### Loading dataset: \", datasetName)\n",
    "#         train_set, val_set, test_set = getData(datasetName)\n",
    "#         print(\"Preproccesing dataset...\")\n",
    "#         X_train, y_train, X_val, y_val, X_test, y_test, encodingLabels = preprocessData(train_set, \n",
    "#                                                                                        val_set, \n",
    "#                                                                                        test_set,  \n",
    "#                                                                                        preprocess_functions)\n",
    "\n",
    "#     # TO SOLVE THE DROPOUT LAYER SHAPE PROBLEM\n",
    "#     missing_train = (BATCH_SIZE-(X_train.shape[0]%BATCH_SIZE))%BATCH_SIZE\n",
    "#     X_train = np.concatenate((X_train,X_train[:missing_train]),axis=0)\n",
    "#     y_train = np.concatenate((y_train,y_train[:missing_train]),axis=0)\n",
    "\n",
    "#     ### DEFINING MODEL ###\n",
    "#     inputDim = (X_train.shape[1], X_train.shape[2])\n",
    "#     outputLen = len(y_train[0])\n",
    "\n",
    "#     ## callbacks and checkpoints\n",
    "#     minLossModelName = \"{}-min_val_loss.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "#     checkpointLoss = ModelCheckpoint(minLossModelName, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "#     maxAccModelName = \"{}-max_val_acc.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "\n",
    "#     checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') \n",
    "# #   checkpointAcc = ModelCheckpoint(maxAccModelName, monitor='val_acc', verbose=1, save_best_only=True, mode='max') ## 4 COLAB \n",
    "\n",
    "\n",
    "#     callbacks_list = [checkpointLoss, checkpointAcc]\n",
    "\n",
    "#     if USE_SCHEDULER:\n",
    "#         callbacks_list.append(LearningRateScheduler(scheduler, verbose=1))\n",
    "#     else:\n",
    "#         callbacks_list.append(earlyStop)\n",
    "\n",
    "            \n",
    "#     model = load_model(folderPathWhereToSave+modelToTrain+\".h5\")\n",
    "\n",
    "#     rmpsprop = RMSprop(lr=LEARNING_RATE, rho=0.9) \n",
    "\n",
    "#     model.compile(\n",
    "# #               optimizer='rmsprop',\n",
    "#                 optimizer=rmpsprop,\n",
    "#                 loss='categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#     ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "#     if exists(minLossModelName):\n",
    "#         print(\"#### Loading weights from MIN LOSS model\")\n",
    "#         model.load_weights(minLossModelName)\n",
    "\n",
    "#     ## RECOVER FROM MIN LOSS MODEL IF EXISTS\n",
    "#     minLossBackupModelName = \"{}-min_val_loss-BACKUP.hdf5\".format(folderPathWhereToSave+saveFileName)\n",
    "#     if exists(maxAccModelName):\n",
    "#         print(\"#### Loading weights from MAX ACCURACY model\")\n",
    "#         model.load_weights(minLossModelName)\n",
    "#         if exists(minLossModelName):\n",
    "#             print(\"#### BACKUP of weights for previous MIN LOSS model\")\n",
    "#             shutil.copyfile(minLossModelName,minLossBackupModelName)\n",
    "\n",
    "\n",
    "#     ## FIT ###    \n",
    "#     model_history = model.fit(X_train, y_train,\n",
    "#                         epochs=EPOCHS,\n",
    "#                         batch_size=BATCH_SIZE,\n",
    "#                         callbacks=callbacks_list,\n",
    "#                         validation_data=(X_val, y_val)\n",
    "#                        )\n",
    "\n",
    "#     ### SAVE MODEL ###\n",
    "#     model.save(folderPathWhereToSave+saveFileName+\".h5\")\n",
    "\n",
    "#     ### SAVE HISTORY AND PREPROCESS FUNCTIONS ###\n",
    "#     env_functions = [one_hot_encoding, \n",
    "#                       euclDistance,\n",
    "#                       paddingTrainValTest, \n",
    "#                       getClosestNonZeroCoordinate,\n",
    "#                       removeZerosFromVideo,\n",
    "#                       getZeroStatsForDataset,\n",
    "#                       preprocessData,\n",
    "#                      ]\n",
    "\n",
    "#     historyToSave = {\n",
    "#         \"acc\" : model_history.history['accuracy'],\n",
    "#         \"val_acc\" : model_history.history['val_accuracy'],\n",
    "#         \"loss\" : model_history.history['loss'],\n",
    "#         \"val_loss\" : model_history.history['val_loss']\n",
    "#     }\n",
    "\n",
    "\n",
    "#     info_to_save = {\"history\": historyToSave,\n",
    "#                     \"env_fun_DILL\":[dill.dumps(x) for x in env_functions],\n",
    "#                     \"spec_fun_DILL\":[dill.dumps(x) for x in preprocess_functions]}\n",
    "\n",
    "#     info_to_save[\"loaded_from\"] = folderPathWhereToSave+modelToTrain\n",
    "\n",
    "#     with open(folderPathWhereToSave+saveFileName+\".pickle\",\"wb\") as handle:\n",
    "#         pickle.dump(info_to_save, handle) \n",
    "#         print(\"## Saved in {} ###\\n\\n\".format(folderPathWhereToSave+saveFileName+\".pickle\"))\n",
    "\n",
    "\n",
    "#     ### EVALUATING MODEL ### \n",
    "#     model = load_model(maxAccModelName)\n",
    "#     !mv $maxAccModelName $modelFileNamePath\n",
    "#     val_acc, test_acc, y_val_true, y_val_pred, y_test_true, y_test_pred = getValTestAccuracy(model,X_val,y_val,X_test,y_test, encodingLabels)\n",
    "#     print(\"Model for MAX ACCURACY test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc*100,val_acc*100))\n",
    "\n",
    "#     if exists(minLossModelName):\n",
    "#         model_minLoss = load_model(minLossModelName)\n",
    "#         val_acc_minLoss, test_acc_minLoss, y_val_true, y_val_pred_minLoss, y_test_true, y_test_pred_minLoss = getValTestAccuracy(model_minLoss,X_val,y_val,X_test,y_test,encodingLabels)\n",
    "#         print(\"Model for MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc_minLoss*100,val_acc_minLoss*100))\n",
    "#     else:\n",
    "#         print(\"Model for MIN LOSS NOT SAVED\")\n",
    "#         val_acc_minLoss = math.inf\n",
    "\n",
    "#     if exists(minLossBackupModelName):\n",
    "#         model_minLoss_b = load_model(minLossBackupModelName)\n",
    "#         print(\"#### Evaluating BACKUP min loss model ####\")\n",
    "#         val_acc_minLoss_b, test_acc_minLoss_b, y_val_true, y_val_pred_minLoss_b, y_test_true, y_test_pred_minLoss_b = getValTestAccuracy(model_minLoss_b,X_val,y_val,X_test,y_test,encodingLabels)\n",
    "#         print(\"Model for BACKUP MIN LOSS test_acc: {:.3f} val_acc: {:.3f}\".format(test_acc_minLoss_b*100,val_acc_minLoss_b*100))\n",
    "#         if (val_acc_minLoss_b < val_acc_minLoss):\n",
    "#             print(\"### keeping BACKUP MIN LOSS model ####\")\n",
    "#             val_acc_minLoss, test_acc_minLoss, y_val_pred_minLoss, y_test_pred_minLoss = val_acc_minLoss_b, test_acc_minLoss_b, y_val_pred_minLoss_b, y_test_pred_minLoss_b\n",
    "#             !mv $minLossBackupModelName $minLossModelName\n",
    "#         else:\n",
    "#             !rm $minLossBackupModelName\n",
    "\n",
    "\n",
    "#     ### SAVING RESULTS ###\n",
    "#     if EPOCHS < 10:\n",
    "#         print(\"## SKIPPING SAVING. EPOCHS < 11\")\n",
    "#         continue\n",
    "\n",
    "#     if exists(folderPathWhereToSave+\"summaryResults.pickle\"):\n",
    "#         print(\"Loading previous results...\")\n",
    "#         with open(folderPathWhereToSave+\"summaryResults.pickle\",\"rb\") as handle:\n",
    "#                 results = pickle.load(handle)\n",
    "#     else:\n",
    "#         results = []\n",
    "\n",
    "#     results.append({\"val_acc\": val_acc, \n",
    "#                     \"test_acc\": test_acc, \n",
    "#                     \"model_name\": saveFileName, \n",
    "#                     \"y_val_true\": y_val_true,\n",
    "#                     \"y_val_pred\": y_val_pred,\n",
    "#                     \"y_test_true\": y_test_true,\n",
    "#                     \"y_test_pred\": y_test_pred,\n",
    "\n",
    "#                     \"val_acc_minLoss\": val_acc_minLoss, \n",
    "#                     \"test_acc_minLoss\": test_acc_minLoss, \n",
    "#                     \"y_val_pred_minLoss\": y_val_pred_minLoss,\n",
    "#                     \"y_test_pred_minLoss\": y_test_pred_minLoss\n",
    "#                    })\n",
    "\n",
    "#     print(\"Dumping results...\")\n",
    "#     with open(folderPathWhereToSave+\"summaryResults.pickle\",\"wb\") as handle:\n",
    "#         pickle.dump(results, handle)\n",
    "\n",
    "# print(\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping results on  /data/students_home/amoscatelli/Desktop/actionAnalysis/datasets/keypoint_rcnn_X_101_32x8d_FPN_3x-CROSS_SUBJECT-MIRR-STD_JIT_2-removeZerosFromDataset-relativeTo3GlobalBaricentersOfVideo-normalizeVideos-dataset.pickle\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot serialize a bytes object larger than 4 GiB",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-73cfe38edac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                  \u001b[0;34m\"X_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                  \u001b[0;34m\"y_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                  \"encodingLabels\": encodingLabels}, handle)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot serialize a bytes object larger than 4 GiB"
     ]
    }
   ],
   "source": [
    "from os.path import exists, basename\n",
    "newDatasetName = basename(datasetName).replace(\"-dataset.pickle\",\"\")\n",
    "newDatasetName += \"-MIRR\" if MIRRORING else \"\"\n",
    "newDatasetName += \"-STD_JIT_\"+str(STD_JITTERING) if STD_JITTERING>0 else \"\"\n",
    "for f in preprocess_functions:\n",
    "    newDatasetName += \"-\"+f.__name__\n",
    "newDatasetName += \"-dataset.pickle\"\n",
    "\n",
    "newDatasetPath = DATASET_FOLDER+newDatasetName\n",
    "newDatasetPath\n",
    "print(\"Dumping results on \",newDatasetPath)\n",
    "with open(newDatasetPath,\"wb\") as handle:\n",
    "    pickle.dump({\"X_train\": X_train,\n",
    "                 \"y_train\": y_train,\n",
    "                 \"X_val\": X_val,\n",
    "                 \"y_val\": y_val, \n",
    "                 \"X_test\": X_test,\n",
    "                 \"y_test\": y_test, \n",
    "                 \"encodingLabels\": encodingLabels}, handle)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.session.delete();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript \n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_6 (Dropout)          (None, 251, 68)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 64)                34304     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 34,824\n",
      "Trainable params: 34,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from keras import models #, layers\n",
    "from keras.layers import LSTM, CuDNNLSTM, Dropout, Dense #, Concatenate \n",
    "from keras.models import load_model #, Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l2 #, l1\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,LearningRateScheduler\n",
    "# import random\n",
    "from os import scandir\n",
    "from os.path import exists\n",
    "import shutil \n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed \n",
    "\n",
    "# setting SEED in order to initialize the networks always in the same way\n",
    "seed(2)\n",
    "set_random_seed(2)\n",
    "\n",
    "USE_LSTM = False\n",
    "USE_CuDNNLSTM = not USE_LSTM\n",
    "LSTM_LAYERS = 1\n",
    "HIDDEN_UNITS = 64\n",
    "### inputDim (251, 68)\n",
    "# 122 4L -> 335k\n",
    "# 155 3L -> 334k\n",
    "# 256 2L -> 336k\n",
    "\n",
    "### inputDim (251, 17*16)\n",
    "# 122 4L -> 434k\n",
    "# 155 3L -> 461k\n",
    "# 256 2L -> 545k\n",
    "\n",
    "DROPOUT = 0\n",
    "RECURRENT_DROPOUT = 0\n",
    "regularizer = 0\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 80\n",
    "inputDim = (251, 68) # Mini\n",
    "outputLen = 8\n",
    "\n",
    "# inputDim = (300, 68) # 60 azioni\n",
    "# outputLen = 60\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Dropout(DROPOUT, input_shape=inputDim, noise_shape=(BATCH_SIZE, 1, inputDim[1])))\n",
    "\n",
    "if USE_LSTM:\n",
    "    if LSTM_LAYERS == 1:\n",
    "        model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT))\n",
    "    else:       \n",
    "        model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT, return_sequences=True))\n",
    "        for layerIdx in range(2, LSTM_LAYERS):\n",
    "            model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT, return_sequences=True))\n",
    "        model.add(LSTM(HIDDEN_UNITS, recurrent_dropout = RECURRENT_DROPOUT))    \n",
    "\n",
    "elif USE_CuDNNLSTM:\n",
    "    reg=l2(regularizer) if regularizer > 0 else None\n",
    "\n",
    "    if LSTM_LAYERS == 1:\n",
    "        model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer = reg))\n",
    "    else:\n",
    "        model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer = reg, return_sequences=True))\n",
    "        for layerIdx in range(2, LSTM_LAYERS):\n",
    "            model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer = reg, return_sequences=True))                  \n",
    "        model.add(CuDNNLSTM(HIDDEN_UNITS, kernel_regularizer = reg, recurrent_regularizer=reg))\n",
    "\n",
    "\n",
    "model.add(Dense(outputLen, activation='softmax'))\n",
    "\n",
    "rmpsprop = RMSprop(learning_rate=LEARNING_RATE, rho=0.9)\n",
    "\n",
    "model.compile(\n",
    "#                                 optimizer='rmsprop',\n",
    "            optimizer=rmpsprop,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight1 = model.get_weights()\n",
    "weight2 = model.get_weights()\n",
    "# for layer in model.layers:\n",
    "#     weights = layer.get_weights() # list of numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing accessories file for low results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os.path import isfile, isdir, join, exists,getsize,basename\n",
    "# from os import scandir\n",
    "# import pickle\n",
    "\n",
    "# NUMBER_OF_BEST_MODEL_TO_SAVE = 20\n",
    "\n",
    "# SAVED_MODEL_FOLDER = \"/data/students_home/amoscatelli/Desktop/actionAnalysis/savedModels/\"\n",
    "# # SAVED_MODEL_FOLDER += \"Senesi/\"\n",
    "# # SAVED_MODEL_FOLDER += \"top-models/\"\n",
    "# SAVED_MODEL_FOLDER += \"Cross_view_mini/\"\n",
    "# # SAVED_MODEL_FOLDER += \"Cross_subject_mini/\"\n",
    "\n",
    "\n",
    "# accessoryFileList = [f.path for f in scandir(SAVED_MODEL_FOLDER) \n",
    "#                        if f.path.endswith(\".pickle\") \n",
    "#                        and \"summaryResult\" not in basename(f)]\n",
    "\n",
    "# with open(SAVED_MODEL_FOLDER+\"summaryResults.pickle\",\"rb\") as handle:\n",
    "#         loadedResults = pickle.load(handle)\n",
    "        \n",
    "# loadedResults.sort(key=lambda x : x[\"test_acc\"], reverse=True)\n",
    "# assert NUMBER_OF_BEST_MODEL_TO_SAVE > 10\n",
    "# bestModels = [r['model_name'] for r in loadedResults[:NUMBER_OF_BEST_MODEL_TO_SAVE]]\n",
    "\n",
    "# for accessoryFile in accessoryFileList:\n",
    "#     modelNameToCheck = basename(accessoryFile).replace(\".pickle\",\"\")\n",
    "#     if modelNameToCheck not in bestModels:\n",
    "#         print(\"Removing\",accessoryFile)\n",
    "#         !rm $accessoryFile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
