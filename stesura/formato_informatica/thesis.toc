\select@language {italian}
\select@language {italian}
\vspace {-\cftbeforepartskip }
\contentsline {chapter}{\numberline {1}L'apprendimento automatico}{9}{chapter.1}
\contentsline {section}{\numberline {1.1}Deep learning}{11}{section.1.1}
\contentsline {section}{\numberline {1.2}Le reti neurali}{11}{section.1.2}
\contentsline {section}{\numberline {1.3}Le reti neurali ricorrenti}{14}{section.1.3}
\contentsline {section}{\numberline {1.4}Le reti LSTM}{16}{section.1.4}
\contentsline {chapter}{\numberline {2}Lavori precedenti}{21}{chapter.2}
\contentsline {section}{\numberline {2.1}Recognizing Human Actions as Evolution of Pose Estimation Maps (2018)}{22}{section.2.1}
\contentsline {section}{\numberline {2.2}Action Machine: Rethinking Action Recognition in Trimmed Videos (2018)}{26}{section.2.2}
\contentsline {section}{\numberline {2.3}Vertex feature encoding and hierarchical temporal modelling in a spatial-temporal graph convolutional network for action recognition (2019)}{29}{section.2.3}
\contentsline {chapter}{\numberline {3}Stima della posa}{31}{chapter.3}
\contentsline {section}{\numberline {3.1}PoseNet}{32}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Stima dei key-points}{34}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Raggruppamento dei key-points in istanze di persona}{35}{subsection.3.1.2}
\contentsline {section}{\numberline {3.2}Detectron2}{37}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Mask R-CNN}{39}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Predizione della posa con Mask R-CNN}{41}{subsection.3.2.2}
\contentsline {chapter}{\numberline {4}Metodo proposto}{43}{chapter.4}
\contentsline {section}{\numberline {4.1}Estrazione delle pose}{43}{section.4.1}
\contentsline {section}{\numberline {4.2}Assegnazione coerente delle pose}{44}{section.4.2}
\contentsline {section}{\numberline {4.3}Rimozione degli zeri}{46}{section.4.3}
\contentsline {section}{\numberline {4.4}Tecniche di rielaborazione}{47}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}Baricentro del frame}{48}{subsection.4.4.1}
\contentsline {subsection}{\numberline {4.4.2}Baricentro del video}{49}{subsection.4.4.2}
\contentsline {subsection}{\numberline {4.4.3}Baricentri multipli}{50}{subsection.4.4.3}
\contentsline {subsection}{\numberline {4.4.4}Tecnica ``Next frame"}{51}{subsection.4.4.4}
\contentsline {subsection}{\numberline {4.4.5}Tecnica delle distanze cumulate}{53}{subsection.4.4.5}
\contentsline {subsection}{\numberline {4.4.6}Tecnica delle distanze relative}{54}{subsection.4.4.6}
\contentsline {section}{\numberline {4.5}Normalizzazione}{54}{section.4.5}
\contentsline {section}{\numberline {4.6}Smussamento}{56}{section.4.6}
\contentsline {section}{\numberline {4.7}Struttura della rete}{56}{section.4.7}
\contentsline {chapter}{\numberline {5}Il dataset NTU RGB+D}{59}{chapter.5}
\contentsline {section}{\numberline {5.1}NTU RGB+D in dettaglio}{61}{section.5.1}
\contentsline {section}{\numberline {5.2}Criteri di valutazione}{63}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Valutazione Cross-subject}{63}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Valutazione Cross-view}{64}{subsection.5.2.2}
\contentsline {chapter}{\numberline {6}Esperimenti e risultati}{65}{chapter.6}
\contentsline {section}{\numberline {6.1}Una porzione rappresentativa del dataset}{65}{section.6.1}
\contentsline {section}{\numberline {6.2}FAI}{66}{section.6.2}
\contentsline {chapter}{\numberline {7}Conclusioni e sviluppi futuri}{67}{chapter.7}
