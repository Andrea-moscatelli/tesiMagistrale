\select@language {italian}
\select@language {italian}
\vspace {-\cftbeforepartskip }
\contentsline {chapter}{\numberline {1}L'apprendimento automatico}{9}{chapter.1}
\contentsline {section}{\numberline {1.1}Deep learning}{11}{section.1.1}
\contentsline {section}{\numberline {1.2}Le reti neurali}{11}{section.1.2}
\contentsline {section}{\numberline {1.3}Le reti neurali ricorrenti}{14}{section.1.3}
\contentsline {section}{\numberline {1.4}Le reti LSTM}{16}{section.1.4}
\contentsline {chapter}{\numberline {2}Lavori precedenti}{21}{chapter.2}
\contentsline {section}{\numberline {2.1}Recognizing Human Actions as the Evolution of Pose Estimation Maps (2018)}{22}{section.2.1}
\contentsline {section}{\numberline {2.2}Actional-Structural Graph Convolutional Networks for Skeleton-based Action Recognition (2019)}{26}{section.2.2}
\contentsline {section}{\numberline {2.3}Vertex feature encoding and hierarchical temporal modelling in a spatial-temporal graph convolutional network for action recognition (2019)}{26}{section.2.3}
\contentsline {chapter}{\numberline {3}Stima della posa}{27}{chapter.3}
\contentsline {section}{\numberline {3.1}PoseNet}{28}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Stima dei key-points}{30}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Raggruppamento dei key-points in istanze di persona}{31}{subsection.3.1.2}
\contentsline {section}{\numberline {3.2}Detectron2}{33}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Mask R-CNN}{35}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Predizione della posa con Mask R-CNN}{37}{subsection.3.2.2}
\contentsline {chapter}{\numberline {4}Metodo proposto}{39}{chapter.4}
\contentsline {section}{\numberline {4.1}Estrazione delle pose}{39}{section.4.1}
\contentsline {section}{\numberline {4.2}Assegnazione coerente delle pose}{40}{section.4.2}
\contentsline {section}{\numberline {4.3}Rimozione degli zeri}{42}{section.4.3}
\contentsline {section}{\numberline {4.4}Tecniche di rielaborazione}{43}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}Baricentro del frame}{44}{subsection.4.4.1}
\contentsline {subsection}{\numberline {4.4.2}Baricentro del video}{45}{subsection.4.4.2}
\contentsline {subsection}{\numberline {4.4.3}Baricentri multipli}{46}{subsection.4.4.3}
\contentsline {subsection}{\numberline {4.4.4}Tecnica ``Next frame"}{47}{subsection.4.4.4}
\contentsline {subsection}{\numberline {4.4.5}Tecnica delle distanze cumulate}{49}{subsection.4.4.5}
\contentsline {subsection}{\numberline {4.4.6}Tecnica delle distanze relative}{50}{subsection.4.4.6}
\contentsline {section}{\numberline {4.5}Normalizzazione}{50}{section.4.5}
\contentsline {section}{\numberline {4.6}Smussamento}{52}{section.4.6}
\contentsline {section}{\numberline {4.7}Struttura della rete}{52}{section.4.7}
\contentsline {chapter}{\numberline {5}Il dataset NTU RGB+D}{55}{chapter.5}
\contentsline {section}{\numberline {5.1}NTU RGB+D in dettaglio}{57}{section.5.1}
\contentsline {section}{\numberline {5.2}Criteri di valutazione}{59}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Valutazione Cross-subject}{59}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Valutazione Cross-view}{60}{subsection.5.2.2}
\contentsline {chapter}{\numberline {6}Esperimenti e risultati}{61}{chapter.6}
\contentsline {section}{\numberline {6.1}Una porzione rappresentativa del dataset}{61}{section.6.1}
\contentsline {section}{\numberline {6.2}FAI}{62}{section.6.2}
\contentsline {chapter}{\numberline {7}Conclusioni e sviluppi futuri}{63}{chapter.7}
