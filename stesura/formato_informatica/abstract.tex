%--------------------------------------------------------------
% thesis.tex 
%--------------------------------------------------------------
% Corso di Laurea in Informatica 
% http://if.dsi.unifi.it/
% @Facolt\`a di Scienze Matematiche, Fisiche e Naturali
% @Universit\`a degli Studi di Firenze
%--------------------------------------------------------------
% - template for the main file of Informatica@Unifi Thesis 
% - based on Classic Thesis Style Copyright (C) 2008 
%   Andr\'e Miede http://www.miede.de   
%--------------------------------------------------------------
\documentclass[twoside,openright,titlepage,fleqn,
	headinclude,12pt,a4paper,BCOR5mm,footinclude]{scrbook}
%--------------------------------------------------------------
\newcommand{\myItalianTitle}{Riconoscimento di azioni umane usando tecniche di apprendimento profondo per la stima della posa\xspace}
\newcommand{\myEnglishTitle}{Human action recognition using deep learning techniques for pose estimation\xspace}
% use the right myDegree option
\newcommand{\myDegree}{Corso di Laurea Magistrale in Informatica\xspace}
%\newcommand{\myDegree}{
	%Corso di Laurea Specialistica in Scienze e Tecnologie 
	%dell'Informazione\xspace}
\newcommand{\myName}{Andrea Moscatelli\xspace}
\newcommand{\myProf}{Marco Bertini\xspace}
\newcommand{\myOtherProf}{Correlatore2\xspace}
\newcommand{\mySupervisor}{Nome Cognome\xspace}
\newcommand{\myFaculty}{
	Scuola di Scienze Matematiche, Fisiche e Naturali\xspace}
\newcommand{\myUni}{\protect{
	Universit\`a degli Studi di Firenze}\xspace}
\newcommand{\myLocation}{Firenze\xspace}
\newcommand{\myTime}{Anno Accademico 2018-2019\xspace}
\newcommand{\myVersion}{Version 0.1\xspace}
%--------------------------------------------------------------
\usepackage[italian]{babel}
\usepackage[latin1]{inputenc} 
\usepackage[T1]{fontenc} 
\usepackage[square,numbers]{natbib} 
\usepackage[fleqn]{amsmath}  
\usepackage{ellipsis}
\usepackage{listings}
%\usepackage{subfig}
\usepackage{caption}
\usepackage{appendix}
\usepackage{siunitx}
%--------------------------------------------------------------
\usepackage{dia-classicthesis-ldpkg}
%--------------------------------------------------------------
% Options for classicthesis.sty:
% tocaligned eulerchapternumbers drafting linedheaders 
% listsseparated subfig nochapters beramono eulermath parts 
% minionpro pdfspacing
\usepackage[eulerchapternumbers,linedheaders,beramono,eulermath,
parts]{classicthesis}
%--------------------------------------------------------------

%------------------------- MY PACKAGES -------------------------------------
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{siunitx}
\usepackage{makecell}
\usepackage{caption}
%\usepackage{subcaption}
\usepackage{longtable}
\usepackage{multicol}
\usepackage{color, colortbl}
\definecolor{highlightColor}{rgb}{0.88,1,1}
\usepackage{adjustbox}
%--------------------------------------------------------------

\newlength{\abcd} % for ab..z string length calculation
% how all the floats will be aligned
\newcommand{\myfloatalign}{\centering} 
\setlength{\extrarowheight}{3pt} % increase table row height
\captionsetup{format=hang,font=small}
%--------------------------------------------------------------
% Layout setting
%--------------------------------------------------------------
\usepackage{geometry}
\geometry{
	a4paper,
	ignoremp,
	bindingoffset = 1cm, 
	textwidth     = 13.5cm,
	textheight    = 21.5cm,
	lmargin       = 3.5cm, % left margin
	tmargin       = 4cm    % top margin 
}

\lstset{
  	frame=tb,
	language=Matlab,
  	aboveskip=3mm,
  	belowskip=3mm,
  	showstringspaces=false,
  	columns=flexible,
  	basicstyle={\small\ttfamily},
  	numbers=none,
  	breaklines=true,
  	breakatwhitespace=true,
  	tabsize=3
}

%--------------------------------------------------------------
\begin{document}
\frenchspacing
\raggedbottom
\pagenumbering{roman}
\pagestyle{plain}
%--------------------------------------------------------------
% Frontmatter
%--------------------------------------------------------------
\include{titlePage}
\pagestyle{scrheadings}
%--------------------------------------------------------------
% Mainmatter
%--------------------------------------------------------------
\pagenumbering{arabic}
% use \cleardoublepage here to avoid problems with pdfbookmark
%\include{intro} % use \myChapter command instead of \chapter
\cleardoublepage
\thispagestyle{empty}

\chapter{Abstract - Italiano}
I recenti progressi nel campo della visione artificiale hanno permesso alla comunità scientifica di spostarsi verso problemi ancora più articolati rispetto a quelli classici ed il riconoscimento di azioni corporee tramite l'analisi della posa umana sta attraendo recentemente una notevole attenzione. Il suo successo è senzaltro dovuto non solo agli ottimi risultati ottenuti, ma anche alla sua efficiente semplificazione della struttura umana riducendo di fatto i costi computazionali e le risorse necessarie allo stoccaggio dati.

In questo lavoro di tesi ci siamo dedicati al riconoscimento e alla classificazione di azioni umane tramite tecniche di apprendimento profondo per la stima della posa. A tale scopo abbiamo deciso di ideare un algoritmo che non avesse bisogno di informazioni iniziali complesse, come ad esempio la posizione dei giunti dei soggetti inquadrati, ma che attraverso l'uso dei soli video RGB fosse in grado di estrapolare tutte le informazioni necessarie.

Al fine di ottenere il miglior algoritmo abbiamo eseguito un serie di esperimenti strutturati secondo un procedimento ben preciso, che permettesse l'esplorazione rapida di ogni tecnica ideata affinando progressivamente i risultati per quelle più promettenti.

Quello che abbiamo ottenuto alla fine del processo sono due algoritmi con una discreta capacità di classificazione della azioni umane e per la loro semplicità anche un'elevata portabilità.

Il dataset utilizzato per l'addestramento degli algoritmi trovati è stato NTU-RGB+D di \emph{Amir Shahroudy, Jun Liu, Tian-Tsong Ng e Gang Wang} e l'accuratezza dei nostri algoritmi misurate secondo le metriche proposte dagli autori del dataset sono le seguenti:
\begin{itemize}
\item il classificatore ``\emph{3BAR-NEXT-Detectron}" con un accuratezza Cross subject di $83,32\%$ e Cross view di $93,69\%$  
\item il classificatore ``\emph{3BAR-NEXT-Posenet}" con un accuratezza Cross subject di $79,06\%$ e Cross view di $87,79\%$.
\end{itemize}

La semplicità di questi due algoritmi sottintende un'elevata portabilità, inoltre pur facendo uso dei soli video RGB, le loro prestazioni sono comparabili a molti altri lavori scientifici facenti uso dalla posizione dei giunti fornita da dataset stesso.

\chapter{Abstract - English version}
The recent advances in the computer vision field allowed the scientific community to move towards more complex problems than the classic ones and the recognition of human actions through the analysis of the human pose attracted recently considerable attention. Its success is undoubtedly due not only to the excellent obtained results, but also to its efficient simplification of the human structure, drastically reducing the computational and storage costs.

In this thesis work we focused on the recognition and classification of human actions through deep learning techniques for the estimation of the pose. To this end, we decided to create an algorithm that doesn't need complex initial information, such as the joints position of the subjects, and that through the use of the RGB video only is able to extract all the needed information.

In order to obtain the best algorithm, we followed a series of experiments structured according to a very precise procedure, which allowed us to a rapid exploration of the designed techniques, progressively refining the results for the most promising ones.

What we got at the end of the process are two algorithms with a good performance in classifying human actions and for their simplicity a high portability as well.

The dataset used to train the algorithms is \emph{NTU-RGB+D} by \emph{Amir Shahroudy, Jun Liu, Tian-Tsong Ng} and \emph{Gang Wang} and the accuracy of our algorithms measured according to the metrics proposed by the authors of this dataset are the follows:
\begin{itemize}
\item the classifier ``\emph{3BAR-NEXT-Detectron}" with a Cross subject and Cross view accuracy of $83,32\%$ and $93,69\%$ respectively.   
\item the classifier  ``\emph{3BAR-NEXT-Posenet}" with a Cross subject and Cross view accuracy of  $79,06\%$ and $87,79\%$ respectively.
\end{itemize}

The simplicity of these two algorithms implies high portability and while using only RGB videos, their performance is comparable to many other scientific works which use the position of the joints provided by the dataset itself.

\end{document}
