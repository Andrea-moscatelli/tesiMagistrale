\relax 
\select@language{italian}
\@writefile{toc}{\select@language{italian}}
\@writefile{lof}{\select@language{italian}}
\@writefile{lot}{\select@language{italian}}
\select@language{italian}
\@writefile{toc}{\select@language{italian}}
\@writefile{lof}{\select@language{italian}}
\@writefile{lot}{\select@language{italian}}
\@writefile{toc}{\contentsline {chapter}{Prefazione}{iii}}
\@writefile{toc}{\contentsline {chapter}{Introduzione}{iv}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}L'apprendimento automatico}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Deep learning}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Le reti neurali}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Un neurone biologico (sinistra) ed un neurone artificiale (destra) a confronto. La struttura del neurone artificiale si ispira molto a quella del neurone biologico. \relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:neurone}{{1.1}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Struttura di una rete neurale. Ogni livello della rete, eccetto il primo e l'ultimo, viene chiamato \emph  {hidden layer} ed i neuroni che lo compongono prendono il nome di \emph  {hidden units}. Magiore sar\`a il numero di hidden units e maggiore sar\`a la capacit\`a espressiva della rete. \relax }}{5}}
\newlabel{fig:hiddenLayer}{{1.2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Un esempio di rete convoluzionale per l'analisi di un'immagine. \emph  {Conv} = ``Convolution layer", moltiplicazione vettoriale della porzione di layer al quale ogni neurone \`e collegato; \emph  {Pool} = ``Pooling layer", sintetizzazione della porzione di layer connessa; \emph  {FC} = ``Fully connected layer"; \emph  {Softmax} = operazione conclusiva per la decisione del valore di output.\relax }}{7}}
\newlabel{fig:convNetwork}{{1.3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Le reti neurali ricorrenti}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Un esempio di rete ricorrente con due hidden layers.\relax }}{8}}
\newlabel{fig:reteRicorrente}{{1.4}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Esempio di ``srotolamento" di una rete ricorrente, ovvero la trasformazione da una rete ricorrente ad una combinazione equivalente di reti neurali semplici.\relax }}{8}}
\newlabel{fig:srotolamentoRNN}{{1.5}{8}}
\citation{LSTM}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Le reti LSTM}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Esempio di ``srotolamento" di una rete LSTM. In questa figura ogni unit\`a di rete ``A'' prende in input al tempo $t$ un elemento $X_t$ della sequenza temporale $X$ e restituisce uno stato in output $h_t$. \emph  {tanh} e $\sigma $ sono le funzioni di tangente iperbolica e sigmoidale rispettivamente, mentre ``$+$" e ``$\times $" sono rispettivamente le operazioni vettoriali di somma e moltiplicazione.\relax }}{10}}
\newlabel{fig:srotolamentoLSTM}{{1.6}{10}}
\newlabel{fig:cellState}{{1.7a}{11}}
\newlabel{sub@fig:cellState}{{a}{11}}
\newlabel{fig:gate}{{1.7b}{11}}
\newlabel{sub@fig:gate}{{b}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces I concetti chiave di una LSTM.\relax }}{11}}
\newlabel{fig:LSTMcellStateAndGate}{{1.7}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Forget gate di una LSTM\relax }}{11}}
\newlabel{fig:forgetGate}{{1.8}{11}}
\newlabel{fig:inputGate1}{{1.9a}{12}}
\newlabel{sub@fig:inputGate1}{{a}{12}}
\newlabel{fig:inputGate2}{{1.9b}{12}}
\newlabel{sub@fig:inputGate2}{{b}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Input gate.\relax }}{12}}
\newlabel{fig:LSTMinputForgetGate}{{1.9}{12}}
\citation{peepholeLSTM}
\citation{GRU}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Output gate di una LSTM\relax }}{13}}
\newlabel{fig:outputGate}{{1.10}{13}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Lavori precedenti}{14}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Stima della posa}{15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Esempi di stima della posa. In alto tre esempi di stima della posa utilizzando modelli di tipo volumetrico. In basso due esempi di stima della posa ottenuti utilizando modelli di tipo scheletrici. \relax }}{15}}
\citation{PosenetArticle}
\citation{Detectron2Link}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Un esempio di utilizzo in campo medico della stima della posa\relax }}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}PoseNet}{17}}
\citation{COCO-2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Stima dei key-points}{18}}
\citation{PosenetArticle}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Generazione con PoseNet delle heat-maps per ogni tipologia di key-point\relax }}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Esempio di stima degli offset a corto raggio con PoseNet\relax }}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Esempio di stima degli offset a medio raggio con PoseNet. L'intento \`e quello di raggruppare i keypoints appartenenti alla stessa persona.\relax }}{20}}
\newlabel{fig:midRangeOffset}{{3.5}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Raggruppamento dei key-points in istanze di persona}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Struttura ad albero utilizzata da PoseNet per raggruppare i key-points appartenenti alla stessa persona\relax }}{20}}
\newlabel{fig:strutturakeypoints}{{3.6}{20}}
\citation{DetectronLink}
\citation{caffe2}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Combinazione delle fasi adottate da PoseNet per il riconoscimento della posa in un'immagine.\relax }}{21}}
\newlabel{fig:overview-posenet}{{3.7}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Detectron2}{21}}
\citation{maskRCNN}
\citation{focalLossDetection}
\citation{cascadeRCNN}
\citation{panopticFeatures}
\citation{tensorMask}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Tipologie di analisi visive.\relax }}{22}}
\newlabel{fig:typeOfDetection}{{3.8}{22}}
\citation{maskRCNN}
\citation{focalLossDetection}
\citation{fasterRCNN}
\citation{fasterRCNN}
\citation{fastRCNN}
\citation{RFCN}
\citation{resNetXt}
\citation{resNet}
\citation{featurePyramid}
\citation{vgg16}
\citation{maskRCNN}
\citation{fasterRCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Instance segmentation con Detectron2\relax }}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Mask R-CNN}{24}}
\citation{fastRCNN}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Alcuni esempi di instance segmentation con Mask R-CNN\relax }}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Predizione della posa con Mask R-CNN}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Alcuni esempi di pose prediction con Mask R-CNN\relax }}{26}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Metodo proposto}{27}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Struttura della rete}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Tecniche}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Semplice}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Tecnica dei centri}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Tecnica delle differenze}{27}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Il dataset NTU RGB+D}{28}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{NTURGB}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}NTU RGB+D in dettaglio}{29}}
\citation{NTURGB}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Criteri di valutazione}{30}}
\newlabel{tab:puntiDivista}{{\caption@xref {tab:puntiDivista}{ on input line 615}}{31}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Altezza e distanza delle 3 telecamere per ogni setup di ripresa. Le altezze e le distanze sono espresse in metri. \relax }}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Valutazione Cross-subject}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Valutazione Cross-view}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Alcuni esempi di frames del dataset NTU RGB+D. Nelle prime 4 righe \`e possibile notare la variet\`a degli attori partecipanti al progetto e dei diversi punti di ripresa utilizzati. La quinta riga mostra la variet\`a intra-classe per una stessa azione. L'ultima riga mostra per uno stesso frame i valori RGB, i valori RGB + giunti, mappa di profondit\`a, mappa di profondit\`a + giunti e i valori a infrarossi. \relax }}{32}}
\newlabel{fig:varietaNTURGB}{{5.1}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces La configurazione dei 25 giunti utilizzati in NTU RGB+D. Le etichette utilizzate per i giunti sono: 1 - base della colonna vetrebrale, 2 - punto medio della colonna vertebrale, 3 - collo, 4 - testa, 5 - spalla sinistra, 6 - gomito sinistro, 7 - polso sinistro, 8 - mano sinistra, 9 - spalla destra, 10 - gomito destro, 11 - polso destro, 12 - mano destra, 13 - anca sinistra, 14 - ginocchio sinistro, 15 - caviglia sinistra, 16 - piede sinistro, 17 - anca destra, 18 - ginocchio destro, 19 - caviglia destra, 20 - piede destro, 21 - colonna vertebrale, 22 - punta della mano sinistra, 23 - pollice sinistro, 24 - punta della mano destra, 25 - pollice destro.\relax }}{33}}
\newlabel{fig:giuntiNTURGB}{{5.2}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Disposizione delle telecamere per ogni setup. La telecamera 1 ha ripreso ogni azione da una posizione centrale mentre le telecamere 2 e 3 hanno ripreso le azioni con un'angolazione di $\ang {45}$. Ogni attore ha ripetuto l'azione 2 volte: una rivolto verso la telecamere di destra e una verso quella di sinistra. \relax }}{33}}
\newlabel{fig:schemaTelecamere}{{5.3}{33}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Esperimenti e risultati}{34}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusioni e sviluppi futuri}{35}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{PosenetArticle}{1}
\bibcite{COCO-2016}{2}
\bibcite{PosenetLink}{3}
\bibcite{Detectron2Link}{4}
\bibcite{DetectronLink}{5}
\bibcite{caffe2}{6}
\bibcite{maskRCNN}{7}
\bibcite{focalLossDetection}{8}
\bibcite{fasterRCNN}{9}
\bibcite{fastRCNN}{10}
\bibcite{RFCN}{11}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{36}}
\bibcite{resNetXt}{12}
\bibcite{resNet}{13}
\bibcite{featurePyramid}{14}
\bibcite{vgg16}{15}
\bibcite{cascadeRCNN}{16}
\bibcite{panopticFeatures}{17}
\bibcite{tensorMask}{18}
\bibcite{NTURGB}{19}
\bibcite{LSTM}{20}
\bibcite{peepholeLSTM}{21}
\bibcite{GRU}{22}
